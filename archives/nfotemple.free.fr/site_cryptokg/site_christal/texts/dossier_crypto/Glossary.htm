<html><!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>

<HEAD>
	<META HTTP-EQUIV="Content-Type" CONTENT="text/html;CHARSET=iso-8859-1">
<META NAME = "DESCRIPTION"
      CONTENT = "Hyperlinked definitions and discussions of many
cryptographic, mathematic, logic, statistics, and electronics terms
used in cipher construction and analysis.
A Ciphers By Ritter page.">
<META NAME = "KEYWORDS"
      CONTENT = "cipher,crypto,cryptography,cryptographic,cryptology,
definition,dictionary,encryption,electronics,explain,explained,
explanation,glossary,information,learning,mathematics,statistics,
understanding">

	<META NAME="GENERATOR" Content="Visual Page 2.0 for Windows - Trial Version">
	<TITLE>Ritter's Crypto Glossary and Dictionary of Technical Cryptography</TITLE>
</HEAD>

<BODY BACKGROUND="spirbind2.gif" tppabs="http://christalmirror.ifrance.com/assembly/dossier10/images/spirbind2.gif" BGCOLOR="#FFFFCC">

<H1 ALIGN="CENTER"></H1>
<H1 ALIGN="CENTER"></H1>
<H1 ALIGN="CENTER">Ritter's Crypto Glossary <I>and</I> <BR>
Dictionary of Technical Cryptography</H1>
<P>
<H2 ALIGN="CENTER">Technical Cryptographic Terms Explained</H2>

<BLOCKQUOTE>
<BIG>
	<P><I>Hyperlinked definitions and discussions of many cryptographic, mathematic, logic, statistics, and electronics
	terms used in cipher construction and analysis.</I></BIG>
</BLOCKQUOTE>

<H2 ALIGN="CENTER">A <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/"><I>Ciphers By Ritter</I></A> Page</H2>
<P>
<H2 ALIGN="CENTER">Terry Ritter</H2>
<H2 ALIGN="CENTER">Current Edition: 1999 Jan 19</H2>
<P>For a basic introduction to cryptography, see <A HREF="javascript:if(confirm('http://www.io.com/~ritter/LEARNING.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/LEARNING.HTM'" tppabs="http://www.io.com/~ritter/LEARNING.HTM">Learning About
Cryptography</A>. Please feel free to send comments and suggestions for improvement to: <A HREF="mailto:ritter@io.com">ritter@io.com</A>.
You may wish to help support this work by patronizing <A HREF="javascript:if(confirm('http://www.io.com/~ritter/BOOKSHOP.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/BOOKSHOP.HTM'" tppabs="http://www.io.com/~ritter/BOOKSHOP.HTM" target="Bshop">Ritter's
Crypto Bookshop</A>.</P>
<P>
<HR ALIGN="CENTER">

<H2>Contents</H2>

<DL>
	<DT><BIG>A</BIG></DT>
	<DD><A HREF="Glossary.htm#Absolute">Absolute</A>, <A HREF="Glossary.htm#AC">AC</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#AdditiveCombiner"><NOBR>Additive
	Combiner</A></A><A HREF="Glossary.htm#AdditiveCombiner"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#AdditiveRNG"><NOBR>Additive RNG</A></A><A
	HREF="Glossary.htm#AdditiveRNG"></NOBR></A>, <A HREF="Glossary.htm#Affine">Affine</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#AffineBooleanFunction"><NOBR>Affine
	Boolean Function</A></A><A HREF="Glossary.htm#AffineBooleanFunction"></NOBR></A>, <A HREF="Glossary.htm#Alphabet">Alphabet</A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#AlternativeHypothesis"><NOBR>Alternative Hypothesis</A></A><A HREF="Glossary.htm#AlternativeHypothesis"></NOBR></A>,
	<A HREF="Glossary.htm#Amplifier">Amplifier</A>, <A HREF="Glossary.htm#Amplitude">Amplitude</A>, <A HREF="Glossary.htm#Analog">Analog</A>, <A HREF="Glossary.htm#AND">AND</A>,
	<A HREF="Glossary.htm#ASCII">ASCII</A>, <A HREF="Glossary.htm#Associative">Associative</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#AsymmetricCipher"><NOBR>Asymmetric
	Cipher</A></A><A HREF="Glossary.htm#AsymmetricCipher"></NOBR></A>, <A HREF="Glossary.htm#Attack">Attack</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#AugmentedRepetitions"><NOBR>Augmented
	Repetitions</A></A><A HREF="Glossary.htm#AugmentedRepetitions"></NOBR></A>, <A HREF="Glossary.htm#Authentication">Authentication</A>, <A
	HREF="Glossary.htm"></A><A HREF="Glossary.htm#AuthenticatingBlockCipher"><NOBR>Authenticating Block Cipher</A></A><A HREF="Glossary.htm#AuthenticatingBlockCipher"></NOBR></A>,
	<A HREF="Glossary.htm#Autokey">Autokey</A>, <A HREF="Glossary.htm#Avalanche">Avalanche</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#AvalancheEffect"><NOBR>Avalanche
	Effect</A></A><A HREF="Glossary.htm#AvalancheEffect"></NOBR></A>
	<DT><BIG>B</BIG></DT>
	<DD><A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BackDoor"><NOBR>Back Door</A></A><A HREF="Glossary.htm#BackDoor"></NOBR></A>, <A HREF="Glossary.htm#Balance">Balance</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BalancedBlockMixer"><NOBR>Balanced Block Mixer</A></A><A HREF="Glossary.htm#BalancedBlockMixer"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BalancedBlockMixing"><NOBR>Balanced Block Mixing</A></A><A HREF="Glossary.htm#BalancedBlockMixing"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BalancedCombiner"><NOBR>Balanced Combiner</A></A><A HREF="Glossary.htm#BalancedCombiner"></NOBR></A>,
	<A HREF="Glossary.htm#Base64">Base-64</A>, <A HREF="Glossary.htm#Bel">Bel</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BentFunction"><NOBR>Bent Function</A></A><A
	HREF="Glossary.htm#BentFunction"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BernoulliTrials"><NOBR>Bernoulli Trials</A></A><A HREF="Glossary.htm#BernoulliTrials"></NOBR></A>,
	<A HREF="Glossary.htm#Bijective">Bijective</A>, <A HREF="Glossary.htm#Binary">Binary</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BinomialDistribution"><NOBR>Binomial
	Distribution</A></A><A HREF="Glossary.htm#BinomialDistribution"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BirthdayAttack"><NOBR>Birthday
	Attack</A></A><A HREF="Glossary.htm#BirthdayAttack"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BirthdayParadox"><NOBR>Birthday Paradox</A></A><A
	HREF="Glossary.htm#BirthdayParadox"></NOBR></A>, <A HREF="Glossary.htm#Bit">Bit</A>, <A HREF="Glossary.htm#Block">Block</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BlockCipher"><NOBR>Block
	Cipher</A></A><A HREF="Glossary.htm#BlockCipher"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BlockSize"><NOBR>Block Size</A></A><A
	HREF="Glossary.htm#BlockSize"></NOBR></A>, <A HREF="Glossary.htm#Boolean">Boolean</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BooleanFunction"><NOBR>Boolean
	Function</A></A><A HREF="Glossary.htm#BooleanFunction"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BooleanFunctionNonlinearity"><NOBR>Boolean
	Function Nonlinearity</A></A><A HREF="Glossary.htm#BooleanFunctionNonlinearity"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BooleanLogic"><NOBR>Boolean
	Logic</A></A><A HREF="Glossary.htm#BooleanLogic"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BooleanMapping"><NOBR>Boolean Mapping</A></A><A
	HREF="Glossary.htm#BooleanMapping"></NOBR></A>, <A HREF="Glossary.htm#Break">Break</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BruteForceAttack"><NOBR>Brute
	Force Attack</A></A><A HREF="Glossary.htm#BruteForceAttack"></NOBR></A>, <A HREF="Glossary.htm#Bug">Bug</A>, <A HREF="Glossary.htm#Byte">Byte</A>
	<DT><BIG>C</BIG></DT>
	<DD><A HREF="Glossary.htm#Capacitor">Capacitor</A>, <A HREF="Glossary.htm#CBC">CBC</A>, <A HREF="Glossary.htm#cdf">c.d.f.</A>, <A HREF="Glossary.htm#CFB">CFB</A>,
	<A HREF="Glossary.htm#Chain">Chain</A>, <A HREF="Glossary.htm#Chaos">Chaos</A>, <A HREF="Glossary.htm#ChiSquare">Chi-Square</A>, <A HREF="Glossary.htm#Cipher">Cipher</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#CipherTaxonomy"><NOBR>Cipher Taxonomy</A></A><A HREF="Glossary.htm#CipherTaxonomy"></NOBR></A>, <A
	HREF="Glossary.htm#Ciphering">Ciphering</A>, <A HREF="Glossary.htm#Ciphertext">Ciphertext</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#CiphertextExpansion"><NOBR>Ciphertext
	Expansion</A></A><A HREF="Glossary.htm#CiphertextExpansion"></NOBR></A>, <A HREF="Glossary.htm#Ciphony">Ciphony</A>, <A HREF="Glossary.htm#Circuit">Circuit</A>,
	<A HREF="Glossary.htm#Clock">Clock</A>, <A HREF="Glossary.htm#Closed">Closed</A>, <A HREF="Glossary.htm#Code">Code</A>, <A HREF="Glossary.htm#Codebook">Codebook</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#CodebookAttack"><NOBR>Codebook Attack</A></A><A HREF="Glossary.htm#CodebookAttack"></NOBR></A>, <A
	HREF="Glossary.htm#Combination">Combination</A>, <A HREF="Glossary.htm#Combinatoric">Combinatoric</A>, <A HREF="Glossary.htm#Combiner">Combiner</A>,
	<A HREF="Glossary.htm#Commutative">Commutative</A>, <A HREF="Glossary.htm#Complete">Complete</A>, <A HREF="Glossary.htm#Component">Component</A>, <A
	HREF="Glossary.htm#Computer">Computer</A>, <A HREF="Glossary.htm#Conductor">Conductor</A>, <A HREF="Glossary.htm#Confusion">Confusion</A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#ConfusionSequence"><NOBR>Confusion Sequence</A></A><A HREF="Glossary.htm#ConfusionSequence"></NOBR></A>, <A HREF="Glossary.htm#Congruence">Congruence</A>,
	<A HREF="Glossary.htm#Contextual">Contextual</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ConventionalCipher"><NOBR>Conventional Cipher</A></A><A
	HREF="Glossary.htm#ConventionalCipher"></NOBR></A>, <A HREF="Glossary.htm#Convolution">Convolution</A>, <A HREF="Glossary.htm#Correlation">Correlation</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#CorrelationCoefficient"><NOBR>Correlation Coefficient</A></A><A HREF="Glossary.htm#CorrelationCoefficient"></NOBR></A>,
	<A HREF="Glossary.htm#CRC">CRC</A>, <A HREF="Glossary.htm#Cryptanalysis">Cryptanalysis</A>, <A HREF="Glossary.htm#Cryptanalyst">Cryptanalyst</A>, <A
	HREF="Glossary.htm#Cryptographer">Cryptographer</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#CryptographicMechanism"><NOBR>Cryptographic Mechanism</A></A><A
	HREF="Glossary.htm#CryptographicMechanism"></NOBR></A>, <A HREF="Glossary.htm#Cryptography">Cryptography</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#CryptographyWar"><NOBR>Cryptography
	War</A></A><A HREF="Glossary.htm#CryptographyWar"></NOBR></A>, <A HREF="Glossary.htm#Cryptology">Cryptology</A>, <A HREF="Glossary.htm#Current">Current</A>
	<DT><BIG>D</BIG></DT>
	<DD><A HREF="Glossary.htm#dB">dB</A>, <A HREF="Glossary.htm#DC">DC</A>, <A HREF="Glossary.htm#Debug">Debug</A>, <A HREF="Glossary.htm#Decipher">Decipher</A>, <A
	HREF="Glossary.htm#Decryption">Decryption</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DeductiveReasoning"><NOBR>Deductive Reasoning</A></A><A
	HREF="Glossary.htm#DeductiveReasoning"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DefinedPlaintextAttack"><NOBR>Defined Plaintext
	Attack</A></A><A HREF="Glossary.htm#DefinedPlaintextAttack"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DegreesOfFreedom"><NOBR>Degrees
	of Freedom</A></A><A HREF="Glossary.htm#DegreesOfFreedom"></NOBR></A>, <A HREF="Glossary.htm#DES">DES</A>, <A HREF="Glossary.htm#Decibel">Decibel</A>,
	<A HREF="Glossary.htm#Decimal">Decimal</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DesignStrength"><NOBR>Design Strength</A></A><A HREF="Glossary.htm#DesignStrength"></NOBR></A>,
	<A HREF="Glossary.htm#Deterministic">Deterministic</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DictionaryAttack"><NOBR>Dictionary Attack</A></A><A
	HREF="Glossary.htm#DictionaryAttack"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DifferentialCryptanalysis"><NOBR>Differential Cryptanalysis</A></A><A
	HREF="Glossary.htm#DifferentialCryptanalysis"></NOBR></A>, <A HREF="Glossary.htm#Diffusion">Diffusion</A>, <A HREF="Glossary.htm#Digital">Digital</A>,
	<A HREF="Glossary.htm#Diode">Diode</A>, <A HREF="Glossary.htm#Distribution">Distribution</A>, <A HREF="Glossary.htm#Distributive">Distributive</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DivideAndConquer"><NOBR>Divide and Conquer</A></A><A HREF="Glossary.htm#DivideAndConquer"></NOBR></A>,
	<A HREF="Glossary.htm#Domain">Domain</A>, <A HREF="Glossary.htm#Dyadic">Dyadic</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DynamicKeying"><NOBR>Dynamic
	Keying</A></A><A HREF="Glossary.htm#DynamicKeying"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DynamicSubstitutionCombiner"><NOBR>Dynamic
	Substitution Combiner</A></A><A HREF="Glossary.htm#DynamicSubstitutionCombiner"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#DynamicTransposition"><NOBR>Dynamic
	Transposition</A></A><A HREF="Glossary.htm#DynamicTransposition"></NOBR></A>
	<DT><BIG>E</BIG></DT>
	<DD><A HREF="Glossary.htm#ECB">ECB</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ElectricField"><NOBR>Electric Field</A></A><A HREF="Glossary.htm#ElectricField"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ElectromagneticField"><NOBR>Electromagnetic Field</A></A><A HREF="Glossary.htm#ElectromagneticField"></NOBR></A>,
	<A HREF="Glossary.htm#Electronic">Electronic</A>, <A HREF="Glossary.htm#Encipher">Encipher</A>, <A HREF="Glossary.htm#Encryption">Encryption</A>, <A
	HREF="Glossary.htm#Entropy">Entropy</A>, <A HREF="Glossary.htm#Ergodic">Ergodic</A>, <A HREF="Glossary.htm#Extractor">Extractor</A>, <A HREF="Glossary.htm#ExclusiveOR">Exclusive-OR</A>
	<DT><BIG>F</BIG></DT>
	<DD><A HREF="Glossary.htm#Factorial">Factorial</A>, <A HREF="Glossary.htm#Fallacy">Fallacy</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FastWalshTransform"><NOBR>Fast
	Walsh Transform</A></A><A HREF="Glossary.htm#FastWalshTransform"></NOBR></A>, <A HREF="Glossary.htm#FCSR">FCSR</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FeistelConstruction"><NOBR>Feistel
	Construction</A></A><A HREF="Glossary.htm#FeistelConstruction"></NOBR></A>, <A HREF="Glossary.htm#FencedDES">Fenced DES</A>, <A HREF="Glossary.htm#Fencing">Fencing</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FencingLayer"><NOBR>Fencing Layer</A></A><A HREF="Glossary.htm#FencingLayer"></NOBR></A>, <A HREF="Glossary.htm#FFT">FFT</A>,
	<A HREF="Glossary.htm#Field">Field</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FiniteField"><NOBR>Finite Field</A></A><A HREF="Glossary.htm#FiniteField"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FlipFlop"><NOBR>Flip-Flop</A></A><A HREF="Glossary.htm#FlipFlop"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FourierSeries"><NOBR>Fourier
	Series</A></A><A HREF="Glossary.htm#FourierSeries"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FourierTheorem"><NOBR>Fourier Theorem</A></A><A
	HREF="Glossary.htm#FourierTheorem"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#FourierTransform"><NOBR>Fourier Transform</A></A><A
	HREF="Glossary.htm#FourierTransform"></NOBR></A>, <A HREF="Glossary.htm#Frequency">Frequency</A>, <A HREF="Glossary.htm#Function">Function</A>, <A
	HREF="Glossary.htm#FWT">FWT</A>
	<DT><BIG>G</BIG></DT>
	<DD><A HREF="Glossary.htm#Gain">Gain</A>, <A HREF="Glossary.htm#GaloisField">Galois Field</A>, <A HREF="Glossary.htm#Gate">Gate</A>, <A HREF="Glossary.htm#GF2n">GF
	2<SUP>n</SUP></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#GoodnessOfFit"><NOBR>Goodness of Fit</A></A><A HREF="Glossary.htm#GoodnessOfFit"></NOBR></A>,
	<A HREF="Glossary.htm#Group">Group</A>
	<DT><BIG>H</BIG></DT>
	<DD><A HREF="Glossary.htm"></A><A HREF="Glossary.htm#HammingDistance"><NOBR>Hamming Distance</A></A><A HREF="Glossary.htm#HammingDistance"></NOBR></A>,
	<A HREF="Glossary.htm#Hardware">Hardware</A>, <A HREF="Glossary.htm#Hash">Hash</A>, <A HREF="Glossary.htm#Hexadecimal">Hexadecimal (Hex)</A>, <A HREF="Glossary.htm#Homophonic">Homophonic</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#HomophonicSubstitution"><NOBR>Homophonic Substitution</A></A><A HREF="Glossary.htm#HomophonicSubstitution"></NOBR></A>
	<DT><BIG>I</BIG></DT>
	<DD><A HREF="Glossary.htm#IDEA">IDEA</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#IdealSecrecy"><NOBR>Ideal Secrecy</A></A><A HREF="Glossary.htm#IdealSecrecy"></NOBR></A>,
	<A HREF="Glossary.htm#i.i.d.">i.i.d.</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#InductiveReasoning"><NOBR>Inductive Reasoning</A></A><A
	HREF="Glossary.htm#InductiveReasoning"></NOBR></A>, <A HREF="Glossary.htm#Inductor">Inductor</A>, <A HREF="Glossary.htm#Injective">Injective</A>, <A
	HREF="Glossary.htm#Insulator">Insulator</A>, <A HREF="Glossary.htm#Integer">Integer</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#IntermediateBlock"><NOBR>Intermediate
	Block</A></A><A HREF="Glossary.htm#IntermediateBlock"></NOBR></A>, <A HREF="Glossary.htm#Interval">Interval</A>, <A HREF="Glossary.htm#Into">Into</A>,
	<A HREF="Glossary.htm#Inverse">Inverse</A>, <A HREF="Glossary.htm#Invertible">Invertible</A>, <A HREF="Glossary.htm#Involution">Involution</A>, <A
	HREF="Glossary.htm#Irreducible">Irreducible</A>, <A HREF="Glossary.htm#IV">IV</A>
	<DT><BIG>J</BIG></DT>
	<DD><A HREF="Glossary.htm#Jitterizer">Jitterizer</A>
	<DT><BIG>K</BIG></DT>
	<DD><A HREF="Glossary.htm#KB">KB</A>, <A HREF="Glossary.htm#Kb">Kb</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#KerckhoffsRequirements"><NOBR>Kerckhoff's
	Requirements</A></A><A HREF="Glossary.htm#KerckhoffsRequirements"></NOBR></A>, <A HREF="Glossary.htm#Key">Key</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#KeyDistributionProblem"><NOBR>Key
	Distribution Problem</A></A><A HREF="Glossary.htm#KeyDistributionProblem"></NOBR></A>, <A HREF="Glossary.htm#Keyspace">Keyspace</A>, <A
	HREF="Glossary.htm"></A><A HREF="Glossary.htm#KeyedSubstitution"><NOBR>Keyed Substitution</A></A><A HREF="Glossary.htm#KeyedSubstitution"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#KnownPlaintextAttack"><NOBR>Known Plaintext Attack</A></A><A HREF="Glossary.htm#KnownPlaintextAttack"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#KolmogorovSmirnov"><NOBR>Kolmogorov-Smirnov</A></A><A HREF="Glossary.htm#KolmogorovSmirnov"></NOBR></A>
	<DT><BIG>L</BIG></DT>
	<DD><A HREF="Glossary.htm#Latency">Latency</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#LatinSquare"><NOBR>Latin Square</A></A><A HREF="Glossary.htm#LatinSquare"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#LatinSquareCombiner"><NOBR>Latin Square Combiner</A></A><A HREF="Glossary.htm#LatinSquareCombiner"></NOBR></A>,
	<A HREF="Glossary.htm#Layer">Layer</A>, <A HREF="Glossary.htm#LFSR">LFSR</A>, <A HREF="Glossary.htm#Linear">Linear</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#LinearComplexity"><NOBR>Linear
	Complexity</A></A><A HREF="Glossary.htm#LinearComplexity"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#LinearFeedbackShiftRegister"><NOBR>Linear
	Feedback Shift Register</A></A><A HREF="Glossary.htm#LinearFeedbackShiftRegister"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#LinearLogicFunction"><NOBR>Linear
	Logic Function</A></A><A HREF="Glossary.htm#LinearLogicFunction"></NOBR></A>, <A HREF="Glossary.htm#Logic">Logic</A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#LogicFunction"><NOBR>Logic Function</A></A><A HREF="Glossary.htm#LogicFunction"></NOBR></A>, <A HREF="Glossary.htm#LSB">LSB</A>
	<DT><BIG>M</BIG></DT>
	<DD><A HREF="Glossary.htm#MSequence">M-Sequence</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MachineLanguage"><NOBR>Machine Language</A></A><A
	HREF="Glossary.htm#MachineLanguage"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MagneticField"><NOBR>Magnetic Field</A></A><A HREF="Glossary.htm#MagneticField"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ManInTheMiddleAttack"><NOBR>Man-in-the-Middle Attack</A></A><A HREF="Glossary.htm#ManInTheMiddleAttack"></NOBR></A>,
	<A HREF="Glossary.htm#Mapping">Mapping</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MarkovProcess"><NOBR>Markov Process</A></A><A HREF="Glossary.htm#MarkovProcess"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MathematicalCryptography"><NOBR>Mathematical Cryptography</A></A><A HREF="Glossary.htm#MathematicalCryptography"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MaximalLength"><NOBR>Maximal Length</A></A><A HREF="Glossary.htm#MaximalLength"></NOBR></A>, <A HREF="Glossary.htm#MB">MB</A>,
	<A HREF="Glossary.htm#Mb">Mb</A>, <A HREF="Glossary.htm#Mechanism">Mechanism</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MechanisticCryptography"><NOBR>Mechanistic
	Cryptography</A></A><A HREF="Glossary.htm#MechanisticCryptography"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MersennePrime"><NOBR>Mersenne
	Prime</A></A><A HREF="Glossary.htm#MersennePrime"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MessageDigest"><NOBR>Message Digest</A></A><A
	HREF="Glossary.htm#MessageDigest"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MessageKey"><NOBR>Message Key</A></A><A HREF="Glossary.htm#MessageKey"></NOBR></A>,
	<A HREF="Glossary.htm#MITM">MITM</A>, <A HREF="Glossary.htm#Mixing">Mixing</A>, <A HREF="Glossary.htm#MixingCipher">Mixing Cipher</A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#Mod2"><NOBR>Mod 2</A></A><A HREF="Glossary.htm#Mod2"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#Mod2Polynomial"><NOBR>Mod
	2 Polynomial</A></A><A HREF="Glossary.htm#Mod2Polynomial"></NOBR></A>, <A HREF="Glossary.htm#Mode">Mode</A>, <A HREF="Glossary.htm#Modulo">Modulo</A>,
	<A HREF="Glossary.htm#Monadic">Monadic</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MonoalphabeticSubstitution"><NOBR>Monoalphabetic Substitution</A></A><A
	HREF="Glossary.htm#MonoalphabeticSubstitution"></NOBR></A>, <A HREF="Glossary.htm#Monographic">Monographic</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#MultipleEncryption"><NOBR>Multiple
	Encryption</A></A><A HREF="Glossary.htm#MultipleEncryption"></NOBR></A>
	<DT><BIG>N</BIG></DT>
	<DD><A HREF="Glossary.htm#Nomenclator">Nominclator</A>, <A HREF="Glossary.htm#Nominal">Nominal</A>, <A HREF="Glossary.htm#Nonlinearity">Nonlinearity</A>,
	<A HREF="Glossary.htm#NOT">NOT</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#NullHypothesis"><NOBR>Null Hypothesis</A></A><A HREF="Glossary.htm#NullHypothesis"></NOBR></A>
	<DT><BIG>O</BIG></DT>
	<DD><A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ObjectCode"><NOBR>Object Code</A></A><A HREF="Glossary.htm#ObjectCode"></NOBR></A>, <A HREF="Glossary.htm#Objective">Objective</A>,
	<A HREF="Glossary.htm#Octal">Octal</A>, <A HREF="Glossary.htm#Octave">Octave</A>, <A HREF="Glossary.htm#OFB">OFB</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#OneTimePad"><NOBR>One
	Time Pad</A></A><A HREF="Glossary.htm#OneTimePad"></NOBR></A>, <A HREF="Glossary.htm#OneToOne">One-To-One</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#OneWayDiffusion"><NOBR>One
	Way Diffusion</A></A><A HREF="Glossary.htm#OneWayDiffusion"></NOBR></A>, <A HREF="Glossary.htm#Onto">Onto</A>, <A HREF="Glossary.htm#Opcode">Opcode</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#OperatingMode"><NOBR>Operating Mode</A></A><A HREF="Glossary.htm#OperatingMode"></NOBR></A>, <A HREF="Glossary.htm#Opponent">Opponent</A>,
	<A HREF="Glossary.htm#OR">OR</A>, <A HREF="Glossary.htm#Order">Order</A>, <A HREF="Glossary.htm#Ordinal">Ordinal</A>, <A HREF="Glossary.htm#Orthogonal">Orthogonal</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#OrthogonalLatinSquares"><NOBR>Orthogonal Latin Squares</A></A><A HREF="Glossary.htm#OrthogonalLatinSquares"></NOBR></A>,
	<A HREF="Glossary.htm#OTP">OTP</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#OverallDiffusion"><NOBR>Overall Diffusion</A></A><A HREF="Glossary.htm#OverallDiffusion"></NOBR></A>
	<DT><BIG>P</BIG></DT>
	<DD><A HREF="Glossary.htm#Padding">Padding</A>, <A HREF="Glossary.htm#Password">Password</A>, <A HREF="Glossary.htm#Patent">Patent</A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#PatentInfringement"><NOBR>Patent Infringement</A></A><A HREF="Glossary.htm#PatentInfringement"></NOBR></A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#PerfectSecrecy"><NOBR>Perfect Secrecy</A></A><A HREF="Glossary.htm#PerfectSecrecy"></NOBR></A>, <A HREF="Glossary.htm#Permutation">Permutation</A>,
	<A HREF="Glossary.htm#PGP">PGP</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PhysicallyRandom"><NOBR>Physically Random</A></A><A HREF="Glossary.htm#PhysicallyRandom"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PinkNoise"><NOBR>Pink Noise</A></A><A HREF="Glossary.htm#PinkNoise"></NOBR></A>, <A HREF="Glossary.htm#Plaintext">Plaintext</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PoissonDistribution"><NOBR>Poisson Distribution</A></A><A HREF="Glossary.htm#PoissonDistribution"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PolyalphabeticCombiner"><NOBR>Polyalphabetic Combiner</A></A><A HREF="Glossary.htm#PolyalphabeticCombiner"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PolyalphabeticSubstitution"><NOBR>Polyalphabetic Substitution</A></A><A HREF="Glossary.htm#PolyalphabeticSubstitution"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PolygramSubstitution"><NOBR>Polygram Substitution</A></A><A HREF="Glossary.htm#PolygramSubstitution"></NOBR></A>,
	<A HREF="Glossary.htm#Polygraphic">Polygraphic</A>, <A HREF="Glossary.htm#Polynomial">Polynomial</A>, <A HREF="Glossary.htm#Polyphonic">Polyphonic</A>,
	<A HREF="Glossary.htm#Population">Population</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PopulationEstimation"><NOBR>Population Estimation</A></A><A
	HREF="Glossary.htm#PopulationEstimation"></NOBR></A>, <A HREF="Glossary.htm#Power">Power</A>, <A HREF="Glossary.htm#Primitive">Primitive</A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#PrimitivePolynomial"><NOBR>Primitive Polynomial</A></A><A HREF="Glossary.htm#PrimitivePolynomial"></NOBR></A>, <A HREF="Glossary.htm#Prime">Prime</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PriorArt"><NOBR>Prior Art</A></A><A HREF="Glossary.htm#PriorArt"></NOBR></A>, <A HREF="Glossary.htm#PRNG">PRNG</A>,
	<A HREF="Glossary.htm#Process">Process</A>, <A HREF="Glossary.htm#PseudoRandom">Pseudorandom</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#PublicKeyCipher"><NOBR>Public
	Key Cipher</A></A><A HREF="Glossary.htm#PublicKeyCipher"></NOBR></A>
	<DT><BIG>R</BIG></DT>
	<DD><A HREF="Glossary.htm#Random">Random</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#RandomNumberGenerator"><NOBR>Random Number Generator</A></A><A
	HREF="Glossary.htm#RandomNumberGenerator"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#RandomVariable"><NOBR>Random Variable</A></A><A
	HREF="Glossary.htm#RandomVariable"></NOBR></A>, <A HREF="Glossary.htm#Range">Range</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ReallyRandom"><NOBR>Really
	Random</A></A><A HREF="Glossary.htm#ReallyRandom"></NOBR></A>, <A HREF="Glossary.htm#Relay">Relay</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ResearchHypothesis"><NOBR>Research
	Hypothesis</A></A><A HREF="Glossary.htm#ResearchHypothesis"></NOBR></A>, <A HREF="Glossary.htm#Resistor">Resistor</A>, <A HREF="Glossary.htm#Ring">Ring</A>,
	<A HREF="Glossary.htm#Root">Root</A>, <A HREF="Glossary.htm#RMS">RMS</A>, <A HREF="Glossary.htm#RootMeanSquare">Root Mean Square</A>, <A HREF="Glossary.htm#RNG">RNG</A>,
	<A HREF="Glossary.htm#Round">Round</A>, <A HREF="Glossary.htm#RSA">RSA</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#RunningKey"><NOBR>Running Key</A></A><A
	HREF="Glossary.htm#RunningKey"></NOBR></A>
	<DT><BIG>S</BIG></DT>
	<DD><A HREF="Glossary.htm#Salt">Salt</A>, <A HREF="Glossary.htm#Sample">Sample</A>, <A HREF="Glossary.htm#S-Box">S-Box</A>, <A HREF="Glossary.htm#Scalable">Scalable</A>,
	<A HREF="Glossary.htm#Secrecy">Secrecy</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SecretCode"><NOBR>Secret Code</A></A><A HREF="Glossary.htm#SecretCode"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SecretKeyCipher"><NOBR>Secret Key Cipher</A></A><A HREF="Glossary.htm#SecretKeyCipher"></NOBR></A>,
	<A HREF="Glossary.htm#Security">Security</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SecurityThroughObscurity"><NOBR>Security Through Obscurity</A></A><A
	HREF="Glossary.htm#SecurityThroughObscurity"></NOBR></A>, <A HREF="Glossary.htm#Semiconductor">Semiconductor</A>, <A HREF="Glossary.htm#Semigroup">Semigroup</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SessionKey"><NOBR>Session Key</A></A><A HREF="Glossary.htm#SessionKey"></NOBR></A>, <A HREF="Glossary.htm#Set">Set</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#ShiftRegister"><NOBR>Shift Register</A></A><A HREF="Glossary.htm#ShiftRegister"></NOBR></A>, <A HREF="Glossary.htm#Shuffle">Shuffle</A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SieveOfEratosthenes"><NOBR>Sieve of Eratosthenes</A></A><A HREF="Glossary.htm#SieveOfEratosthenes"></NOBR></A>,
	<A HREF="Glossary.htm#Significance">Significance</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SimpleSubstitution"><NOBR>Simple Substitution</A></A><A
	HREF="Glossary.htm#SimpleSubstitution"></NOBR></A>, <A HREF="Glossary.htm#Software">Software</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SourceCode"><NOBR>Source
	Code</A></A><A HREF="Glossary.htm#SourceCode"></NOBR></A>, <A HREF="Glossary.htm#State">State</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#StationaryProcess"><NOBR>Stationary
	Process</A></A><A HREF="Glossary.htm#StationaryProcess"></NOBR></A>, <A HREF="Glossary.htm#Statistic">Statistic</A>, <A HREF="Glossary.htm#Statistics">Statistics</A>,
	<A HREF="Glossary.htm#Steganography">Steganography</A>, <A HREF="Glossary.htm#Stochastic">Stochastic</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#StreamCipher"><NOBR>Stream
	Cipher</A></A><A HREF="Glossary.htm#StreamCipher"></NOBR></A>, <A HREF="Glossary.htm#Strength">Strength</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#StrictAvalancheCriterion"><NOBR>Strict
	Avalanche Criterion (SAC)</A></A><A HREF="Glossary.htm#StrictAvalancheCriterion"></NOBR></A>, <A HREF="Glossary.htm#Subjective">Subjective</A>,
	<A HREF="Glossary.htm#Substitution">Substitution</A>, <A HREF="Glossary.htm#SubstitutionPermutation">Substitution-Permutation</A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#SubstitutionTable"><NOBR>Substitution Table</A></A><A HREF="Glossary.htm#SubstitutionTable"></NOBR></A>, <A HREF="Glossary.htm#Superencryption">Superencryption</A>,
	<A HREF="Glossary.htm#Surjective">Surjective</A>, <A HREF="Glossary.htm#Switch">Switch</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SwitchingFunction"><NOBR>Switching
	Function</A></A><A HREF="Glossary.htm#SwitchingFunction"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SymmetricCipher"><NOBR>Symmetric
	Cipher</A></A><A HREF="Glossary.htm#SymmetricCipher"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SymmetricGroup"><NOBR>Symmetric
	Group</A></A><A HREF="Glossary.htm#SymmetricGroup"></NOBR></A>, <A HREF="Glossary.htm#System">System</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#SystemDesign"><NOBR>System
	Design</A></A><A HREF="Glossary.htm#SystemDesign"></NOBR></A>
	<DT><BIG>T</BIG></DT>
	<DD><A HREF="Glossary.htm"></A><A HREF="Glossary.htm#TableSelectionCombiner"><NOBR>Table Selection Combiner</A></A><A HREF="Glossary.htm#TableSelectionCombiner"></NOBR></A>,
	<A HREF="Glossary.htm#TEMPEST">TEMPEST</A>, <A HREF="Glossary.htm#Transformer">Transformer</A>, <A HREF="Glossary.htm#Transistor">Transistor</A>, <A
	HREF="Glossary.htm#Transposition">Transposition</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#TrapDoor"><NOBR>Trap Door</A></A><A HREF="Glossary.htm#TrapDoor"></NOBR></A>,
	<A HREF="Glossary.htm"></A><A HREF="Glossary.htm#TripleDES"><NOBR>Triple DES</A></A><A HREF="Glossary.htm#TripleDES"></NOBR></A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#TrulyRandom"><NOBR>Truly Random</A></A><A HREF="Glossary.htm#TrulyRandom"></NOBR></A>, <A HREF="Glossary.htm#Trust">Trust</A>, <A
	HREF="Glossary.htm"></A><A HREF="Glossary.htm#TruthTable"><NOBR>Truth Table</A></A><A HREF="Glossary.htm#TruthTable"></NOBR></A>, <A HREF="Glossary.htm"></A><A
	HREF="Glossary.htm#TypeIError"><NOBR>Type I Error</A></A><A HREF="Glossary.htm#TypeIError"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#TypeIIError"><NOBR>Type
	II Error</A></A><A HREF="Glossary.htm#TypeIIError"></NOBR></A>
	<DT><BIG>U</BIG></DT>
	<DD><A HREF="Glossary.htm#Unary">Unary</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#UnexpectedDistance"><NOBR>Unexpected Distance</A></A><A
	HREF="Glossary.htm#UnexpectedDistance"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#UnicityDistance"><NOBR>Unicity Distance</A></A><A
	HREF="Glossary.htm#UnicityDistance"></NOBR></A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#UniformDistribution"><NOBR>Uniform Distribution</A></A><A
	HREF="Glossary.htm#UniformDistribution"></NOBR></A>
	<DT><BIG>V</BIG></DT>
	<DD><A HREF="Glossary.htm"></A><A HREF="Glossary.htm#VariableSizeBlockCipher"><NOBR>Variable Size Block Cipher</A></A><A HREF="Glossary.htm#VariableSizeBlockCipher"></NOBR></A>,
	<A HREF="Glossary.htm#Voltage">Voltage</A>
	<DT><BIG>W</BIG></DT>
	<DD><A HREF="Glossary.htm"></A><A HREF="Glossary.htm#WalshFunctions"><NOBR>Walsh Functions</A></A><A HREF="Glossary.htm#WalshFunctions"></NOBR></A>,
	<A HREF="Glossary.htm#Weight">Weight</A>, <A HREF="Glossary.htm#Whitening">Whitening</A> <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#WhiteNoise"><NOBR>White
	Noise</A></A><A HREF="Glossary.htm#WhiteNoise"></NOBR></A> <A HREF="Glossary.htm#Wire">Wire</A>
	<DT><BIG>X</BIG></DT>
	<DD><A HREF="Glossary.htm#XOR">XOR</A>
</DL>

<P>
<HR ALIGN="CENTER">


<DL>
	<DT><A NAME="Absolute"></A></DT>
	<DT><B>Absolute</B></DT>
	<DD>In the study of <A HREF="Glossary.htm#Logic">logic</A>, something observed similarly by most observers, or something agreed
	upon, or which has the same value each time measured. Something not in dispute, unarguable, and independent of
	other <A HREF="Glossary.htm#State">state</A>. As opposed to <A HREF="Glossary.htm#Contextual">contextual</A>. <A NAME="AC"></A>
	<P>
	<DT><B>AC</B></DT>
	<DD>Alternating <A HREF="Glossary.htm#Current">Current</A>: Electrical power which repeatedly reverses direction of flow. As
	opposed to <A HREF="Glossary.htm#DC">DC</A>.
	<P>Generally used for power distribution because the changing current supports the use of <A HREF="Glossary.htm#Transformer">transformers</A>.
	Utilities can thus transport power at high <A HREF="Glossary.htm#Voltage">voltage</A> and low <A HREF="Glossary.htm#Current">current</A>,
	which minimize &quot;ohmic&quot; or I<SUP>2</SUP>R losses. The high voltages are then reduced at power substations
	and again by pole transformers for delivery to the consumer. <A NAME="AdditiveCombiner"></A></P>
	<P>
	<DT><B>Additive Combiner</B></DT>
	<DD>An additive <A HREF="Glossary.htm#Combiner">combiner</A> uses numerical concepts similar to addition to <A HREF="Glossary.htm#Mixing">mix</A>
	multiple values into a single result.
	<P>One example is <A HREF="Glossary.htm#Byte">byte</A> addition <A HREF="Glossary.htm#Modulo">modulo</A> 256, which simply adds two byte
	values, each in the range 0..255, and produces the remainder after division by 256, again a value in the byte range
	of 0..255. Subtraction is also an &quot;additive&quot; combiner.</P>
	<P>Another example is bit-level <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> which is addition <A HREF="Glossary.htm#Mod2">mod 2</A>.
	A byte-level exclusive-OR is a <A HREF="Glossary.htm#Polynomial">polynomial</A> addition. <A NAME="AdditiveRNG"></A></P>
	<P>
	<DT><B>Additive RNG</B></DT>
	<DD>(Additive <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>.) A <A HREF="Glossary.htm#LFSR">LFSR</A>-based <A
	HREF="Glossary.htm#RNG">RNG</A> typically using multi-bit elements and integer addition (instead of <A HREF="Glossary.htm#XOR">XOR</A>)
	combining. References include:
	<BLOCKQUOTE>
		<P>Knuth, D. 1981. <I>The Art of Computer Programming,</I> Vol. 2, <I>Seminumerical Algorithms.</I> 2nd ed. 26-31.
		Addison-Wesley: Reading, Massachusetts.
	</BLOCKQUOTE>
	<BLOCKQUOTE>
		<P>Marsaglia, G. and L. Tsay. 1985. Matrices and the Structure of Random Number Sequences. <I>Linear Algebra and
		its Applications.</I> 67: 147-156.
	</BLOCKQUOTE>
	<P>Advantages include:
	<UL>
		<LI>A long, mathematically proven cycle length.
		<LI>Especially efficient <A HREF="Glossary.htm#Software">software</A> implementations.
		<LI>Almost arbitrary initialization (some element must have its least significant bit set).
		<LI>A simple design which is easy to get right.
	</UL>
	<P>In addition, a vast multiplicity of independent cycles has the potential of confusing even a &quot;quantum computer,&quot;
	should such a thing become possible. <BIG></P>
	<PRE>   For Degree-n Primitive, and Bit Width w

   Total States:       2<SUP>nw</SUP>
   Non-Init States:    2<SUP>n(w-1)</SUP>
   Number of Cycles:   2<SUP>(n-1)(w-1)</SUP>
   Length Each Cycle:  (2<SUP>n</SUP>-1)2<SUP>(w-1)</SUP>
   Period of LSB:      2<SUP>n</SUP>-1
</PRE>
</BIG>
	<P>The binary addition of two bits with no carry input is just XOR, so the <A HREF="Glossary.htm#LSB">lsb</A> of an Additive
	RNG has the usual <A HREF="Glossary.htm#MaximalLength">maximal length</A> period.</P>
	<P>A degree-127 Additive RNG using 127 elements of 32 bits each has 2<SUP>4064</SUP> unique states. Of these, 2<SUP>3937</SUP>
	are disallowed by initialization (the <A HREF="Glossary.htm#LSB">lsb</A>'s are all &quot;0&quot;) but this is just one unusable
	state out of 2<SUP>127</SUP>. There are still 2<SUP>3906</SUP> cycles which <I>each</I> have almost 2<SUP>158</SUP>
	steps. (The Cloak2 <A HREF="Glossary.htm#StreamCipher">stream cipher</A> uses an Additive RNG with 9689 elements of 32 bits,
	and so has 2<SUP>310048</SUP> unique states. These are mainly distributed among 2<SUP>300328</SUP> different cycles
	with almost 2<SUP>9720</SUP> steps each.)</P>
	<P>Note that any LFSR, including the Additive RNG, is very weak when used alone. But when steps are taken to hide
	the sequence (such as using a <A HREF="Glossary.htm#Jitterizer">jitterizer</A> and <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic
	Substitution combining</A>) the result can have significant strength. <A NAME="Affine"></A></P>
	<P>
	<DT><B>Affine</B></DT>
	<DD>Generally speaking, <A HREF="Glossary.htm#Linear">linear</A>. Sometimes <I>affine</I> generalizes &quot;linearity&quot;
	to expressions of multiple independent variables, with only a single-variable expression being called &quot;linear.&quot;
	From analytic and algebraic geometry.
	<BLOCKQUOTE>
		<P>Assume the flat plane defined by two arbitrary unit vectors <B>e</B><SUB>1</SUB>, <B>e</B><SUB>2</SUB> and a
		common origin <B>O</B>; this is a coordinate &quot;frame.&quot; Assume a grid of lines parallel to each frame vector,
		separated by unit lengths (a &quot;metric&quot; which may differ for each vector). If the vectors happen to be
		perpendicular, we have a Cartesian coordinate system, but in any case we can locate any point on the plane by its
		position on the grid.</P>
		<P>An affine transformation can change the origin, the angle between the vectors, and unit vector lengths. Shapes
		in the original frame thus become &quot;pinched,&quot; &quot;squashed&quot; or &quot;stretched&quot; images under
		the affine transformation. This same sort of thing generalizes to higher degree expressions.
	</BLOCKQUOTE>
	<P>The <I>Handbook of Mathematics</I> says that if <B>e</B><SUB>1</SUB>, <B>e</B><SUB>2</SUB>, <B>e</B><SUB>3</SUB>
	are linearly independent vectors, any vector <B>a</B> can be expressed uniquely in the form <B>a</B> = <B>a</B><SUB>1</SUB><B>e</B><SUB>1</SUB>
	+ <B>a</B><SUB>2</SUB><B>e</B><SUB>2</SUB> + <B>a</B><SUB>3</SUB><B>e</B><SUB>3</SUB> where the <B>a</B><SUB>i</SUB>
	are the <I>affine coordinates.</I> (p.518)</P>
	<P><I>The VNR Concise Encyclopedia of Mathematics</I> says &quot;All transformations that lead to a uniquely soluble
	system of linear equations are called <I>affine transformations</I>.&quot; (p.534) <A NAME="AffineBooleanFunction"></A></P>
	<P>
	<DT><B>Affine Boolean Function</B></DT>
	<DD>A <A HREF="Glossary.htm#BooleanFunction">Boolean function</A> which can be represented in the form: <BIG>
	<BLOCKQUOTE>
		<P><TT>a<SUB>n</SUB>x<SUB>n</SUB> + a<SUB>n-1</SUB>x<SUB>n-1</SUB> + ... + a<SUB>1</SUB>x<SUB>1</SUB> + a<SUB>0</SUB></TT>
	</BLOCKQUOTE>
</BIG>
	where the operations are <A HREF="Glossary.htm#Mod2">mod 2</A>: addition is <A HREF="Glossary.htm#ExclusiveOR">Exclusive-OR</A>, and multiplication
	is <A HREF="Glossary.htm#AND">AND</A>.
	<P>Note that all of the variables <BIG>x<SUB>i</SUB></BIG> are to the first power only, and each coefficient <BIG>a<SUB>i</SUB></BIG>
	simply enables or disables its associated variable. The result is a single Boolean value, but the constant term
	<BIG>a<SUB>0</SUB></BIG> can produce either possible output polarity.</P>
	<P>Here are all possible 3-variable affine Boolean functions (each of which may be inverted by complementing the
	constant term):</P>
	<PRE>     affine    truth table

          c    0  0  0  0  0  0  0  0
         x0    0  1  0  1  0  1  0  1
      x1       0  0  1  1  0  0  1  1
      x1+x0    0  1  1  0  0  1  1  0
   x2          0  0  0  0  1  1  1  1
   x2+   x0    0  1  0  1  1  0  1  0
   x2+x1       0  0  1  1  1  1  0  0
   x2+x1+x0    0  1  1  0  1  0  0  1

</PRE>
	<A NAME="Alphabet"></A>
	<P>
	<DT><B>Alphabet</B></DT>
	<DD>The set of symbols under discussion. <A NAME="AlternativeHypothesis"></A>
	<P>
	<DT><B>Alternative Hypothesis</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the statement formulated so that the logically contrary statement,
	the <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A> <I>H</I><SUB>0</SUB> has a test <A HREF="Glossary.htm#Statistic">statistic</A>
	with a known <A HREF="Glossary.htm#Distribution">distribution</A> for the case when there is nothing unusual to detect. Also
	called the <A HREF="Glossary.htm#ResearchHypothesis">research hypothesis</A> <I>H</I><SUB>1</SUB>, and logically identical
	to &quot;NOT-<I>H</I><SUB>0</SUB>&quot; or &quot;<I>H</I><SUB>0</SUB> is not true.&quot; <A NAME="Amplifier"></A>
	<P>
	<DT><B>Amplifier</B></DT>
	<DD>a <A HREF="Glossary.htm#Component">component</A> or device intended to sense a signal and produce a larger version of that
	signal. In general, any amplifying device is limited by available power, <A HREF="Glossary.htm#Frequency">frequency</A> response,
	and device maximums for <A HREF="Glossary.htm#Voltage">voltage</A>, <A HREF="Glossary.htm#Current">current</A>, and power dissipation.
	<P><A HREF="Glossary.htm#Transistor">Transistors</A> are <A HREF="Glossary.htm#Analog">analog</A> amplifiers which are basically <A HREF="Glossary.htm#Linear">linear</A>
	over a reasonable range and so require <A HREF="Glossary.htm#DC">DC</A> power. In contrast, <A HREF="Glossary.htm#Relay">Relays</A> are
	classically mechanical devices with direct metal-to-metal moving connections, and so can handle generally higher
	power and <A HREF="Glossary.htm#AC">AC</A> current. <A NAME="Amplitude"></A></P>
	<P>
	<DT><B>Amplitude</B></DT>
	<DD>The signal level, or height. <A NAME="Analog"></A>
	<P>
	<DT><B>Analog</B></DT>
	<DD>Pertaining to continuous values. As opposed to <A HREF="Glossary.htm#Digital">digital</A> or discrete quantities. <A NAME="AND"></A>
	<P>
	<DT><B>AND</B></DT>
	<DD>A Boolean <A HREF="Glossary.htm#LogicFunction">logic function</A> which is also <A HREF="Glossary.htm#Mod2">mod 2</A> multiplication.
	<A NAME="ASCII"></A>
	<P>
	<DT><B>ASCII</B></DT>
	<DD>A public <A HREF="Glossary.htm#Code">code</A> for converting between 7-<A HREF="Glossary.htm#Bit">bit</A> values 0..127 (or 00..7f
	<A HREF="Glossary.htm#Hexadecimal">hex</A>) and text characters. ASCII is an acronym for American Standard Code for Information
	Interchange.
	<PRE>DEC HEX CTRL CMD    DEC HEX CHAR    DEC HEX CHAR   DEC HEX CHAR

  0  00  ^@  NUL     32  20  SPC     64  40  @      96  60  '
  1  01  ^A  SOH     33  21   !      65  41  A      97  61  a
  2  02  ^B  STX     34  22   &quot;      66  42  B      98  62  b
  3  03  ^C  ETX     35  23   #      67  43  C      99  63  c
  4  04  ^D  EOT     36  24   $      68  44  D     100  64  d
  5  05  ^E  ENQ     37  25   %      69  45  E     101  65  e
  6  06  ^F  ACK     38  26   &amp;      70  46  F     102  66  f
  7  07  ^G  BEL     39  27   '      71  47  G     103  67  g
  8  08  ^H  BS      40  28   (      72  48  H     104  68  h
  9  09  ^I  HT      41  29   )      73  49  I     105  69  i
 10  0a  ^J  LF      42  2a   *      74  4a  J     106  6a  j
 11  0b  ^K  VT      43  2b   +      75  4b  K     107  6b  k
 12  0c  ^L  FF      44  2c   ,      76  4c  L     108  6c  l
 13  0d  ^M  CR      45  2d   -      77  4d  M     109  6d  m
 14  0e  ^N  SO      46  2e   .      78  4e  N     110  6e  n
 15  0f  ^O  SI      47  2f   /      79  4f  O     111  6f  o
 16  10  ^P  DLE     48  30   0      80  50  P     112  70  p
 17  11  ^Q  DC1     49  31   1      81  51  Q     113  71  q
 18  12  ^R  DC2     50  32   2      82  52  R     114  72  r
 19  13  ^S  DC3     51  33   3      83  53  S     115  73  s
 20  14  ^T  DC4     52  34   4      84  54  T     116  74  t
 21  15  ^U  NAK     53  35   5      85  55  U     117  75  u
 22  16  ^V  SYN     54  36   6      86  56  V     118  76  v
 23  17  ^W  ETB     55  37   7      87  57  W     119  77  w
 24  18  ^X  CAN     56  38   8      88  58  X     120  78  x
 25  19  ^Y  EM      57  39   9      89  59  Y     121  79  y
 26  1a  ^Z  SUB     58  3a   :      90  5a  Z     122  7a  z
 27  1b  ^[  ESC     59  3b   ;      91  5b  [     123  7b  {
 28  1c  ^\  FS      60  3c   &lt;      92  5c  \     124  7c  |
 29  1d  ^]  GS      61  3d   =      93  5d  ]     125  7d  }
 30  1e  ^^  RS      62  3e   &gt;      94  5e  ^     126  7e
 31  1f  ^_  US      63  3f   ?      95  5f  _     127  7f  DEL
</PRE>
	<A NAME="Associative"></A>
	<P>
	<DT><B>Associative</B></DT>
	<DD>A <A HREF="Glossary.htm#Dyadic">dyadic</A> operation in which two sequential operations on three arguments can first operate
	on either the first two or the last two arguments, producing the same result in either case: <NOBR>(a + b) + c
	= a + (b + c).</NOBR>
	<P>Also see: <A HREF="Glossary.htm#Commutative">commutative</A> and <A HREF="Glossary.htm#Distributive">distributive</A>. <A NAME="AsymmetricCipher"></A></P>
	<P>
	<DT><B>Asymmetric Cipher</B></DT>
	<DD>A <A HREF="Glossary.htm#PublicKeyCipher">public key cipher</A>. <A NAME="Attack"></A>
	<P>
	<DT><B>Attack</B></DT>
	<DD>General ways in which a <A HREF="Glossary.htm#Cryptanalyst">cryptanalyst</A> may try to &quot;<A HREF="Glossary.htm#Break">break</A>&quot;
	or penetrate the secrecy of a <A HREF="Glossary.htm#Cipher">cipher</A>. These are <B>not</B> algorithms; they are just <I>approaches</I>
	as a starting place for constructing specific algorithms.
	<P>Classically, attacks were neither named nor classified; there was just: &quot;here is a cipher, and here is
	the attack.&quot; And while this gradually developed into named attacks, there is no overall attack taxonomy. Currently,
	attacks are often classified by the information available to the attacker or <I>constraints</I> on the attack,
	and then by strategies which use the available information. Not only <A HREF="Glossary.htm#Cipher">ciphers</A>, but also cryptographic
	<A HREF="Glossary.htm#Hash">hash</A> functions can be attacked, generally with very different strategies.
	<H4>Informational Constraints</H4>
	<P>We are to attack a cipher which <A HREF="Glossary.htm#Encipher">enciphers</A> <A HREF="Glossary.htm#Plaintext">plaintext</A> into <A
	HREF="Glossary.htm#Ciphertext">ciphertext</A> or <A HREF="Glossary.htm#Decipher">deciphers</A> the opposite way, under control of a <A
	HREF="Glossary.htm#Key">key</A>. The available information necessarily constrains our attack strategies.
	<UL>
		<LI><B>Ciphertext Only:</B> We have only ciphertext to work with. Sometimes the statistics of the ciphertext provide
		insight and can lead to a break.
		<LI><B>Known Plaintext:</B> We have some, or even an extremely large amount, of plaintext and the associated ciphertext.
		<LI><B>Defined Plaintext:</B> We can submit arbitrary messages to be ciphered and capture the resulting ciphertext.
		(Also Chosen Plaintext and Adaptive Chosen Plaintext.)
		<LI><B>Defined Ciphertext:</B> We can submit arbitrary messages to be deciphered and see the resulting plaintext.
		(Also Chosen Ciphertext and Adaptive Chosen Ciphertext.)
		<LI><B>Chosen Key:</B> We can specify a change in any particular key bit, or some other relationship between keys.
		<LI><B>Timing:</B> We can measure the duration of ciphering operations and use that to reveal the key or data.
		<LI><B>Fault Analysis:</B> We can induce random faults into the ciphering machinery, and use those to expose the
		key.
		<LI><B>Man-in-the-Middle:</B> We can subvert the routing capabilities of a computer network, and pose as the other
		side to each of the communicators. (Usually a key authentication attack on <A HREF="Glossary.htm#PublicKeyCipher">public key</A>
		systems.)
	</UL>
	<H4>Attack Strategies</H4>
	<P>The goal of an attack is to reveal some unknown plaintext, or the key (which will reveal the plaintext). An
	attack which succeeds with less effort than a brute-force search we call a <A HREF="Glossary.htm#Break">break</A>. An &quot;academic&quot;
	(&quot;theoretical,&quot; &quot;certificational&quot;) break may involve impractically large amounts of data or
	resources, yet still be called a &quot;break&quot; if the attack would be easier than brute force. (It is thus
	possible for a &quot;broken&quot; cipher to be much stronger than a cipher with a short key.) Sometimes the attack
	strategy is thought to be obvious, given a particular informational constraint, and is not further classified.
	<UL>
		<LI><A HREF="Glossary.htm#BruteForceAttack"><B>Brute Force</B></A> (also Exhaustive Key Search): Try to decipher ciphertext
		under every possible key until readable messages are produced. (Also &quot;brute force&quot; any searchable-size
		<I>part</I> of a cipher.)
		<LI><A HREF="Glossary.htm#CodebookAttack"><B>Codebook</B></A> (the classic &quot;codebreaking&quot; approach): Collect a <A
		HREF="Glossary.htm#Codebook">codebook</A> of transformations between plaintext and ciphertext.
		<LI><A HREF="Glossary.htm#DifferentialCryptanalysis"><B>Differential Cryptanalysis:</B></A> Find a statistical correlation
		between key values and cipher transformations (typically the Exclusive-OR of text pairs), then use sufficient defined
		plaintext to develop the key.
		<LI><B>Linear Cryptanalysis:</B> Find a linear approximation to the keyed S-boxes in a cipher, and use that to
		reveal the key.
		<LI><B>Meet-in-the-Middle:</B> Given a two-level multiple encryption, search for the keys by collecting every possible
		result for enciphering a known plaintext under the first cipher, and deciphering the known ciphertext under the
		second cipher; then find the match.
		<LI><B>Key Schedule:</B> Choose keys which produce known effects in different rounds.
		<LI><A HREF="Glossary.htm#BirthdayAttack"><B>Birthday</B></A> (usually a hash attack): Use the <A HREF="Glossary.htm#BirthdayParadox">birthday
		paradox</A>, the idea that it is much easier to find two values which match than it is to find a match to some
		particular value.
		<LI><B>Formal Coding</B> (also Algebraic): From the cipher design, develop equations for the key in terms of known
		plaintext, then solve those equations.
		<LI><B>Correlation</B>: In a <A HREF="Glossary.htm#StreamCipher">stream cipher</A>, distinguish between data and confusion,
		or between different confusion streams, from a statistical imbalance in a <A HREF="Glossary.htm#Combiner">combiner</A>.
		<LI><A HREF="Glossary.htm#DictionaryAttack"><B>Dictionary</B></A>: Form a list of the most-likely keys, then try those keys
		one-by-one (a way to improve brute force).
		<LI><B>Replay</B>: Record and save some ciphertext blocks or messages (especially if the content is known), then
		re-send those blocks when useful.
	</UL>
	<P>Many attacks try to isolate unknown small components or aspects so they can be solved separately, a process
	known as <A HREF="Glossary.htm#DivideAndConquer">divide and conquer</A>. Also see: <A HREF="Glossary.htm#Security">security</A>. <A NAME="AugmentedRepetitions"></A></P>
	<P>
	<DT><B>Augmented Repetitions</B></DT>
	<DD>When sampling with replacement, eventually we again find some object or value which has been found before.
	We call such an occurrence a &quot;repetition.&quot; A value found exactly twice is a double, or &quot;2-rep&quot;;
	a value found three times is a triple or &quot;3-rep,&quot; and so on.
	<P>For a known <A HREF="Glossary.htm#Population">population</A>, the number of repetitions expected at each level has long
	been understood to be a <A HREF="Glossary.htm#BinomialDistribution">binomial</A> expression. But if we are sampling in an attempt
	to <I>establish</I> the effective size of an unknown population, we have two problems:
	<OL>
		<P>
		<LI>The binomial equations which predict expected repetitions do not reverse well to predict population, and
		<LI>Exact repetitions discard information and so are less accurate than we would like. For example, if we have
		a double and then find another of that value, we now have a triple, and one <I>less</I> double. So if we are using
		doubles to predict population, the occurrence of a triple influences the predicted population in exactly the wrong
		direction.
	</OL>
	<P>Fortunately, there is an unexpected and apparently previously unknown combinatoric relationship between the
	population and the number of combinations of occurrences of repeated values. This allows us to convert any number
	of triples and higher <I>n</I>-reps to the number of 2-reps which have the same probability. So if we have a double,
	and then get another of the same value, we have a triple, which we can convert into three 2-reps. The total number
	of 2-reps from all repetitions (the <I>augmented 2-reps</I> value) is then used to predict population.</P>
	<P>We can relate the number of samples <I>s</I> to the population <I>N</I> through the expected number of augmented
	doubles <I>Ead</I>:</P>
	<PRE>     Ead(N,s) = s(s-1) / 2N .
</PRE>
	This equation is <B>exact</B>, <I>provided</I> we interpret all the exact n-reps in terms of 2-reps. For example,
	a triple is interpreted as three doubles; the augmentation from 3-reps to 2-reps is (3 C 2) or 3. The augmented
	result is the sum of the contributions from all higher repetition levels:
	<PRE>           n    i
     ad = SUM  ( ) r[i] .
          i=2   2
</PRE>
	where <I>ad</I> is the number of augmented doubles, and <I>r[i]</I> is the exact repetition count at the <I>i</I>-th
	level.
	<P>And this leads to an equation for predicting population:</P>
	<PRE>     Nad(s,ad) = s(s-1) / 2 ad .
</PRE>
	This predicts the population <I>Nad</I> as based on a mean value of augmented doubles <I>ad</I>. Clearly, we expect
	the number of samples to be far larger than the number of augmented doubles, but an error in the augmented doubles
	<I>ad</I> should produce a proportionally similar error in the predicted population <I>Nad.</I> We typically develop
	<I>ad</I> to high precision by averaging the results of many large trials.
	<P>However, since the trials should have approximately a simple <A HREF="Glossary.htm#PoissonDistribution">Poisson distribution</A>
	(which has only a single parameter), we could be a bit more clever and fit the results to the expected distribution,
	thus perhaps developing a bit more accuracy.</P>
	<P>Also see the article: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/ARTS/BIRTHDAY.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/ARTS/BIRTHDAY.HTM'" tppabs="http://www.io.com/~ritter/ARTS/BIRTHDAY.HTM">Estimating Population from Repetitions
	in Accumulated Random Samples</A>, and the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/POPWKSHT.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/POPWKSHT.HTM'" tppabs="http://www.io.com/~ritter/JAVASCRP/POPWKSHT.HTM">Population
	Estimation Worksheets in JavaScript</A> page of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By
	Ritter / JavaScript</A> computation pages. <A NAME="Authentication"></A></P>
	<P>
	<DT><B>Authentication</B></DT>
	<DD>One of the objectives of <A HREF="Glossary.htm#Cryptography">cryptography</A>: Assurance that a message has not been modified
	in transit or storage (<I>message</I> authentication or message <I>integrity</I>). Also <A HREF="Glossary.htm#Key">key</A>
	authentication for <A HREF="Glossary.htm#PublicKeyCipher">public keys</A>. Also user or source identification, which may verify
	the right to send the message in the first place. <A NAME="MessageAuthentication"></A>
	<H4>Message <A HREF="Glossary.htm#Authentication">Authentication</A></H4>
	<P>One form of message authentication computes a <A HREF="Glossary.htm#CRC">CRC</A> <A HREF="Glossary.htm#Hash">hash</A> across the <A
	HREF="Glossary.htm#Plaintext">plaintext</A> data, and appends the CRC remainder (or <I>result</I>) to the plaintext data: this
	adds a computed redundancy to an arbitrary message. The CRC result is then <A HREF="Glossary.htm#Encipher">enciphered</A> along
	with the data. When the message is <A HREF="Glossary.htm#Decipher">deciphered</A>, if a second CRC operation produces the same
	result, the message can be assumed unchanged.</P>
	<P>Note that a CRC is a fast, <A HREF="Glossary.htm#Linear">linear</A> hash. Messages with particular CRC result values can
	be constructed rather easily. However, if the CRC is hidden behind strong ciphering, an <A HREF="Glossary.htm#Opponent">Opponent</A>
	is unlikely to be able to change the CRC value systematically or effectively. In particular, this means that the
	CRC value will need more protection than a simple <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> <A HREF="Glossary.htm#StreamCipher">stream
	cipher</A> or the exclusive-OR approach to handling short last <A HREF="Glossary.htm#Block">blocks</A> in a <A HREF="Glossary.htm#BlockCipher">block
	cipher</A>.</P>
	<P>A similar approach to message authentication uses a nonlinear cryptographic hash function. These also add a
	computed redundancy to the message, but generally require significantly more computation than a CRC. It is thought
	to be exceedingly difficult to construct messages with a particular cryptographic hash result, so the hash result
	perhaps need not be hidden by encryption.</P>
	<P>One form of cryptographic hash is <A HREF="Glossary.htm#DES">DES</A> <A HREF="Glossary.htm#CBC">CBC</A> mode: using a key different
	than that used for encryption, the final block of ciphertext is the hash of the message. This obviously doubles
	the computation when both encryption and authentication are needed. And since any cryptographic hash is vulnerable
	to <A HREF="Glossary.htm#BirthdayAttack">birthday attacks</A>, the small 64-bit block size implies that we should be able to
	find two different messages with the same hash value by constructing and hashing &quot;only&quot; about 2<SUP>32</SUP>
	different messages.</P>
	<P>Another approach to message authentication is to use an <A HREF="Glossary.htm#AuthenticatingBlockCipher">authenticating
	block cipher</A>; this is often a <A HREF="Glossary.htm#BlockCipher">block cipher</A> which has a large <A HREF="Glossary.htm#Block">block</A>,
	with some &quot;extra data&quot; inserted in an &quot;authentication field&quot; as part of the plaintext before
	enciphering each block. The &quot;extra data&quot; can be some transformation of the key, the plaintext, and/or
	a sequence number. This essentially creates a <A HREF="Glossary.htm#Homophonic">homophonic</A> block cipher: If we know the
	key, many different ciphertexts will produce the same plaintext field, but only one of those will have the correct
	authentication field.</P>
	<P>The usual approach to authentication in a <A HREF="Glossary.htm#PublicKeyCipher">public key cipher</A> is to encipher with
	the private key. The resulting ciphertext can then be deciphered by the public key, which anyone can know. Since
	even the wrong key will produce a &quot;deciphered&quot; result, it is also necessary to identify the resulting
	plaintext as a valid message; in general this will also require redundancy in the form of a hash value in the plaintext.
	The process provides no <A HREF="Glossary.htm#Secrecy">secrecy</A>, but only a person with access to the private key could
	have enciphered the message. <A NAME="UserAuthentication"></A>
	<H4>User <A HREF="Glossary.htm#Authentication">Authentication</A></H4>
	<P>The classical approach to user authentication is a <A HREF="Glossary.htm#Password">password</A>; this is &quot;something
	you know.&quot; One can also make use of &quot;something you have&quot; (such as a secure ID card), or &quot;something
	you are&quot; (biometrics).</P>
	<P>The classic problem with passwords is that they must be remembered by ordinary people, and so carry a limited
	amount of uniqueness. Easy-to-remember passwords are often common language phrases, and so often fall to a <A HREF="Glossary.htm#DictionaryAttack">dictionary
	attack</A>. More modern approaches involve using a Diffie-Hellman key exchange, <I>plus</I> the password, thus
	minimizing exposure to a dictionary attack. This does require a program on the user end, however. <A NAME="KeyAuthentication"></A>
	<H4>Key <A HREF="Glossary.htm#Authentication">Authentication</A></H4>
	<P>In <A HREF="Glossary.htm#SecretKeyCipher">secret key ciphers</A>, <A HREF="Glossary.htm#Key">key</A> authentication is <I>inherent</I>
	in <A HREF="Glossary.htm#Security">secure</A> <A HREF="Glossary.htm#KeyDistributionProblem">key distribution</A>.</P>
	<P>In <A HREF="Glossary.htm#PublicKeyCipher">public key ciphers</A>, public keys are exposed and often delivered insecurely.
	But someone who uses the wrong key may unknowingly have &quot;secure&quot; communications with an <A HREF="Glossary.htm#Opponent">Opponent</A>,
	as in a <A HREF="Glossary.htm#ManInTheMiddleAttack">man-in-the-middle attack</A>. It is thus absolutely crucial that public
	keys be authenticated or <I>certified</I> as a separate process. Normally this implies the need for a Certification
	Authority or CA. <A NAME="AuthenticatingBlockCipher"></A></P>
	<P>
	<DT><B>Authenticating Block Cipher</B></DT>
	<DD>A <A HREF="Glossary.htm#BlockCipher">block cipher</A> <A HREF="Glossary.htm#Mechanism">mechanism</A> which inherently contains an <A
	HREF="Glossary.htm#Authentication">authentication</A> value or field. <A NAME="Autokey"></A>
	<P>
	<DT><B>Autokey</B></DT>
	<DD>A cipher whose key is produced by message data. One common form is &quot;ciphertext feedback,&quot; where <A
	HREF="Glossary.htm#Ciphertext">ciphertext</A> is &quot;fed back&quot; into the <A HREF="Glossary.htm#State">state</A> of the <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A> used to produce the <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> for a <A HREF="Glossary.htm#StreamCipher">stream
	cipher</A>. <A NAME="Avalanche"></A>
	<P>
	<DT><B>Avalanche</B></DT>
	<DD>The observed property of a <A HREF="Glossary.htm#BlockCipher">block cipher</A> constructed in <A HREF="Glossary.htm#Layer">layers</A>
	or &quot;<A HREF="Glossary.htm#Round">rounds</A>&quot; with respect to a tiny change in the input. The change of a single input
	bit generally produces multiple bit-changes after one round, many more bit-changes after another round, until,
	eventually, about half of the block will change. An analogy is drawn to an avalanche in snow, where a small initial
	effect can lead to a dramatic result. As originally described by Feistel:
	<BLOCKQUOTE>
		<P>&quot;As the input moves through successive layers the pattern of 1's generated is amplified and results in
		an unpredictable avalanche. In the end the final output will have, on average, half 0's and half 1's . . . .&quot;
		[p.22]
	</BLOCKQUOTE>
	<P>Feistel, H. 1973. Cryptography and Computer Privacy. <I>Scientific American.</I> 228(5): 15-23.</P>
	<P>Also see <A HREF="Glossary.htm#Mixing">mixing</A>, <A HREF="Glossary.htm#Diffusion">diffusion</A>, <A HREF="Glossary.htm#OverallDiffusion">overall
	diffusion</A>, <A HREF="Glossary.htm#StrictAvalancheCriterion">strict avalanche criterion</A>, <A HREF="Glossary.htm#Complete">complete</A>,
	<A HREF="Glossary.htm#S-Box">S-box</A>, and the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#BitChanges'" tppabs="http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#BitChanges">bit changes</A>
	section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages.
	<A NAME="AvalancheEffect"></A></P>
	<P>
	<DT><B>Avalanche Effect</B></DT>
	<DD>The result of <A HREF="Glossary.htm#Avalanche">avalanche</A>. As described by Webster and Tavares:
	<BLOCKQUOTE>
		<P>&quot;For a given transformation to exhibit the avalanche effect, an average of one half of the output bits
		should change whenever a single input bit is complemented.&quot; [p.523]
	</BLOCKQUOTE>
	<P>Webster, A. and S. Tavares. 1985. On the Design of <A HREF="Glossary.htm#S-Box">S-Boxes</A>. <I>Advances in Cryptology --
	CRYPTO '85.</I> 523-534.</P>
	<P>Also see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#BitChanges'" tppabs="http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#BitChanges">bit changes</A> section of
	the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages. <A NAME="BackDoor"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Back Door</B>
	<DD>A <A HREF="Glossary.htm#Cipher">cipher</A> design fault, planned or accidental, which allows the apparent strength of the
	design to be easily avoided by those who know the trick. When the design background of a cipher is kept secret,
	a back door is often suspected. Similar to <A HREF="Glossary.htm#TrapDoor">trap door</A>. <A NAME="Balance"></A>
	<P>
	<DT><B>Balance</B></DT>
	<DD>A term used in <A HREF="Glossary.htm#S-Box">S-box</A> and <A HREF="Glossary.htm#BooleanFunction">Boolean function</A> analysis. As
	described by Lloyd:
	<BLOCKQUOTE>
		<P>&quot;A function is balanced if, when all input vectors are equally likely, then all output vectors are equally
		likely.&quot;
	</BLOCKQUOTE>
	<P>Lloyd, S. 1990. Properties of binary functions. <I>Advances in Cryptology -- EUROCRYPT '90.</I> 124-139.</P>
	<P>There is some desire to generalize this definition to describe multiple-input functions. (Is a function &quot;balanced&quot;
	if, for one value on the first input, all output values can be produced, but for another value on the first input,
	only <I>some</I> output values are possible?) Presumably a two-input balanced function would be balanced for either
	input fixed at any value, which would essentially be a <A HREF="Glossary.htm#LatinSquare">Latin square</A> or a <A HREF="Glossary.htm#LatinSquareCombiner">Latin
	square combiner</A>. <A NAME="BalancedBlockMixer"></A></P>
	<P>
	<DT><B>Balanced Block Mixer</B></DT>
	<DD>A process or any implementation (for example, <A HREF="Glossary.htm#Hardware">hardware</A>, <A HREF="Glossary.htm#Computer">computer</A>
	<A HREF="Glossary.htm#Software">software</A>, hybrids, or the like) for performing <A HREF="Glossary.htm#BalancedBlockMixing">Balanced
	Block Mixing</A>. <A NAME="BalancedBlockMixing"></A>
	<P>
	<DT><B>Balanced Block Mixing</B></DT>
	<DD>The <A HREF="Glossary.htm#Block">block</A> <A HREF="Glossary.htm#Mixing">mixing</A> <A HREF="Glossary.htm#Mechanism">mechanism</A> described in
	U.S. Patent 5,623,549 (see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#BBMTech'" tppabs="http://www.io.com/~ritter/#BBMTech">BBM articles</A> on the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page).
	<P>A <A HREF="Glossary.htm#Balance">Balanced</A> Block Mixer is an <I>m</I>-input-port <I>m</I>-output-port mechanism with
	various properties:
	<OL>
		<P>
		<LI>The overall mapping is one-to-one and invertible: Every possible input value (over all ports) to the mixer
		produces a different output value (including all ports), and every possible output value is produced by a different
		input value;
		<P>
		<LI>Each output port is a function of every input port;
		<P>
		<LI>Any change to any one of the input ports will produce a change to every output port;
		<P>
		<LI>Stepping any one input port through all possible values (while keeping the other input ports fixed) will step
		every output port through all possible values.
	</OL>
	<P>If we have a two port mixer, with input ports labeled <I>A</I> and <I>B,</I> output ports labeled <I>X</I> and
	<I>Y,</I> and some <A HREF="Glossary.htm#Irreducible">irreducible</A> <A HREF="Glossary.htm#Mod2Polynomial">mod 2 polynomial</A> <I>p</I>
	of degree appropriate to the port size, a Balanced Block Mixer is formed by the equations:
	<BLOCKQUOTE>
		<P>X = 3A + 2B (mod 2)(mod p),<BR>
		Y = 2A + 3B (mod 2)(mod p).
	</BLOCKQUOTE>
	<P>This particular BBM is a self-inverse or <A HREF="Glossary.htm#Involution">involution</A>, and so can be used without change
	whether enciphering or deciphering. One possible value for <I>p</I> for mixing 8-bit values is 100011011.</P>
	<P>Balanced Block Mixing functions probably should be thought of as <A HREF="Glossary.htm#OrthogonalLatinSquares">orthogonal
	Latin squares</A>. For example, here is a tiny nonlinear &quot;2-bit&quot; BBM:</P>
	<PRE>   3 1 2 0   0 3 2 1       30  13  22  01
   0 2 1 3   2 1 0 3   =   02  21  10  33
   1 3 0 2   1 2 3 0       11  32  03  20
   2 0 3 1   3 0 1 2       23  00  31  12
</PRE>
	<P>Suppose we wish to mix (1,3); 1 selects the second row up in both squares, and 3 selects the rightmost column,
	thus selecting (2,0) as the output. Since there is only one occurrence of (2,0) among all entry pairs, this discrete
	mixing function is reversible, as well as being balanced on both inputs.</P>
	<P>Cryptographic advantages of balanced block mixing include the fact that each output is always balanced with
	respect to either input, and that no information is lost in the mixing. This allows us to use balanced block mixing
	as the &quot;butterfly&quot; operations in a <A HREF="Glossary.htm#FastWalshTransform">fast Walsh-Hadamard transform</A> or
	the well-known <A HREF="Glossary.htm#FFT">FFT</A>. By using the mixing patterns of these transforms, we can mix 2<SUP>n</SUP>
	elements such that each input is guaranteed to affect each and every output in a balanced way. And if we use <A
	HREF="Glossary.htm#Key">keying</A> to generate the tables, we can have a way to mix huge blocks in small nonlinear mixing tables
	with overall mixing guarantees.</P>
	<P>Also see <A HREF="Glossary.htm#MixingCipher">Mixing Cipher</A>, <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic Substitution
	Combiner</A>, <A HREF="Glossary.htm#VariableSizeBlockCipher">Variable Size Block Cipher</A>, and the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/ACTIVBBM.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/ACTIVBBM.HTM'" tppabs="http://www.io.com/~ritter/JAVASCRP/ACTIVBBM.HTM">Active
	Balanced Block Mixing in JavaScript</A> page of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By
	Ritter / JavaScript</A> computation pages. <A NAME="BalancedCombiner"></A></P>
	<P>
	<DT><B>Balanced Combiner</B></DT>
	<DD>In the context of <A HREF="Glossary.htm#Cryptography">cryptography</A>, a <A HREF="Glossary.htm#Combiner">combiner</A> <A HREF="Glossary.htm#Mixing">mixes</A>
	two input values into a result value. A balanced combiner must provide a <A HREF="Glossary.htm#Balance">balanced</A> relationship
	between each input and the result.
	<P>In a <I>statically-balanced</I> combiner, any particular result value can be produced by any value on one input,
	simply by selecting some appropriate value for the other input. In this way, knowledge of only the output value
	provides no information -- not even statistical information -- about either input.</P>
	<P>The common examples of cryptographic combiner, including byte <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> (<A HREF="Glossary.htm#Mod2">mod
	2</A> <A HREF="Glossary.htm#Polynomial">polynomial</A> addition), byte addition (integer addition <A HREF="Glossary.htm#Modulo">mod</A>
	256), or other <A HREF="Glossary.htm#AdditiveCombiner">&quot;additive&quot; combining</A>, are perfectly balanced. Unfortunately,
	these simple combiners are also very weak, being inherently <A HREF="Glossary.htm#Linear">linear</A> and without internal <A
	HREF="Glossary.htm#State">state</A>.</P>
	<P>A <A HREF="Glossary.htm#LatinSquareCombiner">Latin square combiner</A> is an example of a statically-balanced reversible
	nonlinear combiner with massive internal state. A <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic Substitution Combiner</A>
	is an example of a dynamically or statistically-balanced reversible nonlinear combiner with substantial internal
	state. <A NAME="Base64"></A></P>
	<P>
	<DT><B>Base-64</B></DT>
	<DD>A public <A HREF="Glossary.htm#Code">code</A> for converting between 6-<A HREF="Glossary.htm#Bit">bit</A> values 0..63 (or 00..3f <A
	HREF="Glossary.htm#Hexadecimal">hex</A>) and text symbols accepted by most computers:
	<PRE>        0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f

   0    A  B  C  D  E  F  G  H  I  J  K  L  M  N  O  P
   1    Q  R  S  T  U  V  W  X  Y  Z  a  b  c  d  e  f
   2    g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v
   3    w  x  y  z  0  1  2  3  4  5  6  7  8  9  +  /

   use &quot;=&quot; for padding
</PRE>
	<A NAME="Bel"></A>
	<P>
	<DT><B>Bel</B></DT>
	<DD>The base-10 logarithm of the ratio of two <A HREF="Glossary.htm#Power">power</A> values (which is also the same as the
	difference between the log of each power value). The basis for the more-common term <A HREF="Glossary.htm#Decibel">decibel</A>:
	One bel equals 10 decibels. <A NAME="BentFunction"></A>
	<P>
	<DT><B>Bent Function</B></DT>
	<DD>A bent function is a <A HREF="Glossary.htm#BooleanFunction">Boolean function</A> whose <A HREF="Glossary.htm#FastWalshTransform">fast
	Walsh transform</A> has the same absolute value in each term (except, possibly, the zeroth). This means that the
	bent function has the same <A HREF="Glossary.htm#HammingDistance">distance</A> from every possible <A HREF="Glossary.htm#AffineBooleanFunction">affine
	Boolean function</A>.
	<P>We can do FWT's in &quot;the bottom panel&quot; at the end of <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM'" tppabs="http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM">Active
	Boolean Function Nonlinearity Measurement in JavaScript</A> page of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers
	By Ritter / JavaScript</A> computation pages.</P>
	<P>Here is every bent sequence of length 4, first in {0,1} notation, then in {1,-1} notation, with their FWT results:</P>
	<PRE>   bent {0,1}       FWT           bent {1,-1}       FWT

   0  0  0  1    1 -1 -1  1        1  1  1 -1    2  2  2 -2
   0  0  1  0    1  1 -1 -1        1  1 -1  1    2 -2  2  2
   0  1  0  0    1 -1  1 -1        1 -1  1  1    2  2 -2  2
   1  0  0  0    1  1  1  1       -1  1  1  1    2 -2 -2 -2
   1  1  1  0    3  1  1 -1       -1 -1 -1  1   -2 -2 -2  2
   1  1  0  1    3 -1  1  1       -1 -1  1 -1   -2  2 -2  2
   1  0  1  1    3  1 -1  1       -1  1 -1 -1   -2 -2  2 -2
   0  1  1  1    3 -1 -1 -1        1 -1 -1 -1   -2  2  2  2
</PRE>
	These sequences, like all true bent sequences, are <B>not</B> <A HREF="Glossary.htm#Balance">balanced</A>, and the zeroth element
	of the {0,1} FWT is the number of 1's in the sequence.
	<P>Here are some bent sequences of length 16:</P>
	<PRE>   bent {0,1}    0 1 0 0   0 1 0 0   1 1 0 1   0 0 1 0
    FWT          6,-2,2,-2,2,-2,2,2,-2,-2,2,-2,-2,2,-2,-2
   bent {1,-1}   1 -1 1 1   1 -1 1 1   -1 -1 1 -1   1 1 -1 1
    FWT          4,4,-4,4,-4,4,-4,-4,4,4,-4,4,4,-4,4,4

   bent {0,1}    0 0 1 0   0 1 0 0   1 0 0 0   1 1 1 0
    FWT          6,2,2,-2,-2,2,-2,2,-2,-2,-2,-2,2,2,-2,-2
   bent {1,-1}   1 1 -1 1   1 -1 1 1   -1 1 1 1   -1 -1 -1 1
    FWT          4,-4,-4,4,4,-4,4,-4,4,4,4,4,-4,-4,4,4
</PRE>
	<P>Bent sequences are said to have the highest possible uniform nonlinearity. But, to put this in perspective,
	recall that we <I>expect</I> a random sequence of 16 bits to have 8 bits different from any particular sequence,
	linear or otherwise. That is also the <I>maximum possible</I> nonlinearity, and here we actually <I>get</I> a nonlinearity
	of 6.</P>
	<P>There are various more or less complex constructions for these sequences. In most cryptographic uses, bent sequences
	are modified slightly to achieve balance. <A NAME="BernoulliTrials"></A></P>
	<P>
	<DT><B>Bernoulli Trials</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, observations or sampling with replacement which has exactly two possible
	outcomes, typically called &quot;success&quot; and &quot;failure.&quot; Bernoulli trials have these characteristics:
	<UL>
		<LI>Each trial is independent,
		<LI>Each outcome is determined only by chance, and
		<LI>The probability of success is fixed.
	</UL>
	<P>Bernoulli trials have a <A HREF="Glossary.htm#BinomialDistribution">Binomial distribution</A>. <A NAME="Bijective"></A></P>
	<P>
	<DT><B>Bijective</B></DT>
	<DD>A <A HREF="Glossary.htm#Mapping">mapping</A> f: <I>X -&gt; Y</I> which is both <A HREF="Glossary.htm#OneToOne">one-to-one</A> and <A
	HREF="Glossary.htm#Onto">onto</A>. For each unique <I>x</I> in <I>X</I> there is corresponding unique <I>y</I> in <I>Y</I>.
	An invertible mapping function. <A NAME="Binary"></A>
	<P>
	<DT><B>Binary</B></DT>
	<DD>From the Latin for &quot;dual&quot; or &quot;pair.&quot; Dominantly used to indicate &quot;base 2&quot;: The
	numerical representation in which each digit has an <A HREF="Glossary.htm#Alphabet">alphabet</A> of only two symbols: 0 and
	1. This is just one particular <A HREF="Glossary.htm#Code">coding</A> or representation of a value which might otherwise be
	represented (with the exact same value) as <A HREF="Glossary.htm#Octal">octal</A> (base 8), <A HREF="Glossary.htm#Decimal">decimal</A>
	(base 10), or <A HREF="Glossary.htm#Hexadecimal">hexadecimal</A> (base 16). Also see <A HREF="Glossary.htm#Bit">bit</A> and <A HREF="Glossary.htm#Boolean">Boolean</A>.
	<P>Possibly also the confusing counterpart to <A HREF="Glossary.htm#Unary">unary</A> when describing the number of inputs or
	arguments to a function, but <A HREF="Glossary.htm#Dyadic">dyadic</A> is almost certainly a better choice. <A NAME="BinomialDistribution"></A></P>
	<P>
	<DT><B>Binomial Distribution</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the probability of finding exactly <I>k</I> successes in <I>n</I>
	independent <A HREF="Glossary.htm#BernoulliTrials">Bernoulli trials</A>, when each trial has success probability <I>p</I>:
	<PRE>               n    k      n-k
   P(k,n,p) = ( )  p  (1-p)
               k
</PRE>
	<P>This ideal <A HREF="Glossary.htm#Distribution">distribution</A> is produced by evaluating the probability function for all
	possible <I>k,</I> from 0 to <I>n.</I></P>
	<P>If we have an experiment which we think <I>should</I> produce a binomial distribution, and then repeatedly and
	systematically find very improbable test values, we may choose to reject the <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>
	that the experimental distribution is in fact binomial.</P>
	<P>Also see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#Binomial'" tppabs="http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#Binomial">binomial</A> section of the
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages. <A NAME="BirthdayAttack"></A></P>
	<P>
	<DT><B>Birthday Attack</B></DT>
	<DD>A form of <A HREF="Glossary.htm#Attack">attack</A> in which it is necessary to obtain two identical values from a large
	<A HREF="Glossary.htm#Population">population</A>. The &quot;birthday&quot; part is the realization that it is far easier to
	find an arbitrary matching pair than to match any particular value. Often a <A HREF="Glossary.htm#Hash">hash</A> attack.
	<P>Also see: <A HREF="Glossary.htm#BirthdayParadox">birthday paradox</A>. <A NAME="BirthdayParadox"></A></P>
	<P>
	<DT><B>Birthday Paradox</B></DT>
	<DD>The apparent paradox that, in a schoolroom of only 23 students, there is a 50 percent probability that at least
	two will have the same birthday. The &quot;paradox&quot; is that we have an even chance of success with at most
	23 different days represented.
	<P>The &quot;paradox&quot; is resolved by noting that we have a 1/365 chance of success for each possible <I>pairing</I>
	of students, and there are 253 possible pairs or <A HREF="Glossary.htm#Combination">combinations</A> of 23 things taken 2 at
	a time. (To count the number of pairs, we can choose any of the 23 students as part of the pair, then any of the
	22 remaining students as the other part. But this counts each pair twice, so we have <NOBR>23 * 22 / 2 = 253</NOBR>
	different pairs.)</P>
	<P>We can compute the overall probability of success from the probability of <I>failure</I> <NOBR>(1 - 1/365 =
	0.99726)</NOBR> multiplied by itself for each pair. The overall probability of failure is thus 0.99726<SUP>253</SUP>
	(0.99726 to the 253rd power) or 0.4995. So the success probability for 253 pairs is 0.5005.</P>
	<P>We can relate the probability of finding at least one &quot;double&quot; of some birthday (Pd) to the expected
	number of doubles (Ed) as:</P>
	<PRE>   <BIG><TTY>Pd = 1 - e<SUP>-Ed</SUP></TTY></BIG>  ,

so

   <BIG><TTY>Ed = -Ln( 1 - Pd )</TTY></BIG>

and

   <BIG><TTY>365 * -Ln( 0.5 ) = 365 * 0.693 = 253</TTY></BIG>  .
</PRE>
	<P>Also see: <A HREF="javascript:if(confirm('http://christalmirror.ifrance.com/assembly/dossier10/fichiers/ARTS/BIRTHDAY.HTM  \n\nThis file was not retrieved by Teleport Pro, because the server reports that this file cannot be found.  \n\nDo you want to open it from the server?'))window.location='http://christalmirror.ifrance.com/assembly/dossier10/fichiers/ARTS/BIRTHDAY.HTM'" tppabs="http://christalmirror.ifrance.com/assembly/dossier10/fichiers/ARTS/BIRTHDAY.HTM">Estimating Population from Repetitions in Accumulated Random Samples</A>,
	my &quot;birthday&quot; article. <A NAME="Bit"></A></P>
	<P>
	<DT><B>Bit</B></DT>
	<DD>A contraction of &quot;<A HREF="Glossary.htm#Binary">binary</A> digit.&quot; The smallest possible unit of information.
	A <A HREF="Glossary.htm#Boolean">Boolean</A> value: True or False; Yes or No; one or zero; Set or Cleared. Virtually all information
	to be communicated or stored digitally is <A HREF="Glossary.htm#Code">coded</A> in some way which fundamentally relies on individual
	bits. Alphabetic characters are often stored in eight bits, which is a <A HREF="Glossary.htm#Byte">byte</A>. <A NAME="Block"></A>
	<P>
	<DT><B>Block</B></DT>
	<DD>Some amount of data treated as a single unit. For example, the <A HREF="Glossary.htm#DES">DES</A> <A HREF="Glossary.htm#BlockCipher">block
	cipher</A> has a 64-<A HREF="Glossary.htm#Bit">bit</A> block. So DES ciphers 64 bits (8 <A HREF="Glossary.htm#Byte">bytes</A> or typically
	8 <A HREF="Glossary.htm#ASCII">ASCII</A> characters) at once.
	<P>A 64-bit block supports 2<SUP>64</SUP> or about <NOBR>1.8 x 10<SUP>19</SUP></NOBR> block values or code values.
	Each different <A HREF="Glossary.htm#Permutation">permutation</A> of those values can be considered a complete <A HREF="Glossary.htm#Code">code</A>.
	A block cipher has the ability to select from among many such codes using a <A HREF="Glossary.htm#Key">key</A>.</P>
	<P>It is not normally possible to block-cipher just a single <A HREF="Glossary.htm#Bit">bit</A> or a single <A HREF="Glossary.htm#Byte">byte</A>
	of a block. An arbitrary stream of data can always be partitioned into one or more fixed-size blocks, but it is
	likely that at least one block will not be completely filled. Using fixed-size blocks generally means that the
	associated system must support data expansion in enciphering, if only by one block. Handling even minimal data
	expansion may be difficult in some systems. <A NAME="BlockCipher"></A></P>
	<P>
	<DT><B>Block Cipher</B></DT>
	<DD>A <A HREF="Glossary.htm#Cipher">cipher</A> which requires the accumulation of data (in a <A HREF="Glossary.htm#Block">block</A>) before
	ciphering can complete. Other than simple <A HREF="Glossary.htm#Transposition">transposition</A> ciphers, this seems to be
	the province of ciphers designed to <I>emulate</I> a <A HREF="Glossary.htm#Key">keyed</A> <A HREF="Glossary.htm#SimpleSubstitution">simple
	substitution</A> with a <A HREF="Glossary.htm#SubstitutionTable">table</A> of size far too large to realize. A block cipher
	operates on a <A HREF="Glossary.htm#Block">block</A> of data (for example, multiple <A HREF="Glossary.htm#Byte">bytes</A>) in a single
	ciphering, as opposed to a <A HREF="Glossary.htm#StreamCipher">stream cipher</A>, which operates on bytes or <A HREF="Glossary.htm#Bit">bits</A>
	as they occur. Block ciphers can be called &quot;<A HREF="Glossary.htm#Codebook">codebook</A>-style&quot; ciphers. Also see
	<A HREF="Glossary.htm#VariableSizeBlockCipher">Variable Size Block Cipher</A>.
	<P>A <A HREF="Glossary.htm#BlockCipher">block cipher</A> is a transformation between <A HREF="Glossary.htm#Plaintext">plaintext</A> block
	values and <A HREF="Glossary.htm#Ciphertext">ciphertext</A> block values, and is thus an emulated <A HREF="Glossary.htm#SimpleSubstitution">simple
	substitution</A> on huge block-wide values. Within a particular block size, both plaintext and ciphertext have
	the same set of possible values, and when the ciphertext values have the same ordering as the plaintext, ciphering
	is obviously ineffective. So <I>effective</I> ciphering depends upon <I>re-arranging</I> the ciphertext values
	from the plaintext ordering, and this is a <A HREF="Glossary.htm#Permutation">permutation</A> of the plaintext values. A block
	cipher is <A HREF="Glossary.htm#Key">keyed</A> by constructing a <I>particular</I> permutation of ciphertext values.
	<H4>Block Cipher Data Diffusion</H4>
	<P>In an ideal block cipher, changing even a single bit of the input block will change all bits of the ciphertext
	result, each with independent probability 0.5. This means that about half of the bits in the output will change
	for any different input block, even for differences of just one bit. This is <A HREF="Glossary.htm#OverallDiffusion">overall
	diffusion</A> and is present in a block cipher, but not in a <A HREF="Glossary.htm#StreamCipher">stream cipher</A>. Data diffusion
	is a simple consequence of the keyed invertible simple substitution nature of the ideal block cipher.</P>
	<P>Improper diffusion of data throughout a block cipher can have serious strength implications. One of the functions
	of data diffusion is to hide the different effects of different internal components. If these effects are not in
	fact hidden, it may be possible to attack each component separately, and break the whole cipher fairly easily.
	<H4>Partitioning Messages into Fixed Size Blocks</H4>
	<P>A large message can be ciphered by partitioning the plaintext into blocks of a size which can be ciphered. This
	essentially creates a stream meta-cipher which repeatedly uses the same block cipher transformation. Of course,
	it is also possible to re-key the block cipher for each and every block ciphered, but this is usually expensive
	in terms of computation and normally unnecessary.</P>
	<P>A message of arbitrary size can always be partitioned into some number of whole blocks, with possibly some space
	remaining in the final block. Since partial blocks cannot be ciphered, some random <A HREF="Glossary.htm#Padding">padding</A>
	can be introduced to fill out the last block, and this naturally expands the ciphertext. In this case it may also
	be necessary to introduce some sort of structure which will indicate the number of valid bytes in the last block.
	<H4>Block Partitioning without Expansion</H4>
	<P>Proposals for using a block cipher supposedly <I>without</I> data expansion may involve creating a tiny <A HREF="Glossary.htm#StreamCipher">stream
	cipher</A> for the last block. One scheme is to re-encipher the ciphertext of the preceding block, and use the
	result as the <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A>. Of course, the cipher designer still needs to
	address the situation of files which are so short that they <I>have</I> no preceding block. Because the one-block
	version is <I>in fact</I> a stream cipher, we must be very careful to never re-use a confusion sequence. But when
	we only <I>have</I> one block, there <I>is</I> no prior block to change as a result of the data. In this case,
	ciphering several very short files could expose those files quickly. Furthermore, it is dangerous to encipher a
	<A HREF="Glossary.htm#CRC">CRC</A> value in such a block, because exclusive-OR enciphering is transparent to the field of mod
	2 polynomials in which the CRC operates. Doing this could allow an Opponent to adjust the message CRC in a known
	way, thus avoiding authentication exposure.</P>
	<P>Another proposal for eliminating data expansion consists of ciphering blocks until the last short block, then
	re-positioning the ciphering window to end at the last of the data, thus re-ciphering part of the prior block.
	This is a form of chaining and establishes a sequentiality requirement which requires that the last block be deciphered
	<I>before</I> the next-to-the-last block. Or we can make enciphering inconvenient and deciphering easy, but one
	way will be a problem. And this approach cannot handle very short messages: its minimum size is one block. Yet
	any general-purpose ciphering routine <I>will</I> encounter short messages. Even worse, if we have a short message,
	we still need to somehow indicate the correct length of the message, and this must expand the message, as we saw
	before. Thus, overall, this seems a somewhat dubious technique.</P>
	<P>On the other hand, it does show a way to chain blocks for authentication in a large-block cipher: We start out
	by enciphering the data in the first block. Then we position the next ciphering to start <I>inside</I> the ciphertext
	of the previous block. Of course this would mean that we would have to decipher the message in reverse order, but
	it would also propagate any ciphertext changes through the end of the message. So if we add an authentication field
	at the end of the message (a keyed value known on both ends), and that value is recovered upon deciphering (this
	will be the first block deciphered) we can authenticate the whole message. But we still need to handle the last
	block padding problem and possibly also the short message problem.
	<H4>Block Size and Plaintext Randomization</H4>
	<P>Ciphering raw plaintext data can be dangerous when the cipher has a small block size. Language plaintext has
	a strong, biased distribution of symbols and ciphering raw plaintext would effectively reduce the number of possible
	plaintexts blocks. Worse, some plaintexts would be vastly more probable than others, and if some <A HREF="Glossary.htm#KnownPlaintextAttack">known
	plaintext</A> were available, the most-frequent blocks might already be known. In this way, small blocks can be
	vulnerable to classic <A HREF="Glossary.htm#CodebookAttack">codebook attacks</A> which build up the ciphertext equivalents
	for many of the plaintext phrases. This sort of attack confronts a particular block size, and for these attacks
	Triple-DES is no stronger than simple DES, because they both have the same block size.</P>
	<P>The usual way of avoiding these problems is to randomize the plaintext block with an <A HREF="Glossary.htm#OperatingMode">operating
	mode</A> such as <A HREF="Glossary.htm#CBC">CBC</A>. This can ensure that the plaintext data which is actually ciphered is
	evenly distributed across all possible block values. However, this also requires an <A HREF="Glossary.htm#IV">IV</A> which
	thus expands the ciphertext.</P>
	<P>Another approach is to apply data compression to the plaintext before enciphering. If this is to be used <I>instead</I>
	of plaintext randomization, the designer must be very careful that the data compression does not contain regular
	features which could be exploited by The Opponents.</P>
	<P>An alternate approach is to use blocks of sufficient size for them to be expected to have a substantial amount
	of uniqueness or &quot;entropy.&quot; If we expect plaintext to have about one bit of entropy per byte of text,
	we might want a block size of at least 64 bytes before we stop worrying about an uneven distribution of plaintext
	blocks. This is now a practical block size. <A NAME="Boolean"></A></P>
	<P>
	<DT><B>Boolean</B></DT>
	<DD>TRUE or FALSE; one <A HREF="Glossary.htm#Bit">bit</A> of information. <A NAME="BooleanFunction"></A>
	<P>
	<DT><B>Boolean Function</B></DT>
	<DD>A function which produces a <A HREF="Glossary.htm#Boolean">Boolean</A> result. The individual output <A HREF="Glossary.htm#Bit">bits</A>
	of an <A HREF="Glossary.htm#S-Box">S-box</A> can each be considered to be separate Boolean functions. <A NAME="BooleanFunctionNonlinearity"></A>
	<P>
	<DT><B>Boolean Function Nonlinearity</B></DT>
	<DD>The number of <A HREF="Glossary.htm#Bit">bits</A> which must change in the <A HREF="Glossary.htm#TruthTable">truth table</A> of a <A
	HREF="Glossary.htm#BooleanFunction">Boolean function</A> to reach the closest <A HREF="Glossary.htm#AffineBooleanFunction">affine Boolean
	function</A>. This is the <A HREF="Glossary.htm#HammingDistance">Hamming distance</A> from the closest &quot;<A HREF="Glossary.htm#Linear">linear</A>&quot;
	function.
	<P>Typically computed by using a <A HREF="Glossary.htm#FastWalshTransform">fast Walsh-Hadamard transform</A> on the <A HREF="Glossary.htm#Boolean">Boolean</A>-valued
	truth table of the function. This produces the <A HREF="Glossary.htm#UnexpectedDistance">unexpected distance</A> to every possible
	affine Boolean function (of the given length). Scanning those results for the maximum value implies the minimum
	distance to some particular affine sequence.</P>
	<P>Especially useful in <A HREF="Glossary.htm#S-Box">S-box</A> analysis, where the nonlinearity for the <A HREF="Glossary.htm#SubstitutionTable">table</A>
	is often taken to be the minimum of the nonlinearity values computed for each output bit.</P>
	<P>Also see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM'" tppabs="http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM">Active Boolean Function Nonlinearity
	Measurement in JavaScript</A> page of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A>
	computation pages. <A NAME="BooleanLogic"></A></P>
	<P>
	<DT><B>Boolean Logic</B></DT>
	<DD>The <A HREF="Glossary.htm#Logic">logic</A> which applies to variables which have only two possible values. Also the <A
	HREF="Glossary.htm#Digital">digital</A> <A HREF="Glossary.htm#Hardware">hardware</A> devices which realize such logic, and are used to
	implement a <A HREF="Glossary.htm#Electronic">electronic</A> digital <A HREF="Glossary.htm#Computer">computers</A>. <A NAME="BooleanMapping"></A>
	<P>
	<DT><B>Boolean Mapping</B></DT>
	<DD>A <A HREF="Glossary.htm#Mapping">mapping</A> of some number <I>n</I> <A HREF="Glossary.htm#Boolean">Boolean</A> variables into some
	number <I>m</I> Boolean results. For example, an <A HREF="Glossary.htm#S-Box">S-box</A>. <A NAME="Break"></A>
	<P>
	<DT><B>Break</B></DT>
	<DD>The result of a successful <A HREF="Glossary.htm#Cryptanalysis">cryptanalytic</A> <A HREF="Glossary.htm#Attack">attack</A>. To destroy
	the advantage of a <A HREF="Glossary.htm#Cipher">cipher</A> in hiding information.
	<P>A <A HREF="Glossary.htm#Cipher">cipher</A> is &quot;broken&quot; when the information in a message can be extracted without
	the <A HREF="Glossary.htm#Key">key</A>, or when the key itself can be recovered. The <A HREF="Glossary.htm#Strength">strength</A> of a
	cipher can be considered to be the minimum effort required for a break, by any possible attack. A break is particularly
	significant when the work involved need not be repeated on every message.</P>
	<P>The use of the term &quot;break&quot; can be misleading when an impractical amount of work is required to achieve
	the break. This case might be better described a &quot;theoretical&quot; or &quot;certificational&quot; <I>weakness</I>.
	<A NAME="BlockSize"></A></P>
	<P>
	<DT><B>Block Size</B></DT>
	<DD>The amount of data in a <A HREF="Glossary.htm#Block">block</A>. For example, the size of the <A HREF="Glossary.htm#DES">DES</A> block
	is 64 <A HREF="Glossary.htm#Bit">bits</A> or 8 <A HREF="Glossary.htm#Byte">bytes</A> or 8 octets. <A NAME="BruteForceAttack"></A>
	<P>
	<DT><B>Brute Force Attack</B></DT>
	<DD>A form of <A HREF="Glossary.htm#Attack">attack</A> in which each possibility is tried until success is obtained. Typically,
	a <A HREF="Glossary.htm#Ciphertext">ciphertext</A> is <A HREF="Glossary.htm#Decipher">deciphered</A> under different <A HREF="Glossary.htm#Key">keys</A>
	until <A HREF="Glossary.htm#Plaintext">plaintext</A> is recognized. On average, this may take about half as many decipherings
	as there are keys.
	<P>Recognizing plaintext may or may not be easy. Even when the key length of a cipher is sufficient to prevent
	brute force attack, that key will be far too small to produce every possible plaintext from a given ciphertext
	(see <A HREF="Glossary.htm#PerfectSecrecy">perfect secrecy</A>). Combined with the fact that language is redundant, this means
	that very few of the decipherings will be words in proper form. Of course, if the plaintext is not language, but
	is instead computer code, compressed text, or even ciphertext from another cipher, recognizing a correct deciphering
	can be difficult.</P>
	<P>Brute force is the obvious way to attack a cipher, and the way any cipher can be attacked, so ciphers are designed
	to have a large enough <A HREF="Glossary.htm#Keyspace">keyspace</A> to make this much too expensive to use in practice. Normally,
	the design <A HREF="Glossary.htm#Strength">strength</A> of a cipher is based on the cost of a brute-force attack. <A NAME="Bug"></A></P>
	<P>
	<DT><B>Bug</B></DT>
	<DD>Technical slang for &quot;error in design or implementation.&quot; An unexpected <A HREF="Glossary.htm#System">system</A>
	flaw. <A HREF="Glossary.htm#Debug">Debugging</A> is a normal part of system development and interactive <A HREF="Glossary.htm#SystemDesign">system
	design</A>. <A NAME="Byte"></A>
	<P>
	<DT><B>Byte</B></DT>
	<DD>A collection of eight <A HREF="Glossary.htm#Bit">bits</A>. Also called an &quot;octet.&quot; A byte can represent 256 different
	values or symbols. The common 7-bit <A HREF="Glossary.htm#ASCII">ASCII</A> codes used to represent characters in <A HREF="Glossary.htm#Computer">computer</A>
	use are generally stored in a byte; that is, one byte per character. <A NAME="Capacitor"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Capacitor</B>
	<DD>A basic <A HREF="Glossary.htm#Electronic">electronic</A> <A HREF="Glossary.htm#Component">component</A> which acts as a reservoir for
	electrical power in the form of <A HREF="Glossary.htm#Voltage">voltage</A>. A capacitor thus acts to &quot;even out&quot; the
	voltage across its terminals, and to &quot;conduct&quot; voltage changes from one terminal to the other. A capacitor
	&quot;blocks&quot; <A HREF="Glossary.htm#DC">DC</A> and conducts <A HREF="Glossary.htm#AC">AC</A> in proportion to <A HREF="Glossary.htm#Frequency">frequency</A>.
	Capacitance is measured in Farads: A <A HREF="Glossary.htm#Current">current</A> of 1 Amp into a capacitance of 1 Farad produces
	a voltage change of 1 Volt per Second across the capacitor.
	<P>Typically, two <A HREF="Glossary.htm#Conductor">conductive</A> &quot;plates&quot; or metal foils separated by a thin <A
	HREF="Glossary.htm#Insulator">insulator</A>, such as air, paper, or ceramic. An electron charge on one plate attracts the opposite
	charge on the other plate, thus &quot;storing&quot; charge. A capacitor can be used to collect a small current
	over long time, and then release a high current for a short time, as used in a camera strobe or &quot;flash.&quot;</P>
	<P>Also see <A HREF="Glossary.htm#Inductor">inductor</A> and <A HREF="Glossary.htm#Resistor">resistor</A>. <A NAME="CBC"></A></P>
	<P>
	<DT><B>CBC</B></DT>
	<DD>CBC or Cipher Block Chaining is an <A HREF="Glossary.htm#OperatingMode">operating mode</A> for <A HREF="Glossary.htm#BlockCipher">block
	ciphers</A>. CBC mode is essentially a crude meta-<A HREF="Glossary.htm#StreamCipher">stream cipher</A> which streams block
	transformations.
	<P>In CBC mode the <A HREF="Glossary.htm#Ciphertext">ciphertext</A> value of the preceding <A HREF="Glossary.htm#Block">block</A> is <A
	HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> combined with the <A HREF="Glossary.htm#Plaintext">plaintext</A> value for the current
	block. This has the effect of distributing the combined block values evenly among all possible block values, and
	so prevents <A HREF="Glossary.htm#CodebookAttack">codebook attacks</A>.</P>
	<P>On the other hand, ciphering the <I>first</I> block generally requires an <A HREF="Glossary.htm#IV">IV</A> or initial value
	to start the process. The IV necessarily expands the ciphertext, which may or may not be a problem. And the IV
	must be dynamically random-like so that statistics cannot be developed on the first block of each message sent
	under the same key.</P>
	<P>In CBC mode, each random-like confusing value is the ciphertext from each previous block. Clearly this ciphertext
	is exposed to The Opponent, so there would seem to be little benefit associated with hiding the IV, which is just
	the first of these values. But if The Opponent knows the first sent plaintext, and can intercept and change the
	message IV, The Opponent can manipulate the first block of received plaintext. Because the IV does not represent
	a message enciphering, manipulating this value does not also change any previous block.</P>
	<P>Accordingly, the IV may be sent enciphered or may be specifically authenticated in some way. Alternately, the
	complete body of the plaintext message may be <A HREF="Glossary.htm#Authentication">authenticated</A>, often by a <A HREF="Glossary.htm#CRC">CRC</A>.
	The CRC remainder should be block ciphered, perhaps as part of the plaintext. <A NAME="cdf"></A></P>
	<P>
	<DT><B>c.d.f.</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, <I>cumulative <A HREF="Glossary.htm#Distribution">distribution</A> function.</I>
	A function which gives the probability of obtaining a particular value or lower. <A NAME="CFB"></A>
	<P>
	<DT><B>CFB</B></DT>
	<DD>CFB or Ciphertext FeedBack is an <A HREF="Glossary.htm#OperatingMode">operating mode</A> for a <A HREF="Glossary.htm#BlockCipher">block
	cipher</A>.
	<P>CFB is closely related to <A HREF="Glossary.htm#OFB">OFB</A>, and is intended to provide some of the characteristics of
	a <A HREF="Glossary.htm#StreamCipher">stream cipher</A> from a block cipher. CFB generally forms an <A HREF="Glossary.htm#Autokey">autokey</A>
	stream cipher. CFB is a way of using a block cipher to form a <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>.
	The resulting <A HREF="Glossary.htm#PseudoRandom">pseudorandom</A> <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> can
	be <A HREF="Glossary.htm#Combiner">combined</A> with data as in the usual stream cipher.</P>
	<P>CFB assumes a <A HREF="Glossary.htm#ShiftRegister">shift register</A> of the block cipher <A HREF="Glossary.htm#Block">block</A> size.
	An <A HREF="Glossary.htm#IV">IV</A> or initial value first fills the register, and then is ciphered. Part of the result, often
	just a single <A HREF="Glossary.htm#Byte">byte</A>, is used to cipher data, and the resulting <A HREF="Glossary.htm#Ciphertext">ciphertext</A>
	is also shifted into the register. The new register value is ciphered, producing another confusion value for use
	in stream ciphering.</P>
	<P>One disadvantage of this, of course, is the need for a full block-wide ciphering operation, typically for each
	data byte ciphered. The advantage is the ability to cipher individual characters, instead of requiring accumulation
	into a block before processing. <A NAME="Chain"></A></P>
	<P>
	<DT><B>Chain</B></DT>
	<DD>An operation repeated in a sequence, such that each result depends upon the previous result, or an <A HREF="Glossary.htm#IV">initial
	value</A>. One example is the <A HREF="Glossary.htm#CBC">CBC</A> operating mode. <A NAME="Chaos"></A>
	<P>
	<DT></DT>
	<P><B>Chaos</B>
	<DD>The unexpected ability to find numerical relationships in physical processes formerly considered <A HREF="Glossary.htm#Random">random</A>.
	Typically these take the form of iterative applications of fairly simple computations. In a chaotic system, even
	tiny changes in <A HREF="Glossary.htm#State">state</A> eventually lead to major changes in state; this is called &quot;sensitive
	dependence on initial conditions.&quot; It has been argued that every good computational <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A> is &quot;chaotic&quot; in this sense.
	<P>In physics, the &quot;state&quot; of an <A HREF="Glossary.htm#Analog">analog</A> physical system cannot be fully measured,
	which always leaves some remaining uncertainty to be magnified on subsequent steps. And, in many cases, a physical
	system may be slightly affected by thermal noise and thus continue to accumulate new information into its &quot;state.&quot;</P>
	<P>In a <A HREF="Glossary.htm#Computer">computer</A>, the state of the <A HREF="Glossary.htm#Digital">digital</A> <A HREF="Glossary.htm#System">system</A>
	is explicit and complete, and there is no uncertainty. No noise is accumulated. All operations are completely <A
	HREF="Glossary.htm#Deterministic">deterministic</A>. This means that, in a computer, even a &quot;chaotic&quot; computation
	is completely predictable and repeatable. <A NAME="ChiSquare"></A></P>
	<P>
	<DT><B>Chi-Square</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a <A HREF="Glossary.htm#GoodnessOfFit">goodness of fit</A> test used for comparing
	two <A HREF="Glossary.htm#Distribution">distributions</A>. Mainly used on <A HREF="Glossary.htm#Nominal">nominal</A> and <A HREF="Glossary.htm#Ordinal">ordinal</A>
	measurements. Also see: <A HREF="Glossary.htm#KolmogorovSmirnov">Kolmogorov-Smirnov</A>.
	<P>In the usual case, many independent samples are counted by category or separated into value-range &quot;bins.&quot;
	The reference distribution gives us the the number of values to expect in each bin. Then we compute a X<SUP>2</SUP>
	test <A HREF="Glossary.htm#Statistic">statistic</A> related to the difference between the distributions:</P>
	<PRE>   X<SUP>2</SUP> = SUM( SQR(Observed[i] - Expected[i]) / Expected[i] )
</PRE>
	<P>(&quot;SQR&quot; is the squaring function, and we require that each expectation not be zero.) Then we use a
	tabulation of chi-square statistic values to look up the probability that a particular X<SUP>2</SUP> value or lower
	(in the <A HREF="Glossary.htm#cdf">c.d.f.</A>) would occur by random sampling if both distributions were the same. The statistic
	also depends upon the &quot;<A HREF="Glossary.htm#DegreesOfFreedom">degrees of freedom</A>,&quot; which is almost always one
	less than the final number of bins. See the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/NORMCHIK.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/NORMCHIK.HTM#ChiSquare'" tppabs="http://www.io.com/~ritter/JAVASCRP/NORMCHIK.HTM#ChiSquare">chi-square</A>
	section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages.</P>
	<P>The <A HREF="Glossary.htm#cdf">c.d.f.</A> percentage for a particular chi-square value is the area of the statistic distribution
	to the left of the statistic value; this is the probability of obtaining that statistic value <I>or less</I> by
	random selection when testing two distributions which are exactly the same. Repeated trials which randomly sample
	two identical distributions should produce about the same number of X<SUP>2</SUP> values in each quarter of the
	distribution (0% to 25%, 25% to 50%, 50% to 75%, and 75% to 100%). So if we repeatedly find only very high percentage
	values, we can assume that we are probing different distributions. And even a single very high percentage value
	would be a matter of some interest.</P>
	<P>Any statistic probability can be expressed either as the proportion of the area to the <I>left</I> of the statistic
	value (this is the &quot;cumulative distribution function&quot; or c.d.f.), or as the area to the <I>right</I>
	of the value (this is the &quot;upper tail&quot;). Using the upper tail representation for the X<SUP>2</SUP> distribution
	can make sense because the usual chi-squared test is a &quot;one tail&quot; test where the decision is always made
	on the upper tail. But the &quot;upper tail&quot; has an opposite &quot;sense&quot; to the c.d.f., where higher
	statistic values always produce higher percentage values. Personally, I find it helpful to describe all statistics
	by their c.d.f., thus avoiding the use of a wrong &quot;polarity&quot; when interpreting any particular statistic.
	While it is easy enough to convert from the c.d.f. to the complement or vise versa (just subtract from 1.0), we
	can base our arguments on either form, since the statistical implications are the same.</P>
	<P>It is often unnecessary to use a statistical test if we just want to know whether a function is producing something
	like the expected distribution: We can <I>look</I> at the binned values and generally get a good idea about whether
	the distributions change in similar ways at similar places. A good rule-of-thumb is to expect chi-square totals
	similar to the number of bins, but distinctly different distributions often produce huge totals far beyond the
	values in any table, and computing an exact probability for such cases is simply irrelevant. On the other hand,
	it can be very useful to perform 20 to 40 independent experiments to look for a reasonable statistic distribution,
	rather than simply making a &quot;yes / no&quot; decision on the basis of what might turn out to be a rather unusual
	result.</P>
	<P>Since we are accumulating <I>discrete</I> bin-counts, any fractional expectation will always differ from any
	actual count. For example, suppose we expect an <A HREF="Glossary.htm#UniformDistribution">even distribution</A>, but have
	many bins and so only accumulate enough samples to observe about 1 count for every 2 bins. In this situation, the
	absolute best sample we could hope to see would be something like (0,1,0,1,0,1,...), which would represent an even,
	balanced distribution over the range. But even in this best possible case we would still be off by half a count
	in each and every bin, so the chi-square result would not properly characterize this best possible sequence. Accordingly,
	we need to accumulate enough samples so that the quantization which occurs in binning does not appreciably affect
	the accuracy of the result. Normally I try to expect at least 10 counts in each bin.</P>
	<P>But when we have a reference distribution that trails off toward zero, <I>inevitably</I> there will be some
	bins with few counts. Taking more samples will just expand the range of bins, some of which will be lightly filled
	in any case. We can avoid quantization error by summing both the observations and expectations from multiple bins,
	until we get a reasonable expectation value (again, I like to see 10 counts or more). In this way, the &quot;tails&quot;
	of the distribution can be more properly (and legitimately) characterized. <A NAME="Cipher"></A></P>
	<P>
	<DT><B>Cipher</B></DT>
	<DD>In general, a <A HREF="Glossary.htm#Key">key</A>-selected secret transformation between <A HREF="Glossary.htm#Plaintext">plaintext</A>
	and <A HREF="Glossary.htm#Ciphertext">ciphertext</A>. Specifically, a secrecy <A HREF="Glossary.htm#Mechanism">mechanism</A> or process
	which operates on individual characters or <A HREF="Glossary.htm#Bit">bits</A> independent of semantic content. As opposed
	to a secret <A HREF="Glossary.htm#Code">code</A>, which generally operates on words, phrases or sentences, each of which may
	carry some amount of complete meaning. Also see: <A HREF="Glossary.htm#Cryptography">cryptography</A>, <A HREF="Glossary.htm#BlockCipher">block
	cipher</A>, <A HREF="Glossary.htm#StreamCipher">stream cipher</A>, <A HREF="Glossary.htm"></A><A HREF="Glossary.htm#CipherTaxonomy"><NOBR>a cipher
	taxonomy</A></A><A HREF="Glossary.htm#CipherTaxonomy"></NOBR></A>, and <A HREF="Glossary.htm#Substitution">substitution</A>.
	<P>A good cipher can transform secret information into a multitude of different intermediate forms, each of which
	represents the original information. <I>Any</I> of these intermediate forms or ciphertexts can be produced by ciphering
	the information under a particular key value. The intent is that the original information only be exposed by <I>one</I>
	of the many possible keyed interpretations of that ciphertext. Yet the correct interpretation is available merely
	by deciphering under the appropriate key.</P>
	<P>A cipher appears to reduce the protection of secret information to enciphering under some key, and then keeping
	that key secret. This is a great reduction of effort and potential exposure, and is much like keeping your valuables
	in your house, and then locking the door when you leave. But there are also similar limitations and potential problems.</P>
	<P>With a good cipher, the resulting ciphertext can be stored or transmitted otherwise exposed without also exposing
	the secret information hidden inside. This means that ciphertext can be stored in, or transmitted through, systems
	which have no secrecy protection. For transmitted information, this also means that the cipher itself must be distributed
	in multiple places, so in general the cipher cannot be assumed to be secret. With a good cipher, only the deciphering
	key need be kept secret. <A NAME="CipherTaxonomy"></A></P>
	<P>
	<DT><B>A Cipher Taxonomy</B></DT>
	<DD>For the analysis of cipher operation it is useful to collect ciphers into groups based on their functioning
	(or <I>intended</I> functioning). The goal is to group ciphers which are <I>essentially similar,</I> so that as
	we gain an understanding of one cipher, we can apply that understanding to others in the same group. We thus classify
	<I>not</I> by the <A HREF="Glossary.htm#Component">components</A> which make up the cipher, but instead on the &quot;black-box&quot;
	operation of the cipher itself.
	<P>We seek to hide distinctions of size, because <I>operation</I> is independent of size, and because size effects
	are usually straightforward. We thus classify serious <A HREF="Glossary.htm#BlockCipher">block ciphers</A> as <A HREF="Glossary.htm#Key">keyed</A>
	<A HREF="Glossary.htm#SimpleSubstitution">simple substitution</A>, just like newspaper amusement ciphers, despite their obvious
	differences in strength and construction. This allows us to compare the results from an ideal tiny cipher to those
	from a large cipher construction; the grouping thus can provide <I>benchmark</I> characteristics for measuring
	large cipher constructions.</P>
	<P>We <I>could</I> of course treat each cipher as an entity unto itself, or relate ciphers by their dates of discovery,
	the tree of developments which produced them, or by known strength. But each of these criteria is more or less
	limited to telling us &quot;this cipher is what it is.&quot; We already know that. What we <I>want</I> to know
	is what other ciphers function in a similar way, and then whatever is known about <I>those</I> ciphers. In this
	way, every cipher need not be an island unto itself, but instead can be judged and compared in a related community
	of similar techniques.</P>
	<P>Our primary distinction is between ciphers which handle all the data at once (<A HREF="Glossary.htm#BlockCipher">block ciphers</A>),
	and those which handle some, then some more, then some more (<A HREF="Glossary.htm#StreamCipher">stream ciphers</A>). We thus
	see the usual repeated use of a block cipher as a stream <I>meta-cipher</I> which has the block cipher as a component.
	It is also possible for a stream cipher to be re-keyed or re-originate frequently, and so appear to operate on
	&quot;blocks.&quot; Such a cipher, however, would not have the <A HREF="Glossary.htm#OverallDiffusion">overall diffusion</A>
	we normally associate with a block cipher, and so might usefully be regarded as a stream meta-cipher with a stream
	cipher component.</P>
	<P>The goal is not to give each cipher a label, but instead to seek insight. Each cipher in a particular general
	class carries with it the consequences of that class. And because these groupings ignore size, we are free to generalize
	from the small to the large and so predict effects which may be unnoticed in full-size ciphers.</P>
	<P>
	<OL Type="A" STYLE="List-Style-Type : Upper-Alpha">
<BIG>
		<LI><B><A HREF="Glossary.htm#BlockCipher">BLOCK CIPHER</A></A></B><A HREF="Glossary.htm"></A><A HREF="Glossary.htm#BlockCipher"></BIG></A> <BR>
		A block cipher <I>requires</I> the accumulation of some amount of data or multiple data elements for ciphering
		to complete. (Sometimes stream ciphers accumulate data for convenience, as in cylinder ciphers, which nevertheless
		logically cipher each character independently.)
		<P>(Note that this definition is somewhat broader than the now common understanding of a huge, and thus <I>emulated,</I>
		Simple Substitution. But there are ciphers which require blocked plaintext and which do <I>not</I> emulate Simple
		Substitution, and calling these something other than &quot;block&quot; ciphers negates the advantage of a taxonomy.)</P>
		<P>
		<OL Type="1" STYLE="List-Style-Type : Decimal">
			<LI><B><A HREF="Glossary.htm#Substitution">SUBSTITUTION</A> CIPHER</B>
			<UL>
				<LI>A &quot;codebook&quot; or &quot;simple substitution.&quot;
				<LI>Each code value becomes a distinguishable element. Thus, substitution generally converts a collection of independent
				elements to a single related unit.
				<LI>Keying constitutes a <A HREF="Glossary.htm#Permutation">permutation</A> or re-arrangement of the fixed set of possible
				<A HREF="Glossary.htm#Code">code</A> values.
				<LI><A HREF="Glossary.htm#Avalanche">Avalanche</A> or data <A HREF="Glossary.htm#Diffusion">diffusion</A> is a natural consequence of an
				arbitrary selection among all possible code values.
				<LI>The usual complete binary substitution distributes bit-changes between code values binomially, and this effect
				can be sampled and examined statistically.
				<LI>Avalanche is two-way diffusion in the sense that &quot;later&quot; plaintext can change &quot;earlier&quot;
				ciphertext.
				<LI>A conventional block cipher is built from small components with a design intended to <I>simulate</I> a substitution
				table of a size vastly larger than anything which could be practically realized.
			</UL>
			<P>
			<OL Type="a" STYLE="List-Style-Type : Lower-Alpha">
				<LI><B><A HREF="Glossary.htm#Transposition">Transposition</A> Cipher</B>
				<UL>
					<LI>Clearly, it is necessary for all message elements which will be transposed to be collected before operations
					begin; this is the block cipher signature.
					<LI>Any possible transposition is necessarily a subset of an arbitrary substitution; thus, transposition can be
					seen as a particular keying subset of substitution.
					<LI>Notice, however, that the usual avalanche signature of substitution is not present, and of course the actual
					data values are not changed at all by transposition, just moved about.
					<LI>Also notice that we are close to using the idea of permutation in two very different ways: first as a particular
					n-bit to n-bit substitution, and second as a particular re-arrangement of characters in the block. These have wildly
					different ciphering effects.
				</UL>
			</OL>
		</OL>
		<P><BIG>
		<LI><B><A HREF="Glossary.htm#StreamCipher">STREAM CIPHER</A></A></B></BIG>
		<UL>
			<LI>A stream cipher does <I>not</I> need to accumulate some amount of data or multiple data elements for ciphering
			to complete. (Since we define only two main &quot;types&quot; of cipher, a stream cipher is the opposite of a block
			cipher and vise versa. It is extremely important that the definitions for block and stream ciphering enclose the
			universe of all possible ciphers.)
			<LI>A stream cipher has the ability to transform individual elements one-by-one. The actual transformation usually
			is a block transformation, and may be repeated with the same or different keying.
			<LI>In a stream cipher, data diffusion may or may not occur, but if it does, it is necessarily one-way (from earlier
			to later elements).
			<LI>Since elements are ciphered one-by-one, changing part of the plaintext can affect that part and possibly <I>later</I>
			parts of the ciphertext; this is a stream cipher signature.
			<LI>The simple re-use of a block transformation to cover more data than a single block is a stream operation.
		</UL>
		<P>
		<OL Type="1" STYLE="List-Style-Type : Decimal">
			<LI><B><A HREF="Glossary.htm#ConfusionSequence">CONFUSION SEQUENCE</A></B>
			<UL>
				<LI>With a truly random sequence, used once, we have a <A HREF="Glossary.htm#OneTimePad">one time pad</A>.
				<LI>With a pseudorandom confusion sequence and a simple additive combiner, we have a Vernam cipher.
				<LI>A simple additive transformation becomes weak upon the second character ciphered, or immediately, under <A
				HREF="Glossary.htm#KnownPlaintextAttack">known plaintext</A>, making strength dependent on the confusion sequence.
				<LI>More complex transformations imply the need for correspondingly less strong confusion sequences.
			</UL>
			<P>
			<OL Type="a" STYLE="List-Style-Type : Lower-Alpha">
				<LI><B>Autokey</B>
				<UL>
					<LI>Normally the use of ciphertext, but also perhaps plaintext, as the cipher key.
					<LI>Can create a random-like confusion stream which will re-synchronize after ciphertext data loss.
					<LI>Under known-plaintext, the common &quot;ciphertext feedback&quot; version exposes both the confusion sequence
					and the input which creates that sequence. This is a lot of pressure on a single transformation.
				</UL>
			</OL>
			<P>
			<LI><B><A HREF="Glossary.htm#MonoalphabeticSubstitution">MONOALPHABETIC</A></B> (e.g., <A HREF="Glossary.htm#DES">DES</A> <A HREF="Glossary.htm#CBC">CBC</A>)
			<UL>
				<LI>The repeated use of a single fixed substitution.
				<LI>A conventional block cipher <I>simulates</I> a large substitution.
				<LI>A substitution becomes weak when its code values are re-used.
				<LI>Code value re-use can be minimized by randomizing the plaintext block (e.g., CBC). This distributes the plaintext
				evenly across the possible block values, but at some point the transformation itself must change or be exposed.
				<LI>Another alternative is to use a very large block so that code value re-use is made exceedingly unlikely. A
				large block also has room for a dynamic keying field which would make code value re-use even more unlikely.
			</UL>
			<P>
			<LI><B><A HREF="Glossary.htm#PolyalphabeticSubstitution">POLYALPHABETIC</A></B>
			<UL>
				<LI>The use of multiple fixed substitutions.
				<LI>By itself, the use of multiple alphabets in a regular sequence is inherently not much stronger than just a
				single alphabet.
				<LI>It is of course possible to select an alphabet or transformation at pseudo-random, for example by re-keying
				DES after every block ciphered. This brings back sequence strength as an issue, and opens up the sequence generator
				starting <A HREF="Glossary.htm#State">state</A> as an <A HREF="Glossary.htm#IV">IV</A>.
				<LI>A related possibility is the use of a <A HREF="Glossary.htm#LatinSquareCombiner">Latin square combiner</A> which effectively
				selects among a balanced set of different fixed substitution alphabets.
			</UL>
			<P>
			<OL Type="a" STYLE="List-Style-Type : Lower-Alpha">
				<LI><B>Cylinder</B>
				<UL>
					<LI>A cipher which has or simulates the use of a number of different alphabet disks on a common rod.
					<LI>Primary keying is the arrangement of the alphabet around each disk, and the selection and arrangement of disks.
					<LI>By entering the plaintext on one row, any of n-1 other rows can be sent as ciphertext; this selection is an
					<A HREF="Glossary.htm#IV">IV</A>.
					<LI>If the plaintext data are redundant, it is possible to avoid sending the IV by selecting the one of n-1 possible
					decipherings which shows redundancy. But this is not generally possible when ciphering arbitrary binary data.
					<LI>If an IV is selected first, each character ciphering in that &quot;chunk&quot; is independent of each other
					ciphering. There is no data <A HREF="Glossary.htm#Diffusion">diffusion</A>.
					<LI>In general, each disk is used at fixed periodic intervals through the text, which is weak.
					<LI>The ciphertext selection is <A HREF="Glossary.htm#Homophonic">homophonic</A>, in the sense that different ciphertext rows
					each represent exactly the same plaintext.
					<LI>Cylinder operation is <B>not</B> <A HREF="Glossary.htm#Polyphonic">polyphonic</A> in the usual sense: While a single ciphertext
					<I>can</I> imply any other row is plaintext, generally only one row has a reasonable plaintext meaning.
				</UL>
			</OL>
			<P>
			<LI><B><A HREF="Glossary.htm#DynamicSubstitutionCombiner">DYNAMIC</A></B>
			<UL>
				<LI>The use of one (monoalphabetic) or multiple (polyalphabetic) substitutions which <I>change</I> during ciphering.
			</UL>
			<P>
			<LI><B>ITERATIVE</B>
			<UL>
				<LI>The iterative re-use of a stream cipher with a new random <A HREF="Glossary.htm#IV">IV</A> on each iteration so as to eventually
				achieve the effect of a <A HREF="Glossary.htm#MessageKey">message key</A>.
				<LI>Each iteration seemingly must expand the ciphertext by the size of the IV, although this is probably about
				the same expansion we would have with a message key.
				<LI>Unfortunately, each iteration will take some time.
			</UL>
		</OL>
	</OL>
	<A NAME="Ciphering"></A>
	<P>
	<DT><B>Ciphering</B></DT>
	<DD>The use of a <A HREF="Glossary.htm#Cipher">cipher</A>. The general term which includes both <A HREF="Glossary.htm#Encipher">enciphering</A>
	and <A HREF="Glossary.htm#Decipher">deciphering</A>. <A NAME="Ciphertext"></A>
	<P>
	<DT><B>Ciphertext</B></DT>
	<DD>The result of <A HREF="Glossary.htm#Encipher">enciphering</A>. Ciphertext will contain the same information as the original
	<A HREF="Glossary.htm#Plaintext">plaintext</A>, but hide the original information, typically under the control of a <A HREF="Glossary.htm#Key">key</A>.
	Without the key it should be impractical to recover the original information from the ciphertext. <A NAME="CiphertextExpansion"></A>
	<P>
	<DT><B>Ciphertext Expansion</B></DT>
	<DD>When the <A HREF="Glossary.htm#Ciphertext">ciphertext</A> is larger than the original <A HREF="Glossary.htm#Plaintext">plaintext</A>.
	<P>Ciphertext expansion is the general situation: <A HREF="Glossary.htm#StreamCipher">Stream ciphers</A> need a <A HREF="Glossary.htm#MessageKey">message
	key</A>, and <A HREF="Glossary.htm#BlockCipher">block ciphers</A> with a small block need some form of plaintext randomization,
	which generally needs an <A HREF="Glossary.htm#IV">IV</A> to protect the first block. Only block ciphers with a large size
	block generally can avoid ciphertext expansion, and then only if each block can be expected to hold sufficient
	uniqueness or &quot;entropy&quot; to prevent a <A HREF="Glossary.htm#CodebookAttack">codebook attack</A>.</P>
	<P>It is certainly true that in most situations of new construction a few extra bytes are not going to be a problem.
	However, in some situations, and especially when a cipher is to be installed into an existing system, the ability
	to encipher data <I>without</I> requiring additional storage can be a big advantage. Ciphering data without expansion
	supports the ciphering of data structures which have been defined and fixed by the rest of the system, provided
	only that one can place the cipher at the interface &quot;between&quot; two parts of the system. This is also especially
	efficient, as it avoids the process of acquiring a different, larger, amount of store for each ciphering. Such
	an installation also can apply to the entire system, and not require the re-engineering of all applications to
	support cryptography in each one. <A NAME="Ciphony"></A></P>
	<P>
	<DT><B>Ciphony</B></DT>
	<DD>Audio or voice <A HREF="Glossary.htm#Encryption">encryption</A>. A contraction of &quot;ciphered telephony.&quot; <A NAME="Circuit"></A>
	<P>
	<DT><B>Circuit</B></DT>
	<DD>The &quot;circular&quot; flow of electrons from a power source, through <A HREF="Glossary.htm#Conductor">conductors</A>
	and <A HREF="Glossary.htm#Component">components</A> and back to the power source. Or the arrangement of components which allows
	such flow and performs some function. <A NAME="Clock"></A>
	<P>
	<DT><B>Clock</B></DT>
	<DD>A repetitive or cyclic timing signal to coordinate <A HREF="Glossary.htm#State">state</A> changes in a <A HREF="Glossary.htm#Digital">digital</A>
	system. A clock can coordinate the movement of data and results through various stages of processing. Although
	a clock signal is digital, the source of the repetitive signal is almost always an <A HREF="Glossary.htm#Analog">analog</A>
	<A HREF="Glossary.htm#Circuit">circuit</A>.
	<P>In an analog system we might produce a known delay by slowly charging a <A HREF="Glossary.htm#Capacitor">capacitor</A> and
	measuring the <A HREF="Glossary.htm#Voltage">voltage</A> across it continuously until the voltage reaches the desired level.
	A big problem with this is that the <A HREF="Glossary.htm#Circuit">circuit</A> becomes increasingly susceptible to noise at
	the end of the interval.</P>
	<P>In a digital system we create a delay by simply counting clock cycles. Since all external operations are digital,
	noise effects are virtually eliminated, and we can easily create accurate delays which are as long as the count
	in any counter we can build. <A NAME="Closed"></A></P>
	<P>
	<DT><B>Closed</B></DT>
	<DD>An operation on a <A HREF="Glossary.htm#Set">set</A> which produces only elements in that set. <A NAME="Code"></A>
	<P>
	<DT><B>Code</B></DT>
	<DD>Symbols or values which stand for symbols, values, sequences, or even operations (as in <A HREF="Glossary.htm#Computer">computer</A>
	&quot;<A HREF="Glossary.htm#Opcode">opcodes</A>&quot;). As opposed to a <A HREF="Glossary.htm#Cipher">cipher</A>, which operates only on
	individual characters or <A HREF="Glossary.htm#Bit">bits</A>, classically, codes also represent words, phrases, and entire
	sentences. One application was to decrease the cost of telegraph messages. In modern usage, a code is often simply
	a correspondence between information (such as character symbols) and values (such as the <A HREF="Glossary.htm#ASCII">ASCII</A>
	code or <A HREF="Glossary.htm#Base64">Base-64</A>), although computer opcodes do have independent meanings and variable lengths.
	<P>Coding is a very basic part of modern computation and generally implies no <A HREF="Glossary.htm#Secrecy">secrecy</A> or
	information hiding. Some codes are &quot;secret codes,&quot; however, and then the transformation between the information
	and the coding is kept secret. Also see: <A HREF="Glossary.htm#Cryptography">cryptography</A> and <A HREF="Glossary.htm#Substitution">substitution</A>.
	<A NAME="Codebook"></A></P>
	<P>
	<DT><B>Codebook</B></DT>
	<DD>Literally, the listing or &quot;book&quot; of <A HREF="Glossary.htm#Code">code</A> transformations. More generally, any
	collection of such transformations. Classically, letters, common words and useful phrases were numbered in a codebook;
	messages transformed into those numbers were &quot;coded messages.&quot; Also see <A HREF="Glossary.htm#Nomenclator">nomenclator</A>.
	A &quot;codebook style cipher&quot; refers to a <A HREF="Glossary.htm#BlockCipher">block cipher</A>. <A NAME="CodebookAttack"></A>
	<P>
	<DT><B>Codebook Attack</B></DT>
	<DD>A form of <A HREF="Glossary.htm#Attack">attack</A> in which The <A HREF="Glossary.htm#Opponent">Opponent</A> simply tries to build
	or collect a <A HREF="Glossary.htm#Codebook">codebook</A> of all the possible transformations between <A HREF="Glossary.htm#Plaintext">plaintext</A>
	and <A HREF="Glossary.htm#Ciphertext">ciphertext</A> under a single <A HREF="Glossary.htm#Key">key</A>. This is the classic approach we
	normally think of as &quot;codebreaking.&quot;
	<P>The usual ciphertext-only approach depends upon the plaintext having strong statistical biases which make some
	values far more probable than others, and also more probable in the context of particular preceding known values.
	Such attacks can be defeated if the plaintext data are randomized and thus evenly and independently distributed
	among the possible values. (This may have been the motivation for the use of a <A HREF="Glossary.htm#Random">random</A> <A
	HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> in a <A HREF="Glossary.htm#StreamCipher">stream cipher</A>.)</P>
	<P>When a codebook attack is possible on a <A HREF="Glossary.htm#BlockCipher">block cipher</A>, the complexity of the attack
	is controlled by the size of the block (that is, the number of elements in the codebook) and not the <A HREF="Glossary.htm#Strength">strength</A>
	of the cipher. This means that a codebook attack would be equally effective against either <A HREF="Glossary.htm#DES">DES</A>
	or <A HREF="Glossary.htm#TripleDES">Triple-DES</A>.</P>
	<P>One way a block cipher can avoid a codebook attack is by having a large <A HREF="Glossary.htm#Block">block</A> size which
	will contain an unsearchable amount of plaintext &quot;uniqueness&quot; or <A HREF="Glossary.htm#Entropy">entropy</A>. Another
	approach is to randomize the plaintext block, often by using an <A HREF="Glossary.htm#OperatingMode">operating mode</A> such
	as <A HREF="Glossary.htm#CBC">CBC</A>. <A NAME="Combination"></A></P>
	<P>
	<DT><B>Combination</B></DT>
	<DD>The mathematical term for any particular subset of symbols, independent of order. (Also called the binomial
	coefficient.) The number of combinations of <I>n</I> things, taken <I>k</I> at a time, read &quot;<I>n</I> choose
	<I>k</I>&quot; is:
	<PRE>    n
   ( ) = C(n,k) =  n! / (k! (n-k)!)
    k
</PRE>
	<P>See the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM#Combinations'" tppabs="http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM#Combinations">combinations</A> section of the
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages. Also see
	<A HREF="Glossary.htm#Permutation">permutation</A>. <A NAME="Combinatoric"></A></P>
	<P>
	<DT><B>Combinatoric</B></DT>
	<DD>Combinatorics is a branch of mathematics, like analysis or number theory. Combinatorics is often related to
	counting the subsets of finite sets. One result is to help us to understand the probability of a particular subset
	in the universe of possible values.
	<P>Consider a <A HREF="Glossary.htm#BlockCipher">block cipher</A>: For any given size block, there is some fixed number of
	possible messages. Since every enciphering must be reversible (deciphering must work), we have a 1:1 mapping between
	<A HREF="Glossary.htm#Plaintext">plaintext</A> and <A HREF="Glossary.htm#Ciphertext">ciphertext</A> blocks. The set of all plaintext values
	and the set of all ciphertext values is the same set; particular values just have different meanings in each set.</P>
	<P><A HREF="Glossary.htm#Key">Keying</A> gives us no more ciphertext values, it only re-uses the values which are available.
	Thus, keying a block cipher consists of selecting a particular arrangement or <A HREF="Glossary.htm#Permutation">permutation</A>
	of the possible block values. Permutations are a combinatoric topic. Using combinatorics we can talk about the
	number of possible permutations or keys in a block cipher, or in cipher components like substitution tables.</P>
	<P>Permutations can be thought of as the number of unique arrangements of a given length on a particular set. Other
	combinatoric concepts include <A HREF="Glossary.htm#BinomialDistribution">binomials</A> and <A HREF="Glossary.htm#Combination">combinations</A>
	(the number of unique given-length subsets of a given set). <A NAME="Combiner"></A></P>
	<P>
	<DT><B>Combiner</B></DT>
	<DD>In a cryptographic context, a combiner is a <A HREF="Glossary.htm#Mechanism">mechanism</A> which <A HREF="Glossary.htm#Mixing">mixes</A>
	two data sources into a single result. A &quot;combiner style cipher&quot; refers to a <A HREF="Glossary.htm#StreamCipher">stream
	cipher</A>.
	<P><I>Reversible</I> combiners are used to <A HREF="Glossary.htm#Encipher">encipher</A> <A HREF="Glossary.htm#Plaintext">plaintext</A>
	into <A HREF="Glossary.htm#Ciphertext">ciphertext</A> in a <A HREF="javascript:if(confirm('http://christalmirror.ifrance.com/assembly/dossier10/fichiers/StreamCipher  \n\nThis file was not retrieved by Teleport Pro, because the server reports that this file cannot be found.  \n\nDo you want to open it from the server?'))window.location='http://christalmirror.ifrance.com/assembly/dossier10/fichiers/StreamCipher'" tppabs="http://christalmirror.ifrance.com/assembly/dossier10/fichiers/StreamCipher">stream cipher</A>. The ciphertext is then
	<A HREF="Glossary.htm#Decipher">deciphered</A> into plaintext using a related inverse or <A HREF="Glossary.htm#Extractor">extractor</A>
	mechanism.</P>
	<P><I>Irreversible</I> or non-invertible combiners are often used to mix multiple <A HREF="Glossary.htm#RNG">RNG's</A> into
	a single <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A>, also for use in stream cipher designs.</P>
	<P>Also see <A HREF="Glossary.htm#BalancedCombiner">balanced combiner</A>, <A HREF="Glossary.htm#AdditiveCombiner">additive combiner</A>
	and <A HREF="Glossary.htm#Complete">complete</A>, and <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/COMBCORR.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/COMBCORR.HTM'" tppabs="http://www.io.com/~ritter/RES/COMBCORR.HTM">The Story of Combiner
	Correlation: A Literature Survey</A>, in the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature
	Surveys and Reviews</A> section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers By Ritter</A> page. <A NAME="Commutative"></A></P>
	<P>
	<DT><B>Commutative</B></DT>
	<DD>A <A HREF="Glossary.htm#Dyadic">dyadic</A> operation in which exchanging the two argument values must produce the same
	result: <NOBR>a + b = b + a.</NOBR>
	<P>Also see: <A HREF="Glossary.htm#Associative">associative</A> and <A HREF="Glossary.htm#Distributive">distributive</A>. <A NAME="Complete"></A></P>
	<P>
	<DT><B>Complete</B></DT>
	<DD>A term used in <A HREF="Glossary.htm#S-Box">S-box</A> analysis to describe a property of the value arrangement in an invertible
	<A HREF="Glossary.htm#Substitution">substitution</A> or, equivalently, a <A HREF="Glossary.htm#BlockCipher">block cipher</A>. If we have
	some input value, and then change one bit in that value, we expect about half the output bits to change; this is
	the result of <A HREF="Glossary.htm#Diffusion">diffusion</A>; when partial diffusion is repeated we develop <A HREF="Glossary.htm#Avalanche">avalanche</A>;
	and the ultimate result is <A HREF="Glossary.htm#StrictAvalancheCriterion">strict avalanche</A>. <I>Completeness</I> tightens
	this concept and requires that changing a particular input bit produce a change in a particular output bit, at
	some point in the transformation (that is, for at least one input value). Completeness requires that this relationship
	occur at least once for <I>every</I> combination of input bit and output bit. It is tempting to generalize the
	definition to apply to multi-bit element values, where this makes more sense.
	<P>Completeness does <I>not</I> require that an input bit change an output bit for <I>every</I> input value (which
	would not make sense anyway, since <I>every</I> output bit must be changed at <I>some</I> point, and if they all
	had to change at <I>every</I> point, we would have <I>all</I> the output bits changing, instead of the desired
	half). The inverse of a complete function is not necessarily also complete.</P>
	<P>As originally defined in Kam and Davida:
	<BLOCKQUOTE>
		<P>&quot;For every possible key value, every output bit <I>c<SUB>i</SUB></I> of the SP network depends upon all
		input bits <I>p<SUB>1</SUB>,...,p<SUB>n</SUB></I> and not just a proper subset of the input bits.&quot; [p.748]
	</BLOCKQUOTE>
	Kam, J. and G. Davida. 1979. Structured Design of Substitution-Permutation Encryption Networks. <I>IEEE Transactions
	on Computers.</I> C-28(10): 747-753. <A NAME="Component"></A>
	<P>
	<DT><B>Component</B></DT>
	<DD>A part of a larger construction; a building-block in an overall design or <A HREF="Glossary.htm#System">system</A>. Modern
	<A HREF="Glossary.htm#Digital">digital</A> design is based on the use of a few general classes of pre-defined, fully-specified
	parts. Since even digital logic can use or even require <A HREF="Glossary.htm#Analog">analog</A> values internally, by enclosing
	these values the logic component can hide complexity and present the appearance of a fully digital device.
	<P>The most successful components are extremely general and can be used in many different ways. Even as a brick
	is independent of the infinite variety of brick buildings, a <A HREF="Glossary.htm#FlipFlop">flip-flop</A> is independent of
	the infinite variety of logic machines which use flip-flops.</P>
	<P>The source of the ability to design and build a wide variety of different electronic logic machines is the ability
	to interconnect and use a few very basic but very general parts.</P>
	<P><A HREF="Glossary.htm#Electronic">Electronic</A> components include
	<UL>
		<LI>passive components like <A HREF="Glossary.htm#Resistor">resistors</A>, <A HREF="Glossary.htm#Capacitor">capacitors</A>, and <A HREF="Glossary.htm#Inductor">inductors</A>;
		<LI>active components like <A HREF="Glossary.htm#Transistor">transistors</A> and even <A HREF="Glossary.htm#Relay">relays</A>, and
		<LI>whole varieties of active electronic logic devices, including <A HREF="Glossary.htm#FlipFlop">flip-flops</A>, <A HREF="Glossary.htm#ShiftRegister">shift
		registers</A>, and <A HREF="Glossary.htm#State">state</A> storage, or memory.
	</UL>
	<P>Cryptographic system components include:
	<UL>
		<LI>Nonlinear transformations, such as <A HREF="Glossary.htm#S-Box">S-boxes</A> / <A HREF="Glossary.htm#SubstitutionTable">substitution
		tables</A>,
		<LI><A HREF="Glossary.htm#Key">key</A> <A HREF="Glossary.htm#Hash">hashing</A>, such as <A HREF="Glossary.htm#CRC">CRC</A>,
		<LI><A HREF="Glossary.htm#RandomNumberGenerator">random number generators</A>, such as <A HREF="Glossary.htm#AdditiveRNG">additive RNG's</A>,
		<LI>sequence isolators such as <A HREF="Glossary.htm#Jitterizer">jitterizers</A>,
		<LI><A HREF="Glossary.htm#Combiner">combiners</A>, such as <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic Substitution</A>,
		<A HREF="Glossary.htm#LatinSquareCombiner">Latin squares</A>, and <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A>,
		<LI><A HREF="Glossary.htm#Mixing">mixers</A>, such as <A HREF="Glossary.htm#BalancedBlockMixer">Balanced Block Mixers</A>, or <A HREF="Glossary.htm#OrthogonalLatinSquares">orthogonal
		Latin squares</A>.
	</UL>
	<A NAME="Computer"></A>
	<P>
	<DT><B>Computer</B></DT>
	<DD>Originally the job title for a person who performed a laborious sequence of arithmetic computations. Now a
	machine for performing such calculations.
	<P>A logic machine with:</P>
	<P>
	<OL>
		<LI>Some limited set of fundamental computations. Typical operations include simple arithmetic and <A HREF="Glossary.htm#BooleanLogic">Boolean
		logic</A>. Each operation is selected by a particular operation code value or &quot;<A HREF="Glossary.htm#Opcode">opcode</A>.&quot;
		This is a <A HREF="Glossary.htm#Hardware">hardware</A> interpretation of the opcode.
		<P>
		<LI>The ability to follow a list of instructions or commands, performing each in sequence. Thus capable of simulating
		a wide variety of far more complex &quot;instructions.&quot;
		<P>
		<LI>The ability to execute or perform at least some instructions conditionally, based on parameter values or intermediate
		results.
		<P>
		<LI>The ability to store values into a numbered &quot;address space&quot; which is far larger than the instruction
		set, and later to recover those values when desired.
	</OL>
	<P>Also see: <A HREF="Glossary.htm#SourceCode">source code</A>, <A HREF="Glossary.htm#ObjectCode">object code</A> and <A HREF="Glossary.htm#Software">software</A>.
	<A NAME="Conductor"></A></P>
	<P>
	<DT><B>Conductor</B></DT>
	<DD>A material in which electron flow occurs easily. Typically a metal; usually copper, sometimes silver, brass
	or even aluminum. A <A HREF="Glossary.htm#Wire">wire</A>. As opposed to an <A HREF="Glossary.htm#Insulator">insulator</A>. <A NAME="Confusion"></A>
	<P>
	<DT><B>Confusion</B></DT>
	<DD>Those parts of a <A HREF="Glossary.htm#Cipher">cipher</A> <A HREF="Glossary.htm#Mechanism">mechanism</A> which change the correspondence
	between input values and output values. In contrast to <A HREF="Glossary.htm#Diffusion">diffusion</A>. <A NAME="ConfusionSequence"></A>
	<P>
	<DT><B>Confusion Sequence</B></DT>
	<DD>The sequence combined with data in a <A HREF="Glossary.htm#StreamCipher">stream cipher</A>. Normally produced by a <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A>, it is also called a &quot;running key.&quot; <A NAME="Contextual"></A>
	<P>
	<DT><B>Contextual</B></DT>
	<DD>In the study of <A HREF="Glossary.htm#Logic">logic</A>, an observed fact dependent upon other facts <I>not</I> being observed.
	Or a statement which is conditionally true, provided other unmentioned conditions have the appropriate <A HREF="Glossary.htm#State">state</A>.
	As opposed to <A HREF="Glossary.htm#Absolute">absolute</A>. <A NAME="ConventionalCipher"></A>
	<P>
	<DT><B>Conventional Cipher</B></DT>
	<DD>A <A HREF="Glossary.htm#SecretKeyCipher">secret key cipher</A>. <A NAME="Congruence"></A>
	<P>
	<DT><B>Congruence</B></DT>
	<DD>Casually speaking, the remainder after a division of <A HREF="Glossary.htm#Integer">integers</A>.
	<P>In number theory we say than integer a (exactly) <I>divides</I> integer b (denoted <NOBR>a | b</NOBR>) if and
	only if there is an integer k such that <NOBR>ak = b.</NOBR></P>
	<P>In number theory we say that integer a is <I>congruent</I> to integer b <A HREF="Glossary.htm#Modulo"><I>modulo</I></A>
	m, denoted <NOBR>a = b (mod m),</NOBR> if and only if <NOBR>m | (a - b).</NOBR> Here m is the divisor or <I>modulus.</I>
	<A NAME="Convolution"></A></P>
	<P>
	<DT><B>Convolution</B></DT>
	<DD><A HREF="Glossary.htm#Polynomial">Polynomial</A> multiplication. A multiplication of each term against each other term,
	with no &quot;carries&quot; from term to term. Also see <A HREF="Glossary.htm#Correlation">correlation</A>.
	<P>Used in the analysis of signal processing to develop the response of a processing system to a complicated real-valued
	input signal. The input signal is first separated into some number of discrete impulses. Then the system response
	to an impulse -- the output level at each unit time delay after the impulse -- is determined. Finally, the expected
	response is computed as the sum of the contributions from each input impulse, multiplied by the magnitude of each
	impulse. This is an approximation to the convolution integral with an infinite number of infinitesimal delays.
	Although originally accomplished graphically, the process is just polynomial multiplication.</P>
	<P>It is apparently possible to compute the convolution of two sequences by taking the <A HREF="Glossary.htm#FFT">FFT</A> of
	each, multiplying these results term-by-term, then taking the inverse FFT. While there is an analogous relationship
	in the <A HREF="Glossary.htm#FWT">FWT</A>, in this case the &quot;delays&quot; between the sequences represent <A HREF="Glossary.htm#Mod2">mod
	2</A> distance differences, which may or may not be useful. <A NAME="Correlation"></A></P>
	<P>
	<DT><B>Correlation</B></DT>
	<DD>In general, the probability that two sequences of symbols will, in any position, have the same symbol. We expect
	two <A HREF="Glossary.htm#Random">random</A> binary sequences to have the same symbols about half the time.
	<P>One way to evaluate the correlation of two real-valued sequences is to multiply them together term-by-term and
	sum all results. If we do this for all possible &quot;delays&quot; between the two sequences, we get a &quot;vector&quot;
	or 1-dimensional array of correlations which is a <A HREF="Glossary.htm#Convolution">convolution</A>. Then the maximum value
	represents the delay with the best correlation. <A NAME="CorrelationCoefficient"></A></P>
	<P>
	<DT><B>Correlation Coefficient</B></DT>
	<DD>The value from -1 to +1 describing the <A HREF="Glossary.htm#Correlation">correlation</A> of two binary sequences, averaged
	over the length of interest. Correlation coefficient values are related to the probability that, given a symbol
	from one sequence, the other sequence will have that same symbol. A value of:
	<UL>
		<LI>-1 implies a 0.0 probability (the second sequence is the complement of the first),
		<LI>0 implies a 0.5 probability (the sequences are uncorrelated), and
		<LI>+1 implies a 1.0 probability (the sequences are the same).
	</UL>
	<P>&quot;The correlation coefficient associated with a pair of <A HREF="Glossary.htm#BooleanFunction">Boolean functions</A>
	<I>f(a)</I> and <I>g(a)</I> is denoted by C(f,g) and is given by
	<BLOCKQUOTE>
		<P><TT>C(<I>f,g</I>) = 2 * prob(<I>f(a) = g(a)</I>) - 1 .&quot;</TT>
	</BLOCKQUOTE>
	<P>Daemen, J., R. Govaerts and J. Vanderwalle. 1994. Correlation Matrices. <I>Fast Software Encryption.</I> 276.
	Springer-Verlag. <A NAME="CRC"></A></P>
	<P>
	<DT><B>CRC</B></DT>
	<DD>Cyclic Redundancy Check: A fast error-check <A HREF="Glossary.htm#Hash">hash</A> based on <A HREF="Glossary.htm#Mod2Polynomial">mod
	2 polynomial</A> operations.
	<P>A CRC is essentially a fast remainder operation over a huge numeric value which is the data. (For best speed,
	the actual computation occurs as mod 2 polynomial operations.) The CRC result is an excellent (but linear) hash
	value corresponding to the data.</P>
	<P>No CRC has any appreciable <A HREF="Glossary.htm#Strength">strength</A>, but some applications -- even in cryptography --
	<I>need</I> no strength:
	<UL>
		<LI>One example is <A HREF="Glossary.htm#Authentication">authentication</A>, provided the linear CRC hash result is protected
		by a block cipher.
		<LI>Another example is <A HREF="Glossary.htm#Key">key</A> processing, where the uncertainty in a User Key phrase of arbitrary
		size is collected into a hash result of fixed size. In general, the hash result would be just as good for The Opponent
		as the original key phrase, so no strength shield could possibly improve the situation.
		<LI>A third example is the accumulation of the uncertainty in slightly uncertain <A HREF="Glossary.htm#PhysicallyRandom">physically
		random</A> events. When true randomness is accumulated, it is already as unknowable as any strength shield could
		make it.
	</UL>
	<A NAME="Cryptanalysis"></A>
	<P>
	<DT><B>Cryptanalysis</B></DT>
	<DD>That aspect of <A HREF="Glossary.htm#Cryptology">cryptology</A> which concerns the <A HREF="Glossary.htm#Strength">strength</A> analysis
	of a <A HREF="Glossary.htm#Cryptography">cryptographic</A> system, and the penetration or <A HREF="Glossary.htm#Break">breaking</A> of
	a cryptographic system. Also &quot;codebreaking.&quot;
	<P>Because there is no theory which guarantees strength for any conventional cipher, ciphers traditionally have
	been considered &quot;strong&quot; when they have been used for a long time with &quot;nobody&quot; knowing how
	to break them easily. Cryptanalysis seeks to improve this process by applying the known <A HREF="Glossary.htm#Attack">attack</A>
	strategies to new <A HREF="Glossary.htm#Cipher">ciphers</A>, and by actively seeking new ones. It is normal to assume that
	at least <A HREF="Glossary.htm#KnownPlaintextAttack">known-plaintext</A> is available; often, <A HREF="Glossary.htm#DefinedPlaintextAttack">defined-plaintext</A>
	is assumed. The result is typically some value for the amount of &quot;work&quot; which will achieve a &quot;break&quot;
	(even if that value is impractical); this is &quot;the&quot; <A HREF="Glossary.htm#Strength">strength</A> of the cipher.</P>
	<P>But while cryptanalysis <I>can</I> prove &quot;weakness&quot; for a given level of effort, cryptanalysis <I>cannot</I>
	prove that there is no simpler attack:
	<BLOCKQUOTE>
<BIG>
		<P><B>Lack of proof of weakness is not proof of strength.</B></BIG>
	</BLOCKQUOTE>
	<P>Indeed, when ciphers are used for real, <A HREF="Glossary.htm#Opponent">The Opponents</A> can hardly be expected to advertise
	a successful break, but will instead work hard to reassure users that their ciphers are still secure. The fact
	that <I>apparently</I> &quot;nobody&quot; knows how to break a cipher is somewhat less reassuring from this viewpoint.
	In this context, using a wide variety of different ciphers can make good sense: This reduces the value of the information
	protected by any particular cipher, which thus reduces the rewards from even a successful attack. Having a numerous
	ciphers also requires The Opponents to field far greater resources to identify, analyze, and automate breaking
	(when possible) of each different cipher.</P>
	<P>Many academic attacks are essentially theoretical, involving huge amounts of data and computation. But even
	when a direct technical attack is <I>practical,</I> that may be the most difficult, expensive and time-consuming
	way to obtain the desired information. Other methods include making a paper copy, stealing a copy, bribery, coercion,
	and electromagnetic monitoring. No cipher can keep secret something which has been otherwise revealed. Information
	<A HREF="Glossary.htm#Security">security</A> thus involves far more than just <A HREF="Glossary.htm#Cryptography">cryptography</A>, and
	even a cryptographic system is more than just a cipher. Even finding that information has been revealed does not
	mean that a cipher has been broken.</P>
	<P>At one time it was reasonable to say: &quot;Any cipher a man can make, another man can break.&quot; However,
	with the advent of serious <A HREF="Glossary.htm#Computer">computer</A>-based cryptography, that statement is no longer valid,
	<I>provided</I> that every detail is properly handled. This, of course, often turns out to not be the case. <A
	NAME="Cryptanalyst"></A></P>
	<P>
	<DT><B>Cryptanalyst</B></DT>
	<DD>Someone who <A HREF="Glossary.htm#Attack">attacks</A> <A HREF="Glossary.htm#Cipher">ciphers</A> with <A HREF="Glossary.htm#Cryptanalysis">cryptanalysis</A>.
	A &quot;codebreaker.&quot; Often called the <A HREF="Glossary.htm#Opponent">Opponent</A> by cryptographers, in recognition
	of the (serious) game of thrust and parry between these parties. <A NAME="Cryptographer"></A>
	<P>
	<DT><B>Cryptographer</B></DT>
	<DD>Someone who creates <A HREF="Glossary.htm#Cipher">ciphers</A> using <A HREF="Glossary.htm#Cryptography">cryptography</A>. <A NAME="CryptographicMechanism"></A>
	<P>
	<DT><B>Cryptographic Mechanism</B></DT>
	<DD>A process for enciphering and/or deciphering, or an implementation (for example, <A HREF="Glossary.htm#Hardware">hardware</A>,
	<A HREF="Glossary.htm#Computer">computer</A> <A HREF="Glossary.htm#Software">software</A>, hybrid, or the like) for performing that process.
	See also <A HREF="Glossary.htm#Cryptography">cryptography</A> and <A HREF="Glossary.htm#Mechanism">mechanism</A>. <A NAME="Cryptography"></A>
	<P>
	<DT><B>Cryptography</B></DT>
	<DD>Greek for &quot;hidden writing.&quot; The art and science of transforming information into an intermediate
	form which <A HREF="Glossary.htm#Security">secures</A> that information while in storage or in transit. A part of <A HREF="Glossary.htm#Cryptology">cryptology</A>,
	further divided into secret <A HREF="Glossary.htm#Code">codes</A> and <A HREF="Glossary.htm#Cipher">ciphers</A>. As opposed to <A HREF="Glossary.htm#Steganography">steganography</A>,
	which seeks to hide the existence of any message, cryptography seeks to render a message unintelligible <I>even
	when the message is completely exposed</I>.
	<P>Cryptography includes at least:
	<UL>
		<LI><A HREF="Glossary.htm#Secrecy">secrecy</A> (<I>confidentiality,</I> or <I>privacy,</I> or <I>information security</I>)
		and
		<LI><A HREF="Glossary.htm#Authentication">message authentication</A> (<I>integrity</I>).
	</UL>
	Cryptography may also include:
	<UL>
		<LI><I>nonrepudiation</I> (the inability to deny sending a message),
		<LI><I>access control</I> (<I>user</I> or <I>source</I> authentication), and
		<LI><I>availability</I> (keeping security services available).
	</UL>
	<P>Modern cryptography generally depends upon translating a message into one of an astronomical number of different
	intermediate representations, or <A HREF="Glossary.htm#Ciphertext">ciphertexts</A>, as selected by a <A HREF="Glossary.htm#Key">key</A>.
	If all possible intermediate representations have similar appearance, it may be necessary to try all possible keys
	to find the one which deciphers the message. By creating <A HREF="Glossary.htm#Mechanism">mechanisms</A> with an astronomical
	number of keys, we can make this approach impractical.</P>
	<P>Cryptography may also be seen as a zero-sum game, where a <A HREF="Glossary.htm#Cryptographer">cryptographer</A> competes
	against a <A HREF="Glossary.htm#Cryptanalyst">cryptanalyst</A>. We might call this the <A HREF="Glossary.htm#CryptographyWar">cryptography
	war</A>. <A NAME="CryptographyWar"></A></P>
	<P>
	<DT><B>Cryptography War</B></DT>
	<DD><A HREF="Glossary.htm#Cryptography">Cryptography</A> may be seen as a dynamic <I>battle</I> between <A HREF="Glossary.htm#Cryptographer">cryptographer</A>
	and <A HREF="Glossary.htm#Cryptanalyst">cryptanalyst</A>. The cryptographer tries to produce a <A HREF="Glossary.htm#Cipher">cipher</A>
	which can retain <A HREF="Glossary.htm#Secrecy">secrecy</A>. Then, when it becomes worthwhile, one or more cryptanalysts try
	to penetrate that secrecy by <A HREF="Glossary.htm#Attack">attacking</A> the cipher. Fortunately for the war, even after fifty
	years of mathematical cryptology, not <I>one</I> practical cipher has been accepted as <I>proven</I> <A HREF="Glossary.htm#Security">secure</A>
	in practice. (See, for example, the <A HREF="Glossary.htm#OneTimePad">one-time pad</A>.)
	<P>Note that the successful cryptanalyst must keep good attacks secret, or the opposing cryptographer will just
	produce a <A HREF="Glossary.htm#Strength">stronger</A> cipher. This means that the cryptographer is in the odd position of
	never knowing whether his or her best cipher designs are successful, or which side is winning.</P>
	<P>Cryptographers are often scientists who are trained to ignore unsubstantiated claims. But there will <I>be</I>
	no substantiation when a <A HREF="Glossary.htm#Cipher">cipher</A> <A HREF="Glossary.htm#System">system</A> is <A HREF="Glossary.htm#Attack">attacked</A>
	and <A HREF="Glossary.htm#Break">broken</A> for real, yet continued use will endanger all messages so &quot;protected.&quot;
	Thus, it is a very reasonable policy to not adopt a widely-used cipher, and to change ciphers periodically. <A
	NAME="Cryptology"></A></P>
	<P>
	<DT><B>Cryptology</B></DT>
	<DD>The field of study which generally includes <A HREF="Glossary.htm#Steganography">steganography</A>, <A HREF="Glossary.htm#Cryptography">cryptography</A>
	and <A HREF="Glossary.htm#Cryptanalysis">cryptanalysis</A>. <A NAME="Current"></A>
	<P>
	<DT><B>Current</B></DT>
	<DD>The measure of electron flow, in amperes. Current is analogous to the amount of water <I>flow,</I> as opposed
	to <I>pressure</I> or <A HREF="Glossary.htm#Voltage">voltage</A>. A flowing electrical current will create a <A HREF="Glossary.htm#MagneticField">magnetic
	field</A> around the <A HREF="Glossary.htm#Conductor">conductor</A>. A changing electrical current may create an <A HREF="Glossary.htm#ElectromagneticField">electromagnetic
	field</A>. <A NAME="dB"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>dB</B>
	<DD><A HREF="Glossary.htm#Decibel">decibel</A>. <A NAME="DC"></A>
	<P>
	<DT><B>DC</B></DT>
	<DD>Direct <A HREF="Glossary.htm#Current">Current</A>: Electrical power which flows in one direction, more or less constantly.
	As opposed to <A HREF="Glossary.htm#AC">AC</A>.
	<P>Most <A HREF="Glossary.htm#Electronic">electronic</A> devices require DC -- at least internally -- for proper operation,
	so a substantial part of modern design is the &quot;power supply&quot; which converts 120 VAC wall power into 12
	VDC, 5 VDC and/or 3 VDC as needed by the <A HREF="Glossary.htm#Circuit">circuit</A> and active devices. <A NAME="Debug"></A></P>
	<P>
	<DT><B>Debug</B></DT>
	<DD>The interactive analytical process of correcting the design of a complex <A HREF="Glossary.htm#System">system</A>. A normal
	part of the development process, although when <A HREF="Glossary.htm#Bug">bugs</A> are not caught during development, they
	can remain in production systems.
	<P>Contrary to naive expectations, a complex system almost never performs as desired when first realized. Both
	<A HREF="Glossary.htm#Hardware">hardware</A> and <A HREF="Glossary.htm#Software">software</A> <A HREF="Glossary.htm#SystemDesign">system design</A>
	environments generally deal with systems which are not working. (When a system <I>really</I> works, the design
	and development process is generally over.) Debugging involves identifying problems, analyzing the source of those
	problems, then changing the construction to fix the problem. (Hopefully, the fix will not itself create new problems.)
	This form of interactive analysis can be especially difficult because the realized design may not actually be what
	is described in the schematics, flow-charts, or other working documents: To some extent the real system is unknown.</P>
	<P>When a system has many problems, the problems tend to interact, which can make the identification of a particular
	cause very difficult. This can be managed by &quot;shrinking&quot; the system: first by partitioning the design
	into components and testing those components, and then by temporarily disabling or removing sections so as to identify
	the section in which the problem lies. Eventually, with enough testing, partitioning and analysis, the source of
	any problem can be identified. Some &quot;problems,&quot; however, turn out to be the unexpected implications of
	a complex design and are sometimes accepted as &quot;features&quot; rather than the alternative of a complete design
	overhaul. <A NAME="Decipher"></A></P>
	<P>
	<DT><B>Decipher</B></DT>
	<DD>The process which can reveal the information or <A HREF="Glossary.htm#Plaintext">plaintext</A> hidden in message <A HREF="Glossary.htm#Ciphertext">ciphertext</A>
	(provided it is the correct process, with the proper <A HREF="Glossary.htm#Key">key</A>). The inverse of <A HREF="Glossary.htm#Encipher">encipher</A>.
	<A NAME="Decryption"></A>
	<P>
	<DT><B>Decryption</B></DT>
	<DD>The general term for extracting information which was hidden by <A HREF="Glossary.htm#Encryption">encryption</A>. <A NAME="DeductiveReasoning"></A>
	<P>
	<DT><B>Deductive Reasoning</B></DT>
	<DD>In the study of <A HREF="Glossary.htm#Logic">logic</A>, reasoning about a particular case from one or more general statements;
	a proof. Also see: <A HREF="Glossary.htm#InductiveReasoning">inductive reasoning</A> and <A HREF="Glossary.htm#Fallacy">fallacy</A>. <A
	NAME="DefinedPlaintextAttack"></A>
	<P>
	<DT><B>Defined Plaintext Attack</B></DT>
	<DD>A form of <A HREF="Glossary.htm#Attack">attack</A> in which the <A HREF="Glossary.htm#Opponent">Opponent</A> can present arbitrary
	<A HREF="Glossary.htm#Plaintext">plaintext</A> to be enciphered, and then capture the resulting <A HREF="Glossary.htm#Ciphertext">ciphertext</A>.
	The ultimate form of <A HREF="Glossary.htm#KnownPlaintextAttack">known plaintext attack</A>.
	<P>A defined plaintext attack can be a problem for systems which allow unauthorized users to present arbitrary
	messages for ciphering. Such attack can be made difficult by allowing only authorized users to encipher data, by
	allowing only a few messages to be enciphered between <A HREF="Glossary.htm#Key">key</A> changes, by changing keys frequently,
	and by enciphering each message in a different random <A HREF="Glossary.htm#MessageKey">message key</A>. <A NAME="DegreesOfFreedom"></A></P>
	<P>
	<DT><B>Degrees of Freedom</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the number of completely independent values in a sample. The number
	of sampled values or observations or bins, less the number of defined or freedom-limiting relationships or &quot;constraints&quot;
	between those values.
	<P>If we choose two values completely independently, we have a DF of 2. But if we must choose two values such that
	the second is twice the first, we can choose only the first value independently. Imposing a relationship on one
	of the sampled value means that we will have a DF of one less than the number of samples, even though we may end
	up with apparently similar sample values.</P>
	<P>In a typical <A HREF="Glossary.htm#GoodnessOfFit">goodness of fit</A> test such as <A HREF="Glossary.htm#ChiSquare">chi-square</A>,
	the reference <A HREF="Glossary.htm#Distribution">distribution</A> (the expected counts) is normalized to give the same number
	of counts as the experiment. This is a constraint, so if we have N bins, we will have a DF of N - 1. <A NAME="DES"></A></P>
	<P>
	<DT><B>DES</B></DT>
	<DD>The particular <A HREF="Glossary.htm#BlockCipher">block cipher</A> which is the U.S. Data Encryption Standard. A 64-bit
	block cipher with a 56-bit key organized as 16 <A HREF="Glossary.htm#Round">rounds</A> of operations. <A NAME="Decibel"></A>
	<P>
	<DT><B>Decibel</B></DT>
	<DD>Ten times the base-10 logarithm of the ratio of two <A HREF="Glossary.htm#Power">power</A> values. Denoted by dB. One-tenth
	of a <A HREF="Glossary.htm#Bel">bel</A>.
	<P>When <A HREF="Glossary.htm#Voltage">voltages</A> or <A HREF="Glossary.htm#Current">currents</A> are measured, power changes as the square
	of these values, so a decibel is twenty times the base-10 logarithm of the ratio of two voltages or currents. <A
	NAME="Decimal"></A></P>
	<P>
	<DT><B>Decimal</B></DT>
	<DD>Base 10: The numerical representation in which each digit has an <A HREF="Glossary.htm#Alphabet">alphabet</A> of ten symbols,
	usually 0 through 9. Also see: <A HREF="Glossary.htm#Binary">binary</A>, <A HREF="Glossary.htm#Octal">octal</A>, and <A HREF="Glossary.htm#Hexadecimal">hexadecimal</A>.
	<A NAME="DesignStrength"></A>
	<P>
	<DT><B>Design Strength</B></DT>
	<DD>The <A HREF="Glossary.htm#Keyspace">keyspace</A>; the effort required for a <A HREF="Glossary.htm#BruteForceAttack">brute force attack</A>.
	<A NAME="Deterministic"></A>
	<P>
	<DT><B>Deterministic</B></DT>
	<DD>A process whose sequence of operations is fully determined by its initial <A HREF="Glossary.htm#State">state</A>. A mechanical
	or clockwork-like process whose outcome is inevitable, given its initial setting. <A HREF="Glossary.htm#PseudoRandom">Pseudorandom</A>.
	<A NAME="DictionaryAttack"></A>
	<P>
	<DT><B>Dictionary Attack</B></DT>
	<DD>Typically an <A HREF="Glossary.htm#Attack">attack</A> on a secret password. A dictionary of common passwords is developed,
	and a <A HREF="Glossary.htm#BruteForceAttack">brute force attack</A> conducted on the target with each common password. <A
	NAME="DifferentialCryptanalysis"></A>
	<P>
	<DT><B>Differential Cryptanalysis</B></DT>
	<DD>A form of <A HREF="Glossary.htm#Attack">attack</A> in which the difference between values (or keys) is used to gain some
	information about the system.
	<P>Also see <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/DIFFANA.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/DIFFANA.HTM'" tppabs="http://www.io.com/~ritter/RES/DIFFANA.HTM">Differential Cryptanalysis: A Literature Survey</A>,
	in the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers By Ritter</A> page. <A NAME="Diffusion"></A></P>
	<P>
	<DT><B>Diffusion</B></DT>
	<DD>Diffusion is the property of an operation such that changing one <A HREF="Glossary.htm#Bit">bit</A> (or <A HREF="Glossary.htm#Byte">byte</A>)
	of the input will change adjacent or near-by bits (or bytes) after the operation. In a <A HREF="Glossary.htm#BlockCipher">block
	cipher</A>, diffusion propagates bit-changes from one part of a block to other parts of the block. Diffusion requires
	<A HREF="Glossary.htm#Mixing">mixing</A>, and the step-by-step process of increasing diffusion is described as <A HREF="Glossary.htm#Avalanche">avalanche</A>.
	Diffusion is in contrast to <A HREF="Glossary.htm#Confusion">confusion</A>.
	<P>Normally we speak of <I>data</I> diffusion, in which changing a tiny part of the plaintext data may affect the
	whole ciphertext. But we can also speak of <I>key</I> diffusion, in which changing even a tiny part of the <A HREF="Glossary.htm#Key">key</A>
	should change each bit in the ciphertext with probability 0.5.</P>
	<P>Perhaps the best diffusing <A HREF="Glossary.htm#Component">component</A> is <A HREF="Glossary.htm#SimpleSubstitution">substitution</A>,
	but this diffuses only within a single substituted value. <A HREF="Glossary.htm#SubstitutionPermutation">Substitution-permutation</A>
	ciphers get around this by moving the bits of each substituted element to other elements, substituting again, and
	repeating. But this only provides guaranteed diffusion if particular substitution tables are constructed. Another
	alternative is to use some sort of <A HREF="Glossary.htm#BalancedBlockMixing">Balanced Block Mixing</A> which has an inherently
	guaranteed diffusion, or a <A HREF="Glossary.htm#VariableSizeBlockCipher">Variable Size Block Cipher</A> construction. Also
	see <A HREF="Glossary.htm#OverallDiffusion">Overall Diffusion</A>. <A NAME="Digital"></A></P>
	<P>
	<DT><B>Digital</B></DT>
	<DD>Pertaining to discrete or distinct finite values. As opposed to <A HREF="Glossary.htm#Analog">analog</A> or continuous
	quantities. <A NAME="Diode"></A>
	<P>
	<DT><B>Diode</B></DT>
	<DD>An <A HREF="Glossary.htm#Electronic">electronic</A> device with two terminals which allows <A HREF="Glossary.htm#Current">current</A>
	to flow in only one direction. <A NAME="Distribution"></A>
	<P>
	<DT><B>Distribution</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the range of values which a <A HREF="Glossary.htm#RandomVariable">random variable</A>,
	and the probability that each value or range of values will occur. Also the probability of test <A HREF="Glossary.htm#Statistic">statistic</A>
	values for the case &quot;nothing unusual found,&quot; which is the <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>.
	<P>If we have a <I>discrete</I> distribution, with a finite number of possible result values, we can speak of &quot;frequency&quot;
	and &quot;probability&quot; distributions: The &quot;frequency distribution&quot; is the expected <I>number</I>
	of occurrences for each possible value, in a particular <A HREF="Glossary.htm#Sample">sample</A> size. The &quot;probability
	distribution&quot; is the <I>probability</I> of getting each value, normalized to a probability of 1.0 over the
	sum of all possible values.</P>
	<P>Here is a graph of a typical &quot;discrete probability distribution&quot; or &quot;discrete probability density
	function,&quot; which displays the probability of getting a particular statistic value for the case &quot;nothing
	unusual found&quot;:</P>
	<PRE>   0.1|        ***
      |       *   *         Y = Probability of X
    Y |     **     **       y = P(x)
      | ****         ****
   0.0 -------------------
                X
</PRE>
	<P>Unfortunately, it is not really possible to think in the same way about continuous distributions: Since continuous
	distributions have an infinite number of possible values, the probability of getting any <I>particular</I> value
	is zero. For continuous distributions, we instead talk about the probability of getting a value in some subrange
	of the overall distribution. We are often concerned with the probability of getting a particular value or below,
	or the probability of a particular value or above.</P>
	<P>Here is a graph of the related &quot;cumulative probability distribution&quot; or &quot;cumulative distribution
	function&quot; (<A HREF="Glossary.htm#cdf">c.d.f.</A>) for the case &quot;nothing unusual found&quot;:</P>
	<PRE>   1.0|            ******
      |          **           Y = Probability (0.0 to 1.0) of finding
    Y |         *                 a value which is x or less
      |       **
   0.0 -******------------
                X
</PRE>
	<P>The c.d.f. is just the sum of all probabilities for a given value or less. This is the usual sort of function
	used to interpret a <A HREF="Glossary.htm#Statistic">statistic</A>: Given some result, we can look up the probability of a
	lesser value (normally called <I>p</I>) or a greater value (called <NOBR><I>q</I> = 1.0 - <I>p</I></NOBR>).</P>
	<P>Usually, a test statistic is designed so that extreme values are not likely to occur by chance in the case &quot;nothing
	unusual found&quot; which is the <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>. So if we <I>do</I> find extreme
	values, we have a strong argument that the results were not due simply to random sampling or other random effects,
	and may choose to reject the null hypothesis and thus accept the <A HREF="Glossary.htm#AlternativeHypothesis">alternative hypothesis</A>.</P>
	<P>Common discrete distributions include the <A HREF="Glossary.htm#BinomialDistribution">binomial distribution</A>, and the
	<A HREF="Glossary.htm#PoissonDistribution">Poisson distribution</A>. <A NAME="Distributive"></A></P>
	<P>
	<DT><B>Distributive</B></DT>
	<DD>The case of a <A HREF="Glossary.htm#Dyadic">dyadic</A> operation, which may be called &quot;multiplication,&quot; which
	can be applied to equations involving another dyadic operation, which may be called &quot;addition,&quot; such
	that: <NOBR>a(b + c) = ab + ac</NOBR> and <NOBR>(b + c)a = ba + bc.</NOBR>
	<P>Also see: <A HREF="Glossary.htm#Associative">associative</A> and <A HREF="Glossary.htm#Commutative">commutative</A>. <A NAME="DivideAndConquer"></A></P>
	<P>
	<DT><B>Divide and Conquer</B></DT>
	<DD>The general concept of being able to split a complexity into several parts, each part naturally being less
	complex than the total. If this is possible, The <A HREF="Glossary.htm#Opponent">Opponent</A> may be able to solve all of the
	parts far easier than the supposedly complex whole. Often part of an <A HREF="Glossary.htm#Attack">attack</A>.
	<P>This is a particular danger in cryptosystems, since most ciphers are built from less-complex parts. Indeed,
	a major role of cryptographic design is to combine small <A HREF="Glossary.htm#Component">component</A> parts into a larger
	complex <A HREF="Glossary.htm#System">system</A> which cannot be split apart. <A NAME="Domain"></A></P>
	<P>
	<DT><B>Domain</B></DT>
	<DD>The set of all arguments <I>x</I> which can be applied to a <A HREF="Glossary.htm#Mapping">mapping</A>. Also see <A HREF="Glossary.htm#Range">range</A>.
	<A NAME="Dyadic"></A>
	<P>
	<DT><B>Dyadic</B></DT>
	<DD>Relating to <I>dyad</I>, which is Greek for dual or having two parts. In particular, a function with two inputs
	or arguments. Also see: <A HREF="Glossary.htm#Monadic">monadic</A>, <A HREF="Glossary.htm#Unary">unary</A> and <A HREF="Glossary.htm#Binary">binary</A>.
	<A NAME="DynamicKeying"></A>
	<P>
	<DT><B>Dynamic Keying</B></DT>
	<DD>That aspect of a cipher which allows a <A HREF="Glossary.htm#Key">key</A> to be changed with minimal overhead. A dynamically-keyed
	<A HREF="Glossary.htm#BlockCipher">block cipher</A> might impose little or no additional computation to change a key on a block-by-block
	basis. The dynamic aspect of keying could be just one of multiple keying mechanisms in the same cipher.
	<P>One way to have a dynamic key in a block cipher is to include the key value along with the <A HREF="Glossary.htm#Plaintext">plaintext</A>
	data. But this is normally practical only with blocks of huge size, or <A HREF="Glossary.htm#VariableSizeBlockCipher">variable
	size</A> blocks.</P>
	<P>Another way to have a dynamic key in a block cipher is to add a <A HREF="Glossary.htm#Confusion">confusion</A> <A HREF="Glossary.htm#Layer">layer</A>
	which mixes the key value with the block. For example, exclusive-OR could be used to mix a 64-bit key with a 64-bit
	data block. <A NAME="DynamicSubstitutionCombiner"></A></P>
	<P>
	<DT><B>Dynamic Substitution Combiner</B></DT>
	<DD>The <A HREF="Glossary.htm#Combiner">combining</A> <A HREF="Glossary.htm#Mechanism">mechanism</A> described in U.S. Patent 4,979,832
	(see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#DynSubTech'" tppabs="http://www.io.com/~ritter/#DynSubTech">Dynamic Substitution articles</A> on the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page).
	<P>Dynamic Substitution is the use of an invertible <A HREF="Glossary.htm#SubstitutionTable">substitution table</A> in which
	the arrangement of the entries changes dynamically during operation. This is particularly useful as a strong replacement
	for the strengthless <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> combiner in <A HREF="Glossary.htm#StreamCipher">stream ciphers</A>.</P>
	<P>The arrangement of a <A HREF="Glossary.htm#Key">keyed</A> table starts out unknown to an <A HREF="Glossary.htm#Opponent">Opponent</A>.
	From the Opponent's point of view, each table entry could be any possible value with uniform probability. But after
	the first value is mapped through that table, the used transformation (table entry) is at least potentially exposed,
	and no longer can be considered a completely unknown probability. Dynamic Substitution acts to make the used transformation
	again completely unknown and unbiased, by allowing it to take on any possible mapping. As a first approximation,
	the amount of information leaked about table contents is replaced by information used to re-define each used entry.</P>
	<P>In the usual case, an invertible substitution table is keyed by <A HREF="Glossary.htm#Shuffle">shuffling</A> under the control
	of a <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>. One combiner input value is used to select a
	value from within that table to be the result or output. The other combiner input value is used simply to select
	an entry, and then the values at the two selected entries are exchanged. So as soon as a <A HREF="Glossary.htm#Plaintext">plaintext</A>
	mapping is used, it is immediately reset to any possibility, and the more often any plaintext value occurs, the
	more often that transformation changes.</P>
	<P>Also see <A HREF="Glossary.htm#BalancedBlockMixing">Balanced Block Mixing</A>, and <A HREF="Glossary.htm#VariableSizeBlockCipher">Variable
	Size Block Cipher</A>. <A NAME="DynamicTransposition"></A></P>
	<P>
	<DT><B>Dynamic Transposition</B></DT>
	<DD>A <A HREF="Glossary.htm#BlockCipher">block cipher</A> which first creates an exact bit-<A HREF="Glossary.htm#Balance">balance</A> within
	each <A HREF="Glossary.htm#Block">block</A>, and then <A HREF="Glossary.htm#Shuffle">shuffles</A> the bits within a block, each block being
	<A HREF="Glossary.htm#Permutation">permuted</A> independently from a <A HREF="Glossary.htm#Key">keyed</A> <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A>.
	<P>Since each block -- <A HREF="Glossary.htm#Plaintext">plaintext</A> or <A HREF="Glossary.htm#Ciphertext">ciphertext</A> -- contains exactly
	the same number of 1's and 0's, every possible plaintext block is just some permutation of any possible ciphertext
	block. And since any possible plaintext block can be produced from any ciphertext block in a vast plethora of different
	ways, the keying sequence is hidden even from <A HREF="Glossary.htm#KnownPlaintextAttack">known plaintext</A>. And <A HREF="Glossary.htm#DefinedPlaintextAttack">defined
	plaintext</A> is easily defeated with the usual <A HREF="Glossary.htm#MessageKey">message key</A>. To the extent that every
	possible plaintext block can be produced, the cipher approaches <A HREF="Glossary.htm#PerfectSecrecy">perfect secrecy</A>.</P>
	<P>See the article <A HREF="javascript:if(confirm('http://www.io.com/~ritter/ARTS/DYNTRAN2.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/ARTS/DYNTRAN2.HTM'" tppabs="http://www.io.com/~ritter/ARTS/DYNTRAN2.HTM">Transposition Cipher with Pseudo-Random
	Shuffling: The Dynamic Transposition Combiner</A>. <A NAME="ECB"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>ECB</B>
	<DD>ECB or Electronic Code Book is an <A HREF="Glossary.htm#OperatingMode">operating mode</A> for <A HREF="Glossary.htm#BlockCipher">block
	ciphers</A>. Presumably the name comes from the observation that a block cipher under a fixed <A HREF="Glossary.htm#Key">key</A>
	functions much like a physical codebook: Each possible <A HREF="Glossary.htm#Plaintext">plaintext</A> <A HREF="Glossary.htm#Block">block</A>
	value has a corresponding <A HREF="Glossary.htm#Ciphertext">ciphertext</A> value, and vise versa.
	<P>ECB is the naive method of applying a block cipher, in that the plaintext is simply partitioned into appropriate
	size blocks, and each block is enciphered separately and independently. When we have a small block size, ECB is
	generally unwise, because language text has biased statistics which will result in some block values being re-used
	frequently, and this repetition will show up in the raw ciphertext. This is the basis for a successful <A HREF="Glossary.htm#CodebookAttack">codebook
	attack</A>.</P>
	<P>On the other hand, if we have a large block, we may expect it to contain enough (at least, say, 64 bits) uniqueness
	or &quot;<A HREF="Glossary.htm#Entropy">entropy</A>&quot; to prevent a codebook attack. In that case, ECB mode has the advantage
	of supporting independent ciphering of each block. This, in turn, supports various things, like the use of multiple
	ciphering hardware operating in parallel for higher speeds.</P>
	<P>As another example, modern packet-switching network technologies often deliver raw packets out of order. The
	packets will be re-ordered eventually, but having out-of-sequence packets can be a problem for low-level ciphering
	if the blocks are not ciphered independently. <A NAME="ElectricField"></A></P>
	<P>
	<DT><B>Electric Field</B></DT>
	<DD>The fundamental physical force resulting from the attraction of opposing charges. <A NAME="ElectromagneticField"></A>
	<P>
	<DT><B>Electromagnetic Field</B></DT>
	<DD>The remarkable self-propagating physical field consisting of energy distributed between <A HREF="Glossary.htm#ElectricField">electric</A>
	and <A HREF="Glossary.htm#MagneticField">magnetic</A> fields. Energy in the electric or potential field collapses and creates
	or &quot;charges up&quot; a magnetic field. Energy in the magnetic field collapses and &quot;charges up&quot; an
	electric field. This process allows physical electrical and magnetic fields -- two fairly short-range phenomena
	-- to &quot;propagate&quot; and thus carry energy over relatively large distances at the speed of light. Examples
	include light, &quot;radio&quot; waves (including TV, cell phones, etc.), and microwave cooking.
	<P>It is important to distinguish between a true electromagnetic field, and the simpler and range-limited electric
	and magnetic fields produced by an electrical clock, motor, or power lines. It is also important to distinguish
	between the light-like expanding or &quot;radiating&quot; property of an electromagnetic field, and the damaging
	ionizing radiation produced by a radioactive source.</P>
	<P>As far as we know -- and a great many experiments have been conducted on this -- electromagnetic waves are not
	life-threatening (unless they transfer enough power to dangerously heat the water in our cells). The belief that
	electromagnetic fields are not dangerous is also <I>reasonable,</I> since light itself is an electromagnetic wave,
	and life on Earth developed in the context of the electromagnetic field from the Sun. Indeed, plants actually use
	that field to their and our great benefit. <A NAME="Electronic"></A></P>
	<P>
	<DT><B>Electronic</B></DT>
	<DD>Having to do with the control and use of physical electrons, as electrical potential or <A HREF="Glossary.htm#Voltage">voltage</A>,
	electrical flow or <A HREF="Glossary.htm#Current">current</A>, and generally both. See <A HREF="Glossary.htm#Hardware">hardware</A> and
	<A HREF="Glossary.htm#Component">component</A>. <A NAME="Encipher"></A>
	<P>
	<DT><B>Encipher</B></DT>
	<DD>The process which will transform information or <A HREF="Glossary.htm#Plaintext">plaintext</A> into one of plethora of
	intermediate forms or <A HREF="Glossary.htm#Ciphertext">ciphertext</A>, as selected by a <A HREF="Glossary.htm#Key">key</A>. The inverse
	of <A HREF="Glossary.htm#Decipher">decipher</A>. <A NAME="Encryption"></A>
	<P>
	<DT><B>Encryption</B></DT>
	<DD>The general term for hiding information in secret <A HREF="Glossary.htm#Code">code</A> or <A HREF="Glossary.htm#Cipher">cipher</A>.
	<A NAME="Entropy"></A>
	<P>
	<DT><B>Entropy</B></DT>
	<DD>In information theory, our &quot;uncertainty&quot; as to the value of a <A HREF="Glossary.htm#RandomVariable">random variable</A>.
	Given the non-zero probability (<I>p</I>) of each value (<I>i</I>), we can calculate an entropy (<I>H</I>) in <A
	HREF="Glossary.htm#Bit">bits</A> for random variable <I>X</I> as:
	<PRE>   H(X) = -SUM( p<SUB>i</SUB> log2 p<SUB>i</SUB> )
</PRE>
	<P>Although entropy is sometimes taken as a measure of <A HREF="Glossary.htm#Random">randomness</A>, calculating entropy requires
	a knowledge of the probabilities of each value which we often can attain only by <A HREF="Glossary.htm#Sample">sampling</A>.
	This means that we do not <I>really</I> know the &quot;true&quot; probabilities, but only those we see in our samples.
	And the &quot;true&quot; probabilities may change through time.</P>
	<P>By itself, calculated entropy also does not detect any underlying order that might exist between value probabilities,
	such as a <A HREF="Glossary.htm#Correlation">correlation</A>, or a <A HREF="Glossary.htm#Linear">linear</A> relationship, or any other
	aspect of cryptographically-weak randomness. The &quot;true entropy&quot; of a <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A> is just the number of bits in the <A HREF="Glossary.htm#State">state</A> of that generator, as opposed
	to an entropy computation on the sequence it produces. So a high entropy value does <I>not</I> imply that a <A
	HREF="Glossary.htm#ReallyRandom">really-random</A> source really <I>is</I> random, or indeed have any relationship to the amount
	of cryptographic randomness present. <A NAME="Ergodic"></A></P>
	<P>
	<DT><B>Ergodic</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A> and information theory, a particularly &quot;simple&quot; and easily
	modelled <A HREF="Glossary.htm#StationaryProcess">stationary</A> (homogenous) <A HREF="Glossary.htm#Stochastic">stochastic</A> (random)
	<A HREF="Glossary.htm#Process">process</A> (function) in which the &quot;temporal average&quot; is the same as the &quot;ensemble
	average.&quot; In general, a process in which no <A HREF="Glossary.htm#State">state</A> is prevented from re-occurring. Ergodic
	processes are the basis for many important results in information theory, and are thus a technical requirement
	before those results can be applied.
	<P>Here we have all three possible sequences from a <B>non</B>-ergodic process: <B>across</B> we have the average
	of symbols through time (the &quot;temporal average&quot;), and <B>down</B> we have the average of symbols in a
	particular position over all possible sequences (the &quot;ensemble average&quot;):</P>
	<PRE>   A B A B A B ...   p(A) = 0.5, p(B) = 0.5, p(E) = 0.0
   B A B A B A ...   p(A) = 0.5, p(B) = 0.5, p(E) = 0.0
   E E E E E E ...   p(A) = 0.0, p(B) = 0.0, p(E) = 1.0
   ^ ^ ^ ^ ^ ^
   +-+-+-+-+-+----   p(A) = 0.3, p(B) = 0.3, p(E) = 0.3

(From:  Pierce, J.  1961.  <I>Symbols, Signals and Noise.</I>  Ch. 3)
</PRE>
	When a process is non-ergodic, the measurements we take over time from one or a few sequences may not represent
	all the sequences which may be encountered. <A NAME="Extractor"></A>
	<P>
	<DT><B>Extractor</B></DT>
	<DD>In a cryptographic context, an extractor is a <A HREF="Glossary.htm#Mechanism">mechanism</A> which produces the inverse
	effect of a <A HREF="Glossary.htm#Combiner">combiner</A>. This allows data to be enciphered in a combiner, and then deciphered
	in an extractor. Sometimes an extractor is exactly the same as the combiner, as is the case for exclusive-OR. <A
	NAME="ExclusiveOR"></A>
	<P>
	<DT><B>Exclusive-OR</B></DT>
	<DD>A Boolean <A HREF="Glossary.htm#LogicFunction">logic function</A> which is also <A HREF="Glossary.htm#Mod2">mod 2</A> addition. Also
	called <A HREF="Glossary.htm#XOR">XOR</A>. <A NAME="Factorial"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Factorial</B>
	<DD>The <I>factorial</I> of natural number <I>n,</I> written <B>n!</B>, is the product of all <A HREF="Glossary.htm#Integer">integers</A>
	from 1 to <I>n.</I>
	<P>See the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM#Factorials'" tppabs="http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM#Factorials">factorials</A> section of the <A
	HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages. <A NAME="Fallacy"></A></P>
	<P>
	<DT><B>Fallacy</B></DT>
	<DD>In the philosophical study of <A HREF="Glossary.htm#Logic">logic</A>, apparently-reasonable arguments which lead to false
	conclusions. Also see: <A HREF="Glossary.htm#InductiveReasoning">inductive reasoning</A> and <A HREF="Glossary.htm#DeductiveReasoning">deductive
	reasoning</A>. Including:
	<OL Type="A" STYLE="List-Style-Type : Upper-Alpha">
		<LI>Fallacies of Insufficient Evidence
		<OL Type="1" STYLE="List-Style-Type : Decimal">
			<LI>Accident -- a special circumstance makes a rule inapplicable
			<LI>Hasty Generalization
			<LI><I>non causa pro causa</I> (&quot;False Cause&quot;)
			<UL>
				<LI><I>post hoc ergo propter hoc</I> (&quot;after this therefore because of this&quot;)
				<LI><I>reductio ad absurdum</I> -- the assumption that a particular one of multiple assumptions is necessarily
				false if the argument leads to a contradiction.
			</UL>
			<LI><I>ad ignorantium</I> (&quot;Appeal to Ignorance&quot;) -- a belief which is assumed true because it is not
			proven false.
			<LI>Card Stacking -- a deliberate withholding of evidence which does not support the author's conclusions.
		</OL>
		<LI>Fallacies of Irrelevance (<I>ignoratio elenchi</I>) -- ignoring the question
		<OL Type="1" STYLE="List-Style-Type : Decimal">
			<LI><I>ad hominem</I> (&quot;Name Calling&quot;).
			<LI><I>ad populum</I> (&quot;Plain Folks&quot;) -- an appeal to the prejudices and biases of the audience.
			<LI><I>ad misericordiam</I> (&quot;Appeal to Pity&quot;)
			<LI><I>ad verecundiam</I> (&quot;Inappropriate Authority&quot;) -- a testimonial from someone with expertise in
			a different field.
			<LI><I>tu quoque</I> (&quot;You Did It Too&quot;).
			<LI><I>ad baculum</I> (&quot;Appeal to force&quot;) -- e.g., threats.
			<LI>Red Herring -- information used to throw the discussion off track.
			<LI>Opposition (&quot;Guilt by Association&quot;) -- to condemn an idea because of who is for it.
			<LI>Genetic -- attacking the source of the idea, rather than the idea itself.
			<LI>Bandwagon
		</OL>
		<LI>Fallacies of Ambiguity
		<OL Type="1" STYLE="List-Style-Type : Decimal">
			<LI>Equivocation -- the use of a word in a sense different than that understood by the reader.
			<LI>Amphiboly -- some sentences admit more than one interpretation.
			<LI>Accent -- some sentences have different meanings depending on which word is stressed.
			<LI>Composition -- the implication that what is true of the parts must also be true of the whole.
			<LI>Division -- the implication that what is true of the whole must be true of its parts.
			<LI>False Analogy
		</OL>
		<LI>Fallacies of the Misuse of Logic
		<OL Type="1" STYLE="List-Style-Type : Decimal">
			<LI><I>petitio principii</I> (&quot;Begging the Question&quot;) -- restating one of the premises as the conclusion;
			assuming the truth of a proposition which needs to be proven.
			<UL>
				<LI><I>circulus in probando</I> (&quot;Circular Argument&quot;)
			</UL>
			<LI><I>non sequitur</I> (&quot;Does Not Follow&quot;) -- the stated conclusion does not follow from the evidence
			supplied.
			<LI><I>plurimum interrogationum</I> (&quot;Complex Question&quot;) -- e.g., &quot;When did you stop beating your
			wife?&quot;
			<LI>Garbled Syllogism -- an illogical argument phrased in logical terms.
			<LI>Either-Or -- assuming a question has only two sides.
		</OL>
	</OL>
	<A NAME="FastWalshTransform"></A>
	<P>
	<DT><B>Fast Walsh Transform</B></DT>
	<DD>(Also Walsh-Hadamard transform.) When applied to a <A HREF="Glossary.htm#BooleanFunction">Boolean function</A>, a Fast
	Walsh Transform is essentially a correlation count between the given function and each Walsh function. Since the
	Walsh functions are essentially the <A HREF="Glossary.htm#AffineBooleanFunction">affine Boolean functions</A>, the FWT computes
	the <A HREF="Glossary.htm#UnexpectedDistance">unexpected distance</A> from a given function to each affine function. It does
	this in time proportional to <I>n</I> log n, for functions of <I>n</I> bits, with <I>n</I> some power of 2.
	<P>If two Boolean functions are <I>not</I> correlated, we expect them to agree half the time, which we might call
	the &quot;expected <A HREF="Glossary.htm#HammingDistance">distance</A>.&quot; When two Boolean functions <I>are</I> correlated,
	they will have a distance greater or less than the expected distance, and we might call this difference the <A
	HREF="Glossary.htm#UnexpectedDistance">unexpected distance</A> or UD. The UD can be positive or negative, representing distance
	to a particular affine function or its complement.</P>
	<P>It is easy to do a Fast Walsh Transform by hand. (Well, I say &quot;easy,&quot; then always struggle when I
	actually do it.) Let's do the FWT of function f: (1 0 0 1 1 1 0 0): First note that f has a binary power length,
	as required. Next, each pair of elements is modified by an &quot;in-place butterfly&quot;; that is, the values
	in each pair produce two results which replace the original pair, wherever they were originally located. The left
	result will be the two values added; the right will be the first less the second. That is,</P>
	<PRE>   (a',b') = (a+b, a-b)
</PRE>
	<P>So for the values (1,0), we get (1+0, 1-0) which is just (1,1). We start out pairing adjacent elements, then
	every other element, then every 4th element, and so on until the correct pairing is impossible, as shown:</P>
	<PRE>   original      1   0   0   1   1   1   0   0
                 ^---^   ^---^   ^---^   ^---^

      first      1   1   1  -1   2   0   0   0
                 ^-------^       ^-------^
                     ^-------^       ^-------^

     second      2   0   0   2   2   0   2   0
                 ^---------------^
                     ^---------------^
                         ^---------------^
                             ^---------------^

      final      4   0   2   2   0   0  -2   2
</PRE>
	<P>The result is the &quot;unexpected distance&quot; to each <A HREF="Glossary.htm#AffineBooleanFunction">affine Boolean function</A>.
	The higher the absolute value, the greater the &quot;linearity&quot;; if we want the <A HREF="Glossary.htm#Nonlinearity"><I>non</I>linearity</A>,
	we must subtract the absolute value of each unexpected distance from the expected value, which is half the number
	of bits in the function. Note that the range of possible values increases by a factor of 2 (in both positive and
	negative directions) in each sublayer mixing; this is information expansion, which we often try to avoid in cryptography.</P>
	<P>Also see: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/WALHAD.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/WALHAD.HTM'" tppabs="http://www.io.com/~ritter/RES/WALHAD.HTM">Walsh-Hadamard Transforms: A Literature Survey</A>,
	in the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers By Ritter</A> page, and the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM'" tppabs="http://www.io.com/~ritter/JAVASCRP/NONLMEAS.HTM">Active
	Boolean Function Nonlinearity Measurement in JavaScript</A> page of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers
	By Ritter / JavaScript</A> computation pages.</P>
	<P>The FWT provides a strong mathematical basis for <A HREF="Glossary.htm#BlockCipher">block cipher</A> mixing such that all
	input values will have an equal chance to affect all output values. Cryptographic mixing then occurs in butterfly
	operations based on <A HREF="Glossary.htm#BalancedBlockMixing">balanced block mixing</A> structures which replace the simple
	add / subtract butterfly in the FWT and confine the value ranges so information expansion does not occur. A related
	concept is the well-known <A HREF="Glossary.htm#FFT">FFT</A>, which can use exactly the same mixing patterns as the FWT. <A
	NAME="FCSR"></A></P>
	<P>
	<DT><B>FCSR</B></DT>
	<DD>Feedback with Carry Shift Register. A sequence generator analogous to a <A HREF="Glossary.htm#LFSR">LFSR</A>, but separately
	storing and using a &quot;carry&quot; value from the computation. <A NAME="FeistelConstruction"></A>
	<P>
	<DT><B>Feistel Construction</B></DT>
	<DD>The Feistel construction is the widely-known method of constructing block ciphers used in <A HREF="Glossary.htm#DES">DES</A>.
	Horst Feistel worked for IBM in the 60's and 70's, and was awarded a number of crypto patents, including: 3,768,359,
	3,768,360, and 4,316,055.
	<P>Normally, in a Feistel construction, the input block is split into two parts, one of which drives a transformation
	whose result is exclusive-OR combined into the other block. Then the &quot;other block&quot; value feeds the same
	transformation, whose result is exclusive-OR combined into the first block. This constitutes 2 of perhaps 16 &quot;<A
	HREF="Glossary.htm#Round">rounds</A>.&quot;</P>
	<PRE>     L          R
     |          |
     |--&gt; F --&gt; +    round 1
     |          |
     + &lt;-- F &lt;--|    round 2
     |          |
     v          v
     L'         R'
</PRE>
	<P>One advantage of the Feistel construction is that the transformation does not need to be invertible. To reverse
	any particular layer, it is only necessary to apply the same transformation again, which will undo the changes
	of the original exclusive-OR.</P>
	<P>A disadvantage of the Feistel construction is that <A HREF="Glossary.htm#Diffusion">diffusion</A> depends upon the internal
	transformation. There is no guarantee of <A HREF="Glossary.htm#OverallDiffusion">overall diffusion</A>, and the number of rounds
	required is often found by experiment. <A NAME="FencedDES"></A></P>
	<P>
	<DT><B>Fenced DES</B></DT>
	<DD>A <A HREF="Glossary.htm#BlockCipher">block cipher</A> with three <A HREF="Glossary.htm#Layer">layers</A>, in which the outer layers
	consist of <A HREF="Glossary.htm#Fencing">fencing</A> tables, and the inner layer consists of <A HREF="Glossary.htm#DES">DES</A> used as
	a <A HREF="Glossary.htm#Component">component</A>. For block widths over 64 bits, <A HREF="Glossary.htm#BalancedBlockMixing">Balanced Block
	Mixing</A> technology assures that any bit change is propagated to each DES operation.
	<P>Also see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#FencedTech'" tppabs="http://www.io.com/~ritter/#FencedTech">Fenced DES</A> section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page, and <A HREF="javascript:if(confirm('http://www.io.com/~ritter/KEYSHUF.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/KEYSHUF.HTM'" tppabs="http://www.io.com/~ritter/KEYSHUF.HTM">A Keyed Shuffling System for Block Cipher
	Cryptography</A>. <A NAME="Fencing"></A></P>
	<P>
	<DT><B>Fencing</B></DT>
	<DD>Fencing is a term-of-art which describes a layer of <A HREF="Glossary.htm#SubstitutionTable">substitution tables</A>. In
	schematic or data-flow diagrams, the row of tiny substitution boxes stands like a picket fence between the data
	on each side. <A NAME="FencingLayer"></A>
	<P>
	<DT><B>Fencing Layer</B></DT>
	<DD>A fencing <A HREF="Glossary.htm#Layer">layer</A> is a <A HREF="Glossary.htm#VariableSizeBlockCipher">variable size block cipher</A>
	layer composed of small (and therefore realizable) <A HREF="Glossary.htm#SimpleSubstitution">substitutions</A>. Typically the
	layer contains many separate <A HREF="Glossary.htm#Key">keyed</A> <A HREF="Glossary.htm#SubstitutionTable">substitution tables</A>. To
	make the layer extensible, either the substitutions can be re-used in some order, or in some pre-determined sequence,
	or the table to be used at each position selected by some computed value.
	<P><A HREF="Glossary.htm#Fencing">Fencing</A> layers are also used in other types of cipher. <A NAME="FFT"></A></P>
	<P>
	<DT><B>FFT</B></DT>
	<DD>Fast Fourier Transform. A numerically advantageous way of computing a <A HREF="Glossary.htm#FourierTransform">Fourier transform</A>.
	Basically a way of transforming information from <A HREF="Glossary.htm#Amplitude">amplitude</A> values sampled periodically
	through time, into amplitude values sampled periodically through complex <A HREF="Glossary.htm#Frequency">frequency</A>. The
	FFT performs this transformation in time proportional to n log n, for some n a power of 2.
	<P>While exceedingly valuable, the FFT tends to run into practical problems in use which can require a deep understanding
	of the process. For example, the transform assumes that the waveform is &quot;stationary&quot; and thus repetitive
	and continuous, which is rarely the case. As another example, sampling a continuous wave can create spurious &quot;frequency&quot;
	values related to the sampling and not the wave itself. Also the range of possible values increases by a factor
	of 2 (in both positive and negative directions) in every sublayer mixing; this is information expansion, which
	we often try to avoid in cryptography.</P>
	<P>The FFT provides a strong mathematical basis for <A HREF="Glossary.htm#BlockCipher">block cipher</A> mixing such that all
	input values will have an equal chance to affect all output values. Cryptographic mixing then occurs in butterfly
	operations based on <A HREF="Glossary.htm#BalancedBlockMixing">balanced block mixing</A> structures which replace the simple
	add / subtract butterfly in the FFT and confine the value ranges so information expansion does not occur. A related
	concept is the <A HREF="Glossary.htm#FastWalshTransform">fast Walsh-Hadamard transform</A> (FWT), which can use exactly the
	same mixing patterns as the FFT. <A NAME="Field"></A></P>
	<P>
	<DT><B>Field</B></DT>
	<DD>In abstract algebra, a commutative <A HREF="Glossary.htm#Ring">ring</A> in which all non-zero elements have a multiplicative
	inverse. (This means we can divide.)
	<P>In general, a field supports the four basic operations (addition, subtraction, multiplication and division),
	and satisfies the normal rules of arithmetic. An operation on any two elements in a field is a result which is
	also an element in the field.</P>
	<P>Examples of fields include rings of <A HREF="Glossary.htm#Integer">integers</A> <A HREF="Glossary.htm#Modulo">modulo</A> some <A HREF="Glossary.htm#Prime">prime</A>.
	Here are multiplication tables under mod 2, mod 3 and mod 4:</P>
	<PRE>        0  1             0  1  2             0  1  2  3

    0   0  0        0    0  0  0        0    0  0  0  0
    1   0  1        1    0  1  2        1    0  1  2  3
                    2    0  2  1        2    0  2  0  2
                                        3    0  3  2  1
</PRE>
	In a field, each element must have an inverse, and the product of an element and its inverse is 1. This means that
	every non-zero row and column of the multiplication table for a field must contain a 1. Since row 2 of the mod
	4 table does not contain a 1, the set of integers mod 4 is not a field.
	<P>The <I>order</I> of a field is the number of elements in that field. The integers mod <I>p</I> form a <A HREF="Glossary.htm#FiniteField">finite
	field</A> of order <I>p.</I> Similarly, <A HREF="Glossary.htm#Mod2Polynomial">mod 2 polynomials</A> will form a field with
	respect to an <A HREF="Glossary.htm#Irreducible">irreducible</A> <A HREF="Glossary.htm#Polynomial">polynomial</A>, and will have order
	2<SUP>n</SUP>, which is a very useful size. <A NAME="FiniteField"></A></P>
	<P>
	<DT><B>Finite Field</B></DT>
	<DD>A <A HREF="Glossary.htm#GaloisField">Galois field</A>: A mathematical <A HREF="Glossary.htm#Field">field</A> of non-infinite <A HREF="Glossary.htm#Order">order.</A>
	As opposed to an <I>infinite field,</I> such as the integers, rationals, reals and complex numbers.
	<P>
	<UL>
		<LI>In a finite field, every nonzero element <I>x</I> can be squared, cubed, and so on, and at some power will
		eventually become 1. The smallest (positive) power <I>n</I> at which <NOBR><I>x<SUP>n</SUP></I> = 1</NOBR> is the
		<I>order</I> of element <I>x</I>. This of course makes <I>x</I> an &quot;<I>nth <A HREF="Glossary.htm#Root">root</A> of unity,</I>&quot;
		in that it satisfies the equation <NOBR><I>x<SUP>n</SUP></I> = 1</NOBR>.
		<LI>A finite field of order <I>q</I> will have one or more <I><A HREF="Glossary.htm#Primitive">primitive</A></I> elements <I>a</I>
		whose order is <I>q</I>-1 and whose powers cover all nonzero field elements.
		<LI>For every element <I>x</I> in a finite field of order <I>q</I>, <NOBR><I>x<SUP>q</SUP> = x.</I></NOBR>
	</UL>
	<A NAME="FlipFlop"></A>
	<P>
	<DT><B>Flip-Flop</B></DT>
	<DD>A class of <A HREF="Glossary.htm#Digital">digital</A> <A HREF="Glossary.htm#Logic">logic</A> <A HREF="Glossary.htm#Component">component</A> which
	has a single <A HREF="Glossary.htm#Bit">bit</A> of <A HREF="Glossary.htm#State">state</A> with various control signals to effect a state
	change. There are several common versions:
	<UL>
		<P>
		<LI>Latch -- the output follows the input, but only while the <A HREF="Glossary.htm#Clock">clock</A> input is &quot;1&quot;;
		lowering the clock prevents the output from changing.
		<P>
		<LI>SR FF -- Set / Reset; typically created by cross-connecting two 2-input NAND <A HREF="Glossary.htm#Gate">gates</A>, in
		which case the inputs are complemented: a &quot;0&quot; on the S input forces a stable &quot;1&quot; state, which
		is held until a &quot;0&quot; on the R input forces a &quot;0&quot;.
		<P>
		<LI>D or &quot;delay&quot; FF -- senses the input value at the time of a particular <A HREF="Glossary.htm#Clock">clock</A>
		transition.
		<P>
		<LI>JK FF -- the J input is an <A HREF="Glossary.htm#AND">AND</A> enable for a clocked or synchronous transition to &quot;1&quot;;
		the K input is an AND enable for a clocked transition to &quot;0&quot;; and often there are S and R inputs to force
		&quot;1&quot; or &quot;0&quot; (respectively) asynchronously.
	</UL>
	<A NAME="FourierSeries"></A>
	<P>
	<DT><B>Fourier Series</B></DT>
	<DD>An infinite series in which the terms are constants (A, B) multiplied by sine or cosine functions of integer
	multiples (n) of the variable (x). One way to write this would be: <BIG>
	<PRE>   f(x) = A<SUB>0</SUB> + SUM (A<SUB>n</SUB> cos nx + B<SUB>n</SUB> sin nx)
</PRE>
</BIG>
	Alternately, over the interval [a, a+2c]:
	<PRE>   f(x) = a<SUB>0</SUB> + SUM ( a<SUB>n</SUB> cos(n PI x/c) + b<SUB>n</SUB> sin(n PI x/c) )
   a<SUB>n</SUB> = 1/c INTEGRAL[a,a+2c]( f(x) cos(n PI x/c) dx )
   b<SUB>n</SUB> = 1/c INTEGRAL[a,a+2c]( f(x) sin(n PI x/c) dx )
</PRE>
	<A NAME="FourierTheorem"></A>
	<P>
	<DT><B>Fourier Theorem</B></DT>
	<DD>Under suitable conditions any periodic function can be represented by a <A HREF="Glossary.htm#FourierSeries">Fourier series</A>.
	(Various other &quot;orthogonal functions&quot; are now known.)
	<P>The use of sine and cosine functions is particularly interesting, since each term represents a single <A HREF="Glossary.htm#Frequency">frequency</A>
	oscillation. So to the extent that we can represent an <A HREF="Glossary.htm#Amplitude">amplitude</A> waveform as a series
	of sine and cosine functions, we thus describe the frequency spectrum associated with that waveform. This frequency
	spectrum describes the frequencies which must be handled by a <A HREF="Glossary.htm#Circuit">circuit</A> to reproduce the original
	waveform. This illuminating computation is called a <A HREF="Glossary.htm#FourierTransform">Fourier transform</A>. <A NAME="FourierTransform"></A></P>
	<P>
	<DT><B>Fourier Transform</B></DT>
	<DD>The Fourier transform relates <A HREF="Glossary.htm#Amplitude">amplitude</A> samples at periodic discrete times to amplitude
	samples at periodic discrete <A HREF="Glossary.htm#Frequency">frequencies</A>. There are thus two representations: the amplitude
	vs. time waveform, and the amplitude vs. complex frequency (magnitude and phase) spectrum. Exactly the same information
	is present in either representation, and the transform supports converting either one into the other. This computation
	is efficiently performed by the <A HREF="Glossary.htm#FFT">FFT</A>.
	<P>In a cryptographic context, one of the interesting parts of the Fourier transform is that it represents a thorough
	<A HREF="Glossary.htm#Mixing">mixing</A> of each input value to every output value. <A NAME="Frequency"></A></P>
	<P>
	<DT><B>Frequency</B></DT>
	<DD>The number of repetitions or <I>cycles</I> per second. Now measured in Hertz (Hz); previously called cycles-per-second
	(cps). <A NAME="Function"></A>
	<P>
	<DT><B>Function</B></DT>
	<DD>A <A HREF="Glossary.htm#Mapping">mapping</A>; sometimes specifically confined to numbers. <A NAME="FWT"></A>
	<P>
	<DT><B>FWT</B></DT>
	<DD><A HREF="Glossary.htm#FastWalshTransform">Fast Walsh Transform</A>. <A NAME="Gain"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Gain</B>
	<DD>The <A HREF="Glossary.htm#Amplitude">amplitude</A> change due to <A HREF="Glossary.htm#Amplifier">amplification</A>. A negative gain
	is in fact a <I>loss.</I> <A NAME="GaloisField"></A>
	<P>
	<DT><B>Galois Field</B></DT>
	<DD><A HREF="Glossary.htm#FiniteField">Finite field</A>. First encountered by the 19-year-old student Evariste Galois, in 1830
	France, a year or so before dying in a duel. <A NAME="Gate"></A>
	<P>
	<DT><B>Gate</B></DT>
	<DD>A <A HREF="Glossary.htm#Digital">digital</A> <A HREF="Glossary.htm#Logic">logic</A> <A HREF="Glossary.htm#Component">component</A> which is a simple
	logic function, possibly with a complemented output. Some common <A HREF="Glossary.htm#Boolean">Boolean</A> logic gates include:
	<UL>
		<LI><A HREF="Glossary.htm#AND">AND</A>
		<LI><A HREF="Glossary.htm#OR">OR</A>
		<LI><A HREF="Glossary.htm#ExclusiveOR">Exclusive-OR</A>
		<LI>NAND -- <A HREF="Glossary.htm#AND">AND</A> with output complement
		<LI>NOR -- <A HREF="Glossary.htm#OR">OR</A> with output complement
		<LI>Exclusive-NOR -- <A HREF="Glossary.htm#ExclusiveOR">Exclusive-OR</A> with output complement
		<LI>NOT -- the complement
	</UL>
	<A NAME="GF2n"></A>
	<P>
	<DT><B>GF 2<SUP>n</SUP></B></DT>
	<DD>The <A HREF="Glossary.htm#GaloisField">Galois field</A> or <A HREF="Glossary.htm#FiniteField">finite field</A> of 2<SUP>n</SUP> <A
	HREF="Glossary.htm#Polynomial">polynomials</A> of degree n-1 or less.
	<P>Typically we have <A HREF="Glossary.htm#Mod2Polynomial">mod 2 polynomials</A> with results reduced &quot;modulo&quot; an
	<A HREF="Glossary.htm#Irreducible">irreducible</A> &quot;generator&quot; polynomial <I>g</I> of degree <I>n.</I> This is analogous
	to creating a <A HREF="Glossary.htm#Field">field</A> from the <A HREF="Glossary.htm#Integer">integers</A> <A HREF="Glossary.htm#Modulo">modulo</A>
	some <A HREF="Glossary.htm#Prime">prime</A> <I>p.</I></P>
	<P>For example, consider GF(2<SUP>4</SUP>) using the generator polynomial x<SUP>4</SUP> + x + 1, or 10011, which
	is a degree-4 <A HREF="Glossary.htm#Irreducible">irreducible</A>. First we multiply two elements as usual:</P>
	<PRE>          1 0 1 1
        * 1 1 0 0
        ----------
                0
              0
      1 0 1 1
    1 0 1 1
   ---------------
    1 1 1 0 1 0 0

</PRE>
	Then we &quot;reduce&quot; the result modulo the generator polynomial:
	<PRE>                        1 1 0
              ----------------
    1 0 0 1 1 ) 1 1 1 0 1 0 0
                1 0 0 1 1
                ---------
                  1 1 1 0 0
                  1 0 0 1 1
                  ---------
                    1 1 1 1 0
                    1 0 0 1 1
                    ---------
                        1 1 0 1
                       =========

</PRE>
	<P>So, if I did the arithmetic right, the result is the remainder, 1101. I refer to this as arithmetic &quot;mod
	2, mod p&quot;.</P>
	<P>An <A HREF="Glossary.htm#Irreducible">irreducible</A> is sufficient to form a finite field. However, some special irreducibles
	are also <A HREF="Glossary.htm#PrimitivePolynomial">primitive</A>, and these create &quot;maximal length&quot; sequences in
	<A HREF="Glossary.htm#LFSR">LFSR</A>'s. <A NAME="GoodnessOfFit"></A></P>
	<P>
	<DT><B>Goodness of Fit</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a test used to compare two <A HREF="Glossary.htm#Distribution">distributions</A>.
	For <A HREF="Glossary.htm#Nominal">nominal</A> or &quot;binned&quot; measurements, a <A HREF="Glossary.htm#ChiSquare">chi-square</A> test
	is common. For <A HREF="Glossary.htm#Ordinal">ordinal</A> or ordered measurements, a <A HREF="Glossary.htm#KolmogorovSmirnov">Kolmogorov-Smirnov</A>
	test is appropriate.
	<P>Goodness-of-fit tests can <I>at best</I> tell us whether one distribution <B>is</B> or <B>is not</B> the same
	as the other, and they say even <I>that</I> only with some probability. It is important to be very careful about
	experiment design, so that, almost always, &quot;nothing unusual found&quot; is the goal we seek. When we can match
	distributions, we are obviously able to state exactly what the experimental distribution should be and is. But
	there are <I>many</I> ways in which distributions can differ, and simply finding a difference is <I>not</I> evidence
	of a specific effect. (See <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>.) <A NAME="Group"></A></P>
	<P>
	<DT><B>Group</B></DT>
	<DD>In abstract algebra, a nonempty set <I>G</I> with one <A HREF="Glossary.htm#Dyadic">dyadic</A> (two-input, one-output)
	operation which we choose to call &quot;multiplication&quot; and denote * as usual. If elements (not necessarily
	numbers) <I>a, b</I> are in <I>R,</I> then <I>ab</I> (or <I>a*b</I>) is also in <I>R.</I> The following properties
	hold:
	<OL>
		<LI><B>Multiplication is associative:</B> (ab)c = a(bc)
		<LI><B>There is a multiplicative identity:</B> for e in G, ea = ae = a
		<LI><B>There is a multiplicative inverse:</B> for a in G, there is an a<SUP>-1</SUP> in G such that <NOBR>a<SUP>-1</SUP>a
		= e = aa<SUP>-1</SUP></NOBR>
	</OL>
	<P>A group is basically a <A HREF="Glossary.htm#Mapping">mapping</A> from two elements in the group, through the group operation
	<I>m,</I> into the same group: <BIG></P>
	<PRE>     <I>m</I>:G x G -&gt; G
</PRE>
</BIG>
	<A NAME="HammingDistance"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Hamming Distance</B>
	<DD>A measure of the difference or &quot;distance&quot; between two binary sequences of equal length; in particular,
	the number of bits which differ between the sequences. This is the <A HREF="Glossary.htm#Weight">weight</A> or the number of
	1-bits in the <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> of the two sequences. <A NAME="Hardware"></A>
	<P>
	<DT><B>Hardware</B></DT>
	<DD>The physical realization of computation. Typically, the <A HREF="Glossary.htm#Electronic">electronic</A> <A HREF="Glossary.htm#Digital">digital</A>
	<A HREF="Glossary.htm#Logic">logic</A>, power supply, and various electro-mechanical <A HREF="Glossary.htm#Component">components</A> such
	as disk drives, <A HREF="Glossary.htm#Switch">switches</A>, and possibly <A HREF="Glossary.htm#Relay">relays</A> which make up a <A HREF="Glossary.htm#Computer">computer</A>
	or other digital <A HREF="Glossary.htm#System">system</A>. As opposed to <A HREF="Glossary.htm#Software">software</A>. See <A HREF="Glossary.htm#SystemDesign">system
	design</A> and <A HREF="Glossary.htm#Debug">debug</A>. <A NAME="Hash"></A>
	<P>
	<DT><B>Hash</B></DT>
	<DD>A classic <A HREF="Glossary.htm#Computer">computer</A> operation which forms a fixed-size result from an arbitrary amount
	of data. Ideally, even the smallest change to the input data will change about half of the bits in the result.
	Often used for table look-up, so that very similar language terms or phrases will be well-distributed throughout
	the table. Also often used for error-detection, and, known as a <A HREF="Glossary.htm#MessageDigest">message digest</A>, <A
	HREF="Glossary.htm#Authentication">authentication</A>.
	<P>A hash of data will produce a particular hash value, which then can be included in the message before it is
	sent (or stored). When the data are received (or read) and the hash value computed, this should match the included
	hash value. So if the hash is different, something has changed, and the usual solution is to request the data be
	sent again. But the hash value is typically much smaller than the data, so there <I>must</I> be &quot;many&quot;
	different data sets which will produce that same value. This means that &quot;error detection&quot; inherently
	cannot detect all possible errors, and this is quite independent of any &quot;linearity&quot; in the hash computation.</P>
	<P>An excellent example of a hash function is a <A HREF="Glossary.htm#CRC">CRC</A> operation. CRC is a <A HREF="Glossary.htm#Linear">linear</A>
	function without cryptographic <A HREF="Glossary.htm#Strength">strength</A>, but does have a strong mathematical basis which
	is lacking in <I>ad hoc</I> methods. Strength is not needed when <A HREF="Glossary.htm#Key">keys</A> are processed into the
	<A HREF="Glossary.htm#State">state</A> used in a <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>, because if either
	the key or the state becomes known, the keyed <A HREF="Glossary.htm#Cipher">cipher</A> has been broken.</P>
	<P>In contrast, a <I>cryptographic</I> hash function must be &quot;strong&quot; in the sense that it must be &quot;computationally
	infeasible&quot; to find two input values which produce the same hash result. In general, this means that the hash
	result should be 128 bits or more in size.</P>
	<P>Sometimes a cryptographic hash function is described as being &quot;collision free,&quot; which is a misnomer.
	A collision occurs when two different texts produce exactly the same hash result. Given enough texts, collisions
	will of course occur, precisely because any fixed-size result has only so many possible code values. The intent
	is that collisions be hard to find and particular hash values impossible to create at will. <A NAME="Hexadecimal"></A></P>
	<P>
	<DT><B>Hexadecimal (Hex)</B></DT>
	<DD>Base 16. The numerical representation in which each digit has an <A HREF="Glossary.htm#Alphabet">alphabet</A> of sixteen
	symbols, generally 0 through 9, plus A through F, or &quot;a&quot; through &quot;f&quot;.
	<P>Each hex value represents exactly four <A HREF="Glossary.htm#Bit">bits</A>, which can be particularly convenient. Also see:
	<A HREF="Glossary.htm#Binary">binary</A>, <A HREF="Glossary.htm#Octal">octal</A>, and <A HREF="Glossary.htm#Decimal">decimal</A>. <A NAME="Homophonic"></A></P>
	<P>
	<DT><B>Homophonic</B></DT>
	<DD>Greek for &quot;the same sound.&quot; The concept of having different letter sequences which are pronounced
	alike. In <A HREF="Glossary.htm#Cryptography">cryptography</A>, a <A HREF="Glossary.htm#Cipher">cipher</A> which translates a single <A
	HREF="Glossary.htm#Plaintext">plaintext</A> symbol into any one of multiple <A HREF="Glossary.htm#Ciphertext">ciphertext</A> symbols which
	all have the same meaning. Also see <A HREF="Glossary.htm#Polyphonic">polyphonic</A>, <A HREF="Glossary.htm#Polygraphic">polygraphic</A>
	and <A HREF="Glossary.htm#Monographic">monographic</A>. <A NAME="HomophonicSubstitution"></A>
	<P>
	<DT><B>Homophonic Substitution</B></DT>
	<DD>A type of <A HREF="Glossary.htm#Substitution">substitution</A> in which an original symbol is replaced by any one of multiple
	unique symbols. Intended to combat the property of <A HREF="Glossary.htm#SimpleSubstitution">simple substitution</A> in which
	the most-frequent symbols in the <A HREF="Glossary.htm#Plaintext">plaintext</A> always produce the most-frequent symbols in
	the <A HREF="Glossary.htm#Ciphertext">ciphertext</A>.
	<P>A form of <A HREF="Glossary.htm#Homophonic">homophonic</A> substitution is available in a large <A HREF="Glossary.htm#BlockCipher">block
	cipher</A>, where a homophonic selection field is enciphered along with the plaintext. Any of the possible values
	for that field naturally will produce a unique ciphertext. After deciphering any of those ciphertexts, the homophonic
	selection field could be deleted, and the exact same plaintext recovered. Note that the ability to produce a multitude
	of different encipherings for exactly the same data is related to the concept of a <A HREF="Glossary.htm#Key">key</A>. <A NAME="IDEA"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>IDEA</B>
	<DD>The <A HREF="Glossary.htm#SecretKeyCipher">secret key</A> <A HREF="Glossary.htm#BlockCipher">block cipher</A> used in <A HREF="Glossary.htm#PGP">PGP</A>.
	Designed by James Massey and Xuejia Lai in several installments, called PES, IPES and IDEA. It is <A HREF="Glossary.htm#Round">round</A>-based,
	with a 64-bit <A HREF="Glossary.htm#Block">block</A> size, a 128-bit <A HREF="Glossary.htm#Key">key</A>, and no internal <A HREF="Glossary.htm#SubstitutionTable">tables</A>.
	<P>The disturbing aspect of the IDEA design is the extensive use of <I>almost</I> <A HREF="Glossary.htm#Linear">linear</A>
	operations, and no nonlinear tables at all. While technically <I>non</I>linear, the internal operations seem like
	they might well be linear <I>enough</I> to be attacked. <A NAME="IdealSecrecy"></A></P>
	<P>
	<DT><B>Ideal Secrecy</B></DT>
	<DD>The <A HREF="Glossary.htm#Strength">strength</A> delivered by even a simple <A HREF="Glossary.htm#Cipher">cipher</A> when each and
	every <A HREF="Glossary.htm#Plaintext">plaintext</A> is equally probable and independent of every other plaintext.
	<P>There are various examples:
	<UL>
		<LI>The use of <A HREF="Glossary.htm#CBC">CBC mode</A> in <A HREF="Glossary.htm#DES">DES</A>: By making every plaintext block equally probable,
		DES is greatly strengthened against <A HREF="Glossary.htm#CodebookAttack">codebook attack</A>.
		<LI>The transmission of <A HREF="Glossary.htm#Random">random</A> <A HREF="Glossary.htm#MessageKey">message key</A> values: To the extent
		that every value is equally probable, even a very simple cipher is sufficient to protect those values.
		<LI>The use of a keyed <A HREF="Glossary.htm#SimpleSubstitution">simple substitution</A> <I>of the ciphertext</I> to add strength,
		as used in the Penknife <A HREF="Glossary.htm#StreamCipher">stream cipher</A> design.
		<LI>The use of data compression to reduce the redundancy in a message before ciphering: This of course can only
		<I>reduce</I> language redundancy. (Also, many compression techniques send pre-defined tables before the data and
		so are not suitable in this application.)
	</UL>
	<P>Also see: <A HREF="Glossary.htm#PerfectSecrecy">perfect secrecy</A>. From Claude Shannon. <A NAME="i.i.d."></A></P>
	<P>
	<DT><B>i.i.d.</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>: Independent, Identically Distributed. Generally related to the <A
	HREF="Glossary.htm#Random">random</A> <A HREF="Glossary.htm#Sample">sampling</A> of a single <A HREF="Glossary.htm#Distribution">distribution</A>.
	<A NAME="InductiveReasoning"></A>
	<P>
	<DT><B>Inductive Reasoning</B></DT>
	<DD>In the study of <A HREF="Glossary.htm#Logic">logic</A>, reasoning from the observation of some particular cases to produce
	a general statement. While often incorrect, inductive reasoning does provide a way to go beyond known truth to
	new statements which may then be tested. And certain types of inductive reasoning can be assigned a correctness
	probability using <A HREF="Glossary.htm#Statistics">statisticical</A> techniques. Also see: <A HREF="Glossary.htm#DeductiveReasoning">deductive
	reasoning</A> and <A HREF="Glossary.htm#Fallacy">fallacy</A>. <A NAME="Inductor"></A>
	<P>
	<DT><B>Inductor</B></DT>
	<DD>A basic <A HREF="Glossary.htm#Electronic">electronic</A> <A HREF="Glossary.htm#Component">component</A> which acts as a reservoir for
	electrical power in the form of <A HREF="Glossary.htm#Current">current</A>. An inductor thus acts to &quot;even out&quot; the
	current flowing through it, and to &quot;emphasize&quot; current changes across the terminals. An inductor conducts
	<A HREF="Glossary.htm#DC">DC</A> and opposes <A HREF="Glossary.htm#AC">AC</A> in proportion to <A HREF="Glossary.htm#Frequency">frequency</A>. Inductance
	is measured in Henrys: A <A HREF="Glossary.htm#Voltage">voltage</A> of 1 Volt across an inductance of 1 Henry produces a current
	change of 1 Ampere per Second through the inductor.
	<P>Typically a coil or multiple turns of <A HREF="Glossary.htm#Conductor">conductor</A> wound on a magnetic or ferrous core.
	<A HREF="Glossary.htm#Current">Current</A> in the conductor creates a <A HREF="Glossary.htm#MagneticField">magnetic field</A>, thus &quot;storing&quot;
	charge. When power is removed, the magnetic field collapses to maintain the current flow; this can produce high
	voltages, as in automobile spark coils.</P>
	<P>Also see <A HREF="Glossary.htm#Capacitor">capacitor</A> and <A HREF="Glossary.htm#Resistor">resistor</A>. <A NAME="Injective"></A></P>
	<P>
	<DT><B>Injective</B></DT>
	<DD><A HREF="Glossary.htm#OneToOne">One-to-one</A>. A <A HREF="Glossary.htm#Mapping">mapping</A> f: <I>X -&gt; Y</I> where no two values
	<I>x</I> in <I>X</I> produce the same result <I>f(x)</I> in <I>Y.</I> A one-to-one mapping is invertible for those
	values of <I>X</I> which produce unique results <I>f(x)</I>, but there may not be a full inverse mapping g: <I>Y
	-&gt; X</I>. <A NAME="Insulator"></A>
	<P>
	<DT><B>Insulator</B></DT>
	<DD>A material in which electron flow is difficult or impossible. Classically air or vacuum, or wood, paper, glass,
	ceramic, plastic, etc. As opposed to a <A HREF="Glossary.htm#Conductor">conductor</A>. <A NAME="Integer"></A>
	<P>
	<DT><B>Integer</B></DT>
	<DD>An element in the set consisting of <I>counting</I> numbers: 1, 2, 3, ..., their negatives: -1, -2, -3, ...,
	and zero. <A NAME="IntermediateBlock"></A>
	<P>
	<DT><B>Intermediate Block</B></DT>
	<DD>In the context of a <A HREF="Glossary.htm#Layer">layered</A> <A HREF="Glossary.htm#BlockCipher">block cipher</A>, the data values produced
	by one layer then used by the next.
	<P>In some realizations, an intermediate <A HREF="Glossary.htm#Block">block</A> might be wired connections between layer <A
	HREF="Glossary.htm#Hardware">hardware</A>. In the context of a general purpose <A HREF="Glossary.htm#Computer">computer</A>, an intermediate
	block might represent the movement of data between operations, or perhaps transient storage in the original block.
	<A NAME="Interval"></A></P>
	<P>
	<DT><B>Interval</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, measurements in which the numerical value has meaning. Also see: <A
	HREF="Glossary.htm#Nominal">nominal</A>, and <A HREF="Glossary.htm#Ordinal">ordinal</A>. <A NAME="Into"></A>
	<P>
	<DT><B>Into</B></DT>
	<DD>A <A HREF="Glossary.htm#Mapping">mapping</A> f: <I>X -&gt; Y</I> which only partially covers Y. An inverse mapping g: <I>Y
	-&gt; X</I> may not exist if, for example, multiple elements <I>x</I> in <I>X</I> produce the same <I>f(x)</I>
	in <I>Y.</I>
	<PRE>   +----------+          +----------+
   |          |   INTO   | Y        |
   |    X     |          |   +----+ |
   |          |    f     |   |f(X)| |
   |          |   ---&gt;   |   +----+ |
   +----------+          +----------+
</PRE>
	<A NAME="Inverse"></A>
	<P>
	<DT><B>Inverse</B></DT>
	<DD>A <A HREF="Glossary.htm#Mapping">mapping</A> or function <I>g(y)</I> or <I>f <SUP>-1</SUP>(y),</I> related to some function
	<I>f(x)</I> such that for each <I>x</I> in <I>X</I>: <BIG>
	<PRE>   <I>g(f(x)) = x</I> = <I>f<SUP>-1</SUP>(f(x)).</I>
</PRE>
</BIG>
	Only functions which are <A HREF="Glossary.htm#OneToOne">one-to-one</A> can have an inverse. <A NAME="Invertible"></A>
	<P>
	<DT><B>Invertible</B></DT>
	<DD>A <A HREF="Glossary.htm#Mapping">mapping</A> or function which has an <A HREF="Glossary.htm#Inverse">inverse</A>. A transformation
	which can be reversed. <A NAME="Involution"></A>
	<P>
	<DT><B>Involution</B></DT>
	<DD>A type of <A HREF="Glossary.htm#Mapping">mapping</A> which is a self-inverse.
	<P>A cipher which takes <A HREF="Glossary.htm#Plaintext">plaintext</A> to <A HREF="Glossary.htm#Ciphertext">ciphertext,</A> and ciphertext
	back to plaintext, using the exact same operation. <A NAME="Irreducible"></A></P>
	<P>
	<DT><B>Irreducible</B></DT>
	<DD>A <A HREF="Glossary.htm#Polynomial">polynomial</A> only evenly divisible by itself and 1. The polynomial analogy to <A
	HREF="Glossary.htm#Integer">integer</A> <A HREF="Glossary.htm#Prime">primes</A>. Often used to generate a <I>residue class <A HREF="Glossary.htm#Field">field</A></I>
	for polynomial operations.
	<P>A polynomial form of the ever-popular &quot;<A HREF="Glossary.htm#SieveOfEratosthenes">Sieve of Eratosthenes</A>&quot; can
	be used to build table of irreducibles through degree 16. That table can then be used to check any potential irreducible
	through degree 32. While slow, this can be a simple, clear validation of other techniques.</P>
	<P>Also see <A HREF="Glossary.htm#PrimitivePolynomial">primitive polynomial</A>. <A NAME="IV"></A></P>
	<P>
	<DT><B>IV</B></DT>
	<DD>&quot;Initial value,&quot; &quot;initializing value&quot; or &quot;initialization vector.&quot; An external
	value needed to start off <A HREF="Glossary.htm#Cipher">cipher</A> operations. Most often associated with <A HREF="Glossary.htm#CBC">CBC</A>
	mode.
	<P>An IV often can be seen as a design-specific form of <A HREF="Glossary.htm#MessageKey">message key</A>. Sometimes, iterative
	ciphering under different IV values can provide sufficient keying to perform the message key function.</P>
	<P>Generally, an IV must be accompany the <A HREF="Glossary.htm#Ciphertext">ciphertext</A>, and so always expands the ciphertext
	by the size of the IV. <A NAME="Jitterizer"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Jitterizer</B>
	<DD>A particular cryptographic mechanism intended to complicate the sequence produced by a linear <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A> by deleting elements from the sequence at pseudo-random.
	<P>The name is taken from the use of an oscilloscope on digital circuits, where a signal which is not &quot;in
	sync&quot; is said to &quot;jitter.&quot; Mechanisms designed to restore synchronization are called &quot;synchronizers,&quot;
	so mechanisms designed to cause jitter can legitimately be called &quot;jitterizers.&quot; <A NAME="KB"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>KB</B>
	<DD>Kilobyte. 2<SUP>10</SUP> or 1024 <A HREF="Glossary.htm#Byte">bytes</A>. <A NAME="Kb"></A>
	<P>
	<DT><B>Kb</B></DT>
	<DD>Kilobit. 2<SUP>10</SUP> or 1024 <A HREF="Glossary.htm#Bit">bits</A>. <A NAME="KerckhoffsRequirements"></A>
	<P>
	<DT><B>Kerckhoff's Requirements</B></DT>
	<DD>General cryptosystem requirements formulated in 1883 (from the Handbook of Applied Cryptography):
	<P>
	<OL>
		<A NAME="Kerckhoff1"></A>
		<LI><B>The system should be, if not theoretically unbreakable, unbreakable in practice.</B> (Of course there <I>are</I>
		no realized systems which are &quot;theoretically unbreakable,&quot; but there is also little point in using a
		known <A HREF="Glossary.htm#Break">breakable</A> <A HREF="Glossary.htm#Cipher">cipher</A>.) <A NAME="Kerckhoff2"></A>
		<LI><B>Compromise of the system details should not inconvenience the correspondents.</B> (Nowadays we generally
		<I>assume</I> that the <A HREF="Glossary.htm#Opponent">Opponent</A> will have full details of the cipher, since, for a cipher
		to be widely used, it must be present at many locations and is therefore likely to be exposed. We also assume that
		the Opponent will have some amount of <A HREF="Glossary.htm#KnownPlaintextAttack">known-plaintext</A> to work with.) <A NAME="Kerckhoff3"></A>
		<LI><B>The <A HREF="Glossary.htm#Key">key</A> should be rememberable without notes and easily changed.</B> (This is still an
		issue. <A HREF="Glossary.htm#Hash">Hashing</A> allows us to use long language phrases, but the best approach may someday be
		to have both a <A HREF="Glossary.htm#Hardware">hardware</A> key card <I>and</I> a key phrase.) <A NAME="Kerckhoff4"></A>
		<LI><B>The cryptogram should be transmissible by telegraph.</B> (This is not very important nowadays, since even
		<A HREF="Glossary.htm#Binary">binary</A> <A HREF="Glossary.htm#Ciphertext">ciphertext</A> can be converted into <A HREF="Glossary.htm#ASCII">ASCII</A>
		for transmission if necessary.) <A NAME="Kerckhoff5"></A>
		<LI><B>The <A HREF="Glossary.htm#Encryption">encryption</A> apparatus should be portable and operable by a single person.</B>
		(<A HREF="Glossary.htm#Software">Software</A> encryption approaches this ideal.) <A NAME="Kerckhoff6"></A>
		<LI><B>The system should be easy, requiring neither the knowledge of a long list of rules nor mental strain.</B>
		(Software encryption has the <I>potential</I> to approach this, but often fails to do so. We might think of the
		need to certify <A HREF="Glossary.htm#PublicKeyCipher">public keys</A>, which is still often left up to the user, and thus
		often does not occur.)
	</OL>
	<A NAME="Key"></A>
	<P>
	<DT><B>Key</B></DT>
	<DD>The general concept of protecting things with a &quot;lock,&quot; thus making those things available only if
	one has the correct &quot;key.&quot; In a <A HREF="Glossary.htm#Cipher">cipher</A>, the ability to select a particular transformation
	between a <A HREF="Glossary.htm#Plaintext">plaintext</A> message and a corresponding <A HREF="Glossary.htm#Ciphertext">ciphertext</A>.
	By using a particular key, we can create any one of many different ciphertexts for the exact same message. And
	if we know the correct key, we can transform the ciphertext back into the original message. By supporting a vast
	number of different key possibilities (a large <A HREF="Glossary.htm#Keyspace">keyspace</A>), we hope to make it impossible
	for someone to decipher the message by trying every key in a <A HREF="Glossary.htm#BruteForceAttack">brute force attack</A>.
	<P>In <A HREF="Glossary.htm#Cryptography">cryptography</A> we have various kinds of keys, including a User Key (the key which
	a user actually remembers), which may be the same as an Alias Key (the key for an alias file which relates correspondent
	names with their individual keys). We may also have an Individual Key (the key actually used for a particular correspondent);
	a <A HREF="Glossary.htm#MessageKey">Message Key</A> (normally a random value which differs for each and every message); a <A
	HREF="Glossary.htm#RunningKey">Running Key</A> (the confusion sequence in a <A HREF="Glossary.htm#StreamCipher">stream cipher</A>, normally
	produced by a <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>); and perhaps other forms of key as
	well.</P>
	<P>In general, the value of a cryptographic key is used to initialize the <A HREF="Glossary.htm#State">state</A> of a <A HREF="Glossary.htm#CryptographicMechanism">cryptographic
	mechanism</A>.</P>
	<P>Ideally, a key will be a equiprobable selection among a huge number of possibilities. This is the fundamental
	strength of cryptography, the &quot;needle in a haystack&quot; of false possibilities. But if a key is in some
	way <I>not</I> a random selection, but is instead <I>biased,</I> the most-likely keys can be examined first, thus
	reducing the complexity of the search and the effective <A HREF="Glossary.htm#Keyspace">keyspace</A>.</P>
	<P>In most cases, a key will exhibit <A HREF="Glossary.htm#Diffusion">diffusion</A> across the message; that is, changing even
	one bit of a key should change every bit in the message with probability 0.5. A key with lesser diffusion may succumb
	to some sort of <A HREF="Glossary.htm#DivideAndConquer">divide and conquer</A> attack. <A NAME="KeyDistributionProblem"></A></P>
	<P>
	<DT><B>Key Distribution Problem</B></DT>
	<DD>The problem of distributing <A HREF="Glossary.htm#Key">keys</A> to both ends of a communication path, especially in the
	case of <A HREF="Glossary.htm#SecretKeyCipher">secret key ciphers</A>, since secret keys must be transported and held in absolute
	secrecy. Also the problem of distributing vast numbers of keys, if each user is given a separate key.
	<P>Although this problem is supposedly &quot;solved&quot; by the advent of the <A HREF="Glossary.htm#PublicKeyCipher">public
	key cipher</A>, in fact, the necessary public key validation is almost as difficult as the original problem. Although
	public keys can be <I>exposed,</I> they must represent who they claim to represent, or a &quot;spoofer&quot; or
	<A HREF="Glossary.htm#ManInTheMiddleAttack">man-in-the-middle</A> can operate undetected.</P>
	<P>Nor does it make sense to give each individual a separate secret key, when a related group of people would have
	access to the same files anyway. Typically, a particular group has the same secret key, which will of course be
	changed when any member leaves. Typically, each individual would have a secret key for each group with whom he
	or she associates. <A NAME="Keyspace"></A></P>
	<P>
	<DT><B>Keyspace</B></DT>
	<DD>The number of distinct <A HREF="Glossary.htm#Key">key</A>-selected transformations supported by a particular <A HREF="Glossary.htm#Cipher">cipher</A>.
	Normally described in terms of <A HREF="Glossary.htm#Bit">bits</A>, as in the number of bits needed to count every distinct
	key. This is also the amount of <A HREF="Glossary.htm#State">state</A> required to support a state value for each key. The
	keyspace in bits is the log<SUB>2</SUB> (the base-2 logarithm) of the number of different keys, provided that all
	keys are equally probable.
	<P><A HREF="Glossary.htm#Cryptography">Cryptography</A> is based on the idea that if we have a huge number of keys, and select
	one at <A HREF="Glossary.htm#Random">random</A>, The <A HREF="Glossary.htm#Opponent">Opponents</A> generally must search about half of
	the possible keys to find the correct one; this is a <A HREF="Glossary.htm#BruteForceAttack">brute force attack</A>.</P>
	<P>Although brute force is not the only possible <A HREF="Glossary.htm#Attack">attack</A>, it is the one attack which will
	always exist. Therefore, the ability to resist a brute force attack is normally the &quot;design strength&quot;
	of a cipher. All other attacks should be made even more expensive. To make a brute force attack expensive, a cipher
	simply needs a keyspace large enough to resist such an attack. Of course, a brute force attack may use new computational
	technologies such as DNA or &quot;molecular computation.&quot; Currently, 120 bits is large enough to prevent even
	unimaginably large uses of such new technology.</P>
	<P>It is probably just as easy to build efficient ciphers which use huge keys as it is to build ciphers which use
	small keys, and the cost of storing huge keys is probably trivial. Thus, large keys may be useful when this leads
	to a better cipher design, perhaps with less key processing. Such keys, however, cannot be considered better at
	resisting a brute force attack than a 120-bit key, since 120 bits is already sufficient. <A NAME="KeyedSubstitution"></A></P>
	<P>
	<DT><B>Keyed Substitution</B></DT>
	<DD>Two <A HREF="Glossary.htm#SubstitutionTable">substitution tables</A> of the same size with the same values can differ only
	in the ordering or <A HREF="Glossary.htm#Permutation">permutation</A> of the values in the tables. A huge <A HREF="Glossary.htm#Key">keying</A>
	potential exists: The typical &quot;n-bit-wide&quot; substitution table has 2<SUP>n</SUP> elements, and (2<SUP>n</SUP>)!
	(&quot;two to the nth factorial&quot;) different permutations or key possibilities. A single 8-bit substitution
	table has a <A HREF="Glossary.htm#Keyspace">keyspace</A> of 1648 bits.
	<P>A substitution table is keyed by creating a <I>particular</I> ordering from each different key. This can be
	accomplished by <A HREF="Glossary.htm#Shuffle">shuffling</A> the table under the control of a <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A> which is initialized from the key. <A NAME="KnownPlaintextAttack"></A></P>
	<P>
	<DT><B>Known Plaintext Attack</B></DT>
	<DD>A type of <A HREF="Glossary.htm#Attack">attack</A> in which the cryptanalyst has some quantity of related <A HREF="Glossary.htm#Plaintext">plaintext</A>
	and <A HREF="Glossary.htm#Ciphertext">ciphertext</A>. This allows the ciphering transformation to be examined directly.
	<P>A known plaintext attack is especially dangerous to the usual <A HREF="Glossary.htm#StreamCipher">stream cipher</A> which
	has an <A HREF="Glossary.htm#AdditiveCombiner">additive combiner</A>, because the known plaintext can be &quot;subtracted&quot;
	from the ciphertext, thus completely exposing the <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A>. This is
	the sequence produced by the cryptographic <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>, and can
	be used to attack that generator. This sort of attack can generally be prevented by using a <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic
	Substitution Combiner</A> instead of the usual additive combiner.</P>
	<P>It is surprisingly reasonable that <A HREF="Glossary.htm#Opponent">The Opponent</A> might well have some known plaintext
	(and related ciphertext): This might be the return address on a letter, a known report, or even some suspected
	words. Sometimes the cryptosystem will carry unauthorized messages like birthday greetings which are then exposed,
	due to their apparently innocuous content. <A NAME="KolmogorovSmirnov"></A></P>
	<P>
	<DT><B>Kolmogorov-Smirnov</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a <A HREF="Glossary.htm#GoodnessOfFit">goodness of fit</A> test used to compare
	two <A HREF="Glossary.htm#Distribution">distributions</A> of <A HREF="Glossary.htm#Ordinal">ordinal</A> data, where measurements may be
	re-arranged and placed in order. Also see <A HREF="Glossary.htm#ChiSquare">chi-square</A>.
	<P>
	<UL>
		<LI><I>n</I> independent samples are collected and arranged in numerical order in array <I>X</I> as <I>x</I>[0]..<I>x</I>[<I>n</I>-1].
		<LI><I>S</I>(<I>x</I>[<I>j</I>]) is the fraction of the <I>n</I> observations which are less than or equal to <I>x</I>[<I>j</I>];
		in the ordered array this is just ((<I>j</I>+1)/<I>n</I>).
		<LI><I>F</I>(<I>x</I>) is the reference cumulative distribution, the probability that a random value will be less
		than or equal to <I>x</I>. Here we want <I>F</I>(<I>x</I>[<I>j</I>]), the fraction of the distribution to the left
		of <I>x</I>[<I>j</I>] which is a value from the array.
	</UL>
	<P>The &quot;one-sided&quot; statistics are:</P>
	<PRE>   K<SUP>+</SUP> = SQRT(N) * MAX( S(x[j]) - F(x[j]) )
      = SQRT(N) * MAX( ((j+1)/n) - F(x[j]) )

   K<SUP>-</SUP> = SQRT(N) * MAX( F(x[j]) - S(x[j]) )
      = SQRT(N) * MAX( F(x[j]) - (j/n) )
</PRE>
	<P>And the &quot;two-sided&quot; KS statistic is:</P>
	<PRE>   K = SQRT(N) * MAX( ABS( S(x[j]) - F(x[j]) ) )
     = MAX( K<SUP>+</SUP>, K<SUP>-</SUP> )
</PRE>
	<P>It appears that the &quot;one-sided&quot; KS distribution is far easier to compute precisely, and may be preferred
	on that basis.</P>
	<P>See the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/NORMCHIK.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/NORMCHIK.HTM#KolSmir'" tppabs="http://www.io.com/~ritter/JAVASCRP/NORMCHIK.HTM#KolSmir">Kolmogorov-Smirnov</A> section of
	the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages. <A NAME="Latency"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Latency</B>
	<DD>A form of delay. Typically a <A HREF="Glossary.htm#Hardware">hardware</A> term, latency often refers to the time need to
	perform an operation. In the past, operation delay has largely been dominated by the time taken for <A HREF="Glossary.htm#Gate">gate</A>
	<A HREF="Glossary.htm#Switch">switching</A> <A HREF="Glossary.htm#Transistor">transistors</A> to turn on and off. Currently, operation
	delay is more often dominated by the time it takes to transport the <A HREF="Glossary.htm#Electrical">electrical</A> signals
	to and from gates on long, thin <A HREF="Glossary.htm#Conductor">conductors</A>.
	<P>The effect of latency on throughput can often be reduced by <I>pipelining</I> or partitioning the main operation
	into many small sub-operations, and running each of those <I>in parallel,</I> or at the same time. As each operation
	finishes, that result is latched and saved temporarily, pending the availability of the next sub-operation hardware.
	The result is throughput limited only by the longest sub-operation instead of the overall operation. <A NAME="LatinSquare"></A></P>
	<P>
	<DT><B>Latin Square</B></DT>
	<DD>A Latin square of order <I>n</I> is an <I>n</I> by <I>n</I> array containing symbols from some alphabet of
	size <I>n</I>, arranged such that each symbol appears exactly once in each row and exactly once in each column.
	Also see <A HREF="Glossary.htm#LatinSquareCombiner">Latin square combiner</A> and <A HREF="Glossary.htm#OrthogonalLatinSquares">orthogonal
	Latin squares</A>.
	<PRE>   2  0  1  3
   1  3  0  2
   0  2  3  1
   3  1  2  0
</PRE>
	<P>Also see: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/LATSQ.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/LATSQ.HTM'" tppabs="http://www.io.com/~ritter/RES/LATSQ.HTM">Latin Squares: A Literature Survey</A>, in the <A
	HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page. <A NAME="LatSqComb"></A> <A NAME="LatinSquareCombiner"></A></P>
	<P>
	<DT><B>Latin Square Combiner</B></DT>
	<DD>A <A HREF="Glossary.htm#Cryptography">cryptographic</A> <A HREF="Glossary.htm#Combiner">combining</A> <A HREF="Glossary.htm#Mechanism">mechanism</A>
	in which one input selects a column and the other input selects a row in an existing <A HREF="Glossary.htm#LatinSquare">Latin
	square</A>; the value of the selected element is the combiner result.
	<P>A Latin square combiner is inherently <A HREF="Glossary.htm#Balance">balanced</A>, because for any particular value of one
	input, the other input can produce any possible output value. A Latin square can be treated as an array of <A HREF="Glossary.htm#SubstitutionTable">substitution
	tables</A>, each of which are invertible, and so can be reversed for use in a suitable <A HREF="Glossary.htm#Extractor">extractor</A>.
	As usual with cryptographic combiners, if we know the output and a specific one of the inputs, we can extract the
	value of the other input.</P>
	<P>For example, a tiny Latin square combiner might combine two 2-bit values each having the range zero to three
	(0..3). That Latin square would contain four different symbols (here 0, 1, 2, and 3), and thus be a square of order
	4:</P>
	<PRE>   2  0  1  3
   1  3  0  2
   0  2  3  1
   3  1  2  0
</PRE>
	<P>With this square we can combine the values 0 and 2 by selecting the top row (row 0) and the third column (column
	2) and returning the value 1.</P>
	<P>When extracting, we will know a specific one (but only one) of the two input values, and the result value. Suppose
	we know that row 0 was selected during combining, and that the output was 1: We can check for the value 1 in each
	column at row 0 and find column 2, but this involves searching through all columns. We can avoid this overhead
	by creating the row-inverse of the original Latin square (the inverse of each row), in the well-known way we would
	create the inverse of any invertible substitution. For example, in row 0 of the original square, selection 0 is
	the value 2, so, in the row-inverse square, selection 2 should be the value 0, and so on:</P>
	<PRE>   1  2  0  3
   2  0  3  1
   0  3  1  2
   3  1  2  0
</PRE>
	<P>Then, knowing we are in row 0, the value 1 is used to select the second column, returning the unknown original
	value of 2.</P>
	<P>A practical Latin square combiner might combine two bytes, and thus be a square of order 256, with 65,536 byte
	entries. In such a square, each 256-element column and each 256-element row would contain each of the values from
	0 through 255 exactly once. <A NAME="Layer"></A></P>
	<P>
	<DT><B>Layer</B></DT>
	<DD>In the context of <A HREF="Glossary.htm#BlockCipher">block cipher</A> design, a layer is particular transformation or set
	of operations applied across the <A HREF="Glossary.htm#Block">block</A>. In general, a layer is applied once, and different
	layers have different transformations. As opposed to <A HREF="Glossary.htm#Round">rounds</A>, where a single transformation
	is repeated in each round.
	<P>Layers can be <A HREF="Glossary.htm#Confusion">confusion</A> layers (which simply change the block value), <A HREF="Glossary.htm#Diffusion">diffusion</A>
	layers (which propagate changes across the block in at least one direction) or both. In some cases it is useful
	to do multiple operations as a single layer to avoid the need for internal temporary storage blocks. <A NAME="LFSR"></A></P>
	<P>
	<DT><B>LFSR</B></DT>
	<DD><A HREF="Glossary.htm#LinearFeedbackShiftRegister">Linear Feedback Shift Register</A>. <A NAME="Linear"></A>
	<P>
	<DT><B>Linear</B></DT>
	<DD>Like a line; having an equation of the form <B><TTY>ax + b</B><B></TTY></B> .
	<P>There are various ways a relationship can be linear. One way is to consider <I>a, x,</I> and <I>b</I> as <A
	HREF="Glossary.htm#Integer">integers</A>. Another is for them to be <A HREF="Glossary.htm#Polynomial">polynomial</A> elements of <A HREF="Glossary.htm#GF2n">GF(2<SUP>n</SUP>)</A>.
	Yet another is to consider <B>a</B> to be an <I>n</I> by <I>n</I> matrix, with <B>x</B> and <B>b</B> as <I>n</I>-element
	vectors. There are probably various other ways as well.</P>
	<P>Linearity also depends upon our point of view: For example, integer addition <I>is</I> linear in the integers,
	but when expressed as <A HREF="Glossary.htm#Mod2">mod 2</A> operations, the exact same computation producing the exact same
	results is <I>not</I> considered linear.</P>
	<P>In cryptography the issue may not be as much one of strict mathematical linearity as it is the &quot;distance&quot;
	between a function and some linear approximation (see <A HREF="Glossary.htm#BooleanFunctionNonlinearity">Boolean function nonlinearity</A>).
	True linear functions are used because they are easy and fast, but they are also exceedingly weak. Of course <A
	HREF="Glossary.htm#XOR">XOR</A> is linear and trivial, yet is used all the time in arguably <A HREF="Glossary.htm#Strength">strong</A>
	ciphers. But a design using linear <A HREF="Glossary.htm#Component">components</A> must have other nonlinear components to
	provide strength. <A NAME="LinearComplexity"></A></P>
	<P>
	<DT><B>Linear Complexity</B></DT>
	<DD>The length of the shortest <A HREF="Glossary.htm#LinearFeedbackShiftRegister">Linear Feedback Shift Register</A> which
	can produce a given sequence.
	<P>Also see: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/LINCOMPL.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/LINCOMPL.HTM'" tppabs="http://www.io.com/~ritter/RES/LINCOMPL.HTM">Linear Complexity: A Literature Survey</A>, in
	the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the <A
	HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers By Ritter</A> page. <A NAME="LinearFeedbackShiftRegister"></A></P>
	<P>
	<DT><B>Linear Feedback Shift Register</B></DT>
	<DD>An efficient structure for producing sequences, often used in <A HREF="Glossary.htm#RandomNumberGenerator">random number
	generator</A> applications.
	<P>In an <I>n</I>-element <A HREF="Glossary.htm#ShiftRegister">shift register</A> (SR), if the last element is connected to
	the first element, a set of <I>n</I> values can circulate around the SR in <I>n</I> steps. But if the values in
	two of the elements are combined by <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> and that result connected to the first
	element, it is possible to get an almost-perfect <A HREF="Glossary.htm#MaximalLength">maximal length</A> sequence of 2<SUP>n</SUP>-1
	steps. (The all-zeros state will produce another all-zeros state, and so the system will &quot;lock up&quot; in
	a degenerate cycle.) Because there are only 2<SUP>n</SUP> different states of <I>n</I> binary values, every state
	value but one must occur exactly once, which is a statistically-satisfying result. Moreover, the values so produced
	are a perfect permutation of the &quot;counting&quot; numbers (1..2<SUP>n</SUP>-1).</P>
	<PRE>     A Linear Feedback Shift Register

         +----+    +----+    +----+    +----+    +----+  &quot;a0&quot;
     +-&lt;-| a5 |&lt;---| a4 |&lt;-*-| a3 |&lt;---| a2 |&lt;---| a1 |&lt;--+
     |   +----+    +----+  | +----+    +----+    +----+   |
     |                     v                              |
     +------------------&gt; (+) ----------------------------+

       1         0         1         0         0         1
</PRE>
	<P>In the figure we have a LFSR of degree 5, consisting of 5 storage elements a[5]..a[1] and the feedback computation
	a[0]=a[5]+a[3]. The stored values may be <A HREF="Glossary.htm#Bit">bits</A> and the operation (+) addition <A HREF="Glossary.htm#Mod2">mod
	2</A>. A <A HREF="Glossary.htm#Clock">clock</A> edge will simultaneously shift all elements left, and load element a[1] with
	the feedback result as it was before the clock changed the register. Each SR element is just a time-delayed replica
	of the element before it, and here the element subscript conveniently corresponds to the delay. We can describe
	this logically:</P>
	<PRE>   a[1][t+1] = a[5][t] + a[3][t];
   a[2][t+1] = a[1][t];
   a[3][t+1] = a[2][t];
   a[4][t+1] = a[3][t];
   a[5][t+1] = a[4][t];
</PRE>
	<P>Normally the time distinction is ignored, and we can write more generally, for some feedback <A HREF="Glossary.htm#Polynomial">polynomial</A>
	C and <A HREF="Glossary.htm#State">state</A> polynomial A of degree <I>n</I>:</P>
	<PRE>           n
   a[0] = SUM  c[i]*a[i]
          i=1
</PRE>
	<P>The feedback polynomial shown here is 101001, a degree-5 poly running from c[5]..c[0] which is also <A HREF="Glossary.htm#Irreducible">irreducible</A>.
	Since we have degree 5 which is a <A HREF="Glossary.htm#MersennePrime">Mersenne prime</A>, C is also <A HREF="Glossary.htm#PrimitivePolynomial">primitive</A>.
	So C produces a <A HREF="Glossary.htm#MaximalLength">maximal length</A> sequence of exactly 31 steps, provided only that A
	is not initialized as zero. Whenever C is irreducible, the reversed polynomial (here 100101) is also irreducible,
	and will also produce a maximal length sequence.</P>
	<P>LFSR's are often used to generate the <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> for <A HREF="Glossary.htm#StreamCipher">stream
	ciphers</A>, but this is very dangerous: LFSR's are inherently <A HREF="Glossary.htm#Linear">linear</A> and thus weak. Knowledge
	of the feedback polynomial and only <I>n</I> element values (from <A HREF="Glossary.htm#KnownPlaintextAttack">known plaintext</A>)
	is sufficient to run the sequence backward or forward. And knowledge of only 2<I>n</I> elements is sufficient to
	develop an unknown feedback polynomial. This means that LFSR's should not be used as stream ciphers without in
	some way isolating the sequence from analysis. Also see <A HREF="Glossary.htm#Jitterizer">jitterizer</A> and <A HREF="Glossary.htm#AdditiveRNG">additive
	RNG</A>. <A NAME="LinearLogicFunction"></A></P>
	<P>
	<DT><B>Linear Logic Function</B></DT>
	<DD>A Boolean switching or <A HREF="Glossary.htm#LogicFunction">logic function</A> which can be realized using only <A HREF="Glossary.htm#XOR">XOR</A>
	and <A HREF="Glossary.htm#AND">AND</A> types of functions, which correspond to addition <A HREF="Glossary.htm#Mod2">mod 2</A> and multiplication
	mod 2, respectively. <A NAME="Logic"></A>
	<P>
	<DT><B>Logic</B></DT>
	<DD>A branch of philosophy related to distinguishing between correct and incorrect reasoning. Even an invalid argument
	can sometimes produce a correct conclusion. But a <I>valid</I> argument must <I>always</I> produce a correct conclusion.
	<P>Also devices which realize symbolic logic, such as <A HREF="Glossary.htm#Boolean">Boolean</A> logic, a logic of TRUE or
	FALSE values. Also see: <A HREF="Glossary.htm#Subjective">subjective</A>, <A HREF="Glossary.htm#Objective">objective</A>, <A HREF="Glossary.htm#Contextual">contextual</A>,
	<A HREF="Glossary.htm#Absolute">absolute</A>, <A HREF="Glossary.htm#InductiveReasoning">inductive reasoning</A>, <A HREF="Glossary.htm#DeductiveReasoning">deductive
	reasoning</A>, and <A HREF="Glossary.htm#Fallacy">fallacy</A>. <A NAME="LogicFunction"></A></P>
	<P>
	<DT><B>Logic Function</B></DT>
	<DD>Fundamental <A HREF="Glossary.htm#Digital">digial</A> <A HREF="Glossary.htm#Logic">logic</A> operations. The fundamental two-input
	(<I>dyadic</I>) one-output <A HREF="Glossary.htm#Boolean">Boolean</A> functions are <A HREF="Glossary.htm#AND">AND</A> and <A HREF="Glossary.htm#OR">OR</A>.
	The fundamental one-input (<I>monadic</I>) one-output operation is <A HREF="Glossary.htm#NOT">NOT</A>. These can be used in
	various ways to build <A HREF="Glossary.htm#ExclusiveOR">exclusive-OR</A> (<A HREF="Glossary.htm#XOR">XOR</A>), which is also widely used
	as a fundamental function. Here we show the <A HREF="Glossary.htm#TruthTable">truth tables</A> for the fundamental functions:
	<PRE>  INPUT    NOT
     0      1
     1      0

  INPUT    AND   OR    XOR
   0 0      0     0     0
   0 1      0     1     1
   1 0      0     1     1
   1 1      1     1     0
</PRE>
	<P>These Boolean values can be stored as a <A HREF="Glossary.htm#Bit">bit</A>, and can be associated with 0 or 1, FALSE or
	TRUE, NO or YES, etc. <A NAME="LSB"></A></P>
	<P>
	<DT><B>LSB</B></DT>
	<DD>Least-Significant <A HREF="Glossary.htm#Bit">Bit</A>. Typically the rightmost bit. <A NAME="MSequence"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>M-Sequence</B>
	<DD>A <A HREF="Glossary.htm#MaximalLength">maximal length</A> <A HREF="Glossary.htm#ShiftRegister">shift register</A> sequence. <A NAME="MachineLanguage"></A>
	<P>
	<DT><B>Machine Language</B></DT>
	<DD>Also &quot;machine code.&quot; A <A HREF="Glossary.htm#Computer">computer</A> program in the form of the numeric values
	or &quot;operation codes&quot; (&quot;<A HREF="Glossary.htm#Opcode">opcodes</A>&quot;) which the computer can directly execute
	as instructions, commands, or &quot;orders.&quot; Thus, the very public <A HREF="Glossary.htm#Code">code</A> associated with
	the instructions available in a particular computer. Also the programming of a computer at the bit or hexadecimal
	level, below even assembly language. Also see <A HREF="Glossary.htm#SourceCode">source code</A> and <A HREF="Glossary.htm#ObjectCode">object
	code</A>. <A NAME="MagneticField"></A>
	<P>
	<DT><B>Magnetic Field</B></DT>
	<DD>The fundamental physical force resulting from moving charges. Also see: <A HREF="Glossary.htm#ElectromagneticField">electromagnetic
	field</A>. <A NAME="ManInTheMiddleAttack"></A>
	<P>
	<DT><B>Man-in-the-Middle Attack</B></DT>
	<DD>The original model used to analyze cryptosystems assumed that an <A HREF="Glossary.htm#Opponent">Opponent</A> could <I>listen</I>
	to the <A HREF="Glossary.htm#Ciphertext">ciphertext</A> traffic, and perhaps even <I>interfere</I> with it, but not that messages
	could be intercepted and completely hidden. Unfortunately, this is in fact the situation in a store-and-forward
	<A HREF="Glossary.htm#Computer">computer</A> network like the Internet. Routing is not secure on the Internet, and it is at
	least conceivable that messages between two people could be routed through connections on the other side of the
	world. This might be exploited to make such messages flow through a particular computer for special processing.
	<P>The Man-in-the-Middle (MITM) Attack is mainly applicable to <A HREF="Glossary.htm#PublicKeyCipher">public key</A> systems,
	and focuses on the idea that many people will send their public <A HREF="Glossary.htm#Key">keys</A> on the network. The bad
	part of this is a lack of key <A HREF="Glossary.htm#Authentication">authentication</A>, because the Man-in-the-Middle can send
	a key just as easily, and pretend to be the other end. Then, if one <I>uses</I> that key, one has secure communication
	with The Opponent, instead of the far end. The MITM can receive a message, decipher it, read it, re-encipher it
	in the correct public key, and send it along. In this way, neither end need know anything is wrong, yet The Opponent
	is reading the mail.</P>
	<P>Perhaps the worst part of this is that a successful MITM attack does not involve <I>any</I> attack on the actual
	ciphering. And this means that all proofs or confidence in the security of particular ciphering mechanisms is totally
	irrelevant to the security of a system which supports MITM attacks.</P>
	<P>The way to avoid MITM attacks is to <I>certify</I> public keys, but this is inconvenient and time-consuming.
	Unless the cipher <I>requires</I> keys to be certified, this is rarely done. The worst part of this is that a successful
	MITM attack consumes few resources, need not &quot;break&quot; the cipher itself, and may provide just the kind
	of white-collar desktop intelligence a bureaucracy would love.</P>
	<P>It is interesting to note that, regardless of how inconvenient it may be to share keys for a <A HREF="Glossary.htm#SecretKeyCipher">secret-key
	cipher</A>, this is an inherent authentication which prevents MITM attacks. <A NAME="Mapping"></A></P>
	<P>
	<DT><B>Mapping</B></DT>
	<DD>Given sets <I>X</I> and <I>Y,</I> and operation <I>f</I>
	<PRE>     <I>f</I>: X -&gt; Y  ,
</PRE>
	the <I>mapping</I> or <A HREF="Glossary.htm#Function"><I>function</I></A> or <I>transformation</I> <I>f</I> takes any value
	in the <A HREF="Glossary.htm#Domain">domain</A> <I>X</I> into some value in the <A HREF="Glossary.htm#Range">range</A>, which is contained
	in <I>Y.</I> For each element <I>x</I> in <I>X,</I> a mapping associates a single element <I>y</I> in <I>Y.</I>
	Element <I>f(x)</I> in <I>Y</I> is the <I>image</I> of element <I>x</I> in <I>X.</I>
	<UL>
		<P>
		<LI>If <I>f(X)</I> covers all elements in <I>Y,</I> <I>f</I> is a mapping of <I>X</I> <A HREF="Glossary.htm#Onto"><B>onto</B></A>
		<I>Y,</I> and is <A HREF="Glossary.htm#Surjective"><B>surjective</B></A>.
		<P>
		<LI>If <I>f(X)</I> only partially covers <I>Y,</I> <I>f</I> is a mapping of <I>X</I> <A HREF="Glossary.htm#Into"><B>into</B></A>
		<I>Y</I>.
	</UL>
	<P>If no two values of <I>x</I> in <I>X</I> produce the same result <I>f(x),</I> <I>f</I> is <A HREF="Glossary.htm#OneToOne"><B>one-to-one</B></A>
	or <A HREF="Glossary.htm#Injective"><B>injective</B></A>.
	<UL>
		<P>
		<LI>If <I>f</I> is both injective and surjective, it is <B><A HREF="Glossary.htm#OneToOne">one-to-one</A> and <A HREF="Glossary.htm#Onto">onto</A></B>
		or <A HREF="Glossary.htm#Bijective"><B>bijective</B></A>.
		<P>
		<LI>If <I>f</I> is bijective, there exists an <A HREF="Glossary.htm#Inverse"><B>inverse</B></A> <I>f<SUP> -1</SUP></I> such
		that:
		<PRE>    f<SUP>-1</SUP>(f(x)) = x.
</PRE>
		<P>
		<LI>If <I>f</I> is identical with <I>f<SUP> -1</SUP>,</I> <I>f</I> is an <A HREF="Glossary.htm#Involution"><B>involution</B></A>.
		<P>
		<LI>A <A HREF="Glossary.htm#Permutation">permutation</A> of <I>X</I> is a bijection from <I>X</I> to <I>X.</I>
	</UL>
	<A NAME="MarkovProcess"></A>
	<P>
	<DT><B>Markov Process</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a <A HREF="Glossary.htm#Stochastic">stochastic</A> (random) <A HREF="Glossary.htm#Process">process</A>
	(function) in which all possible outcomes are defined by the current <A HREF="Glossary.htm#State">state</A>, independent of
	all previous states. Also see: <A HREF="Glossary.htm#StationaryProcess">stationary process</A>. <A NAME="MathematicalCryptography"></A>
	<P>
	<DT><B>Mathematical Cryptography</B></DT>
	<DD><A HREF="Glossary.htm#Cryptography">Cryptography</A> based on mathematical operations, such as taking extremely large values
	to extremely large powers, <A HREF="Glossary.htm#Modulo">modulo</A> the product of two <A HREF="Glossary.htm#Prime">primes</A>. Normally
	heavily involved with number theory. As opposed to <A HREF="Glossary.htm#MechanisticCryptography">mechanistic cryptography</A>.
	<P>There are some problems with a strictly mathematical approach to cryptography:
	<OL>
		<LI>Mathematical symbology has evolved for concise expression. It is thus not &quot;isomorphic&quot; to the complexity
		of the implementation, and so is not a good vehicle for the design-time trade-off of computation versus <A HREF="Glossary.htm#Strength">strength</A>.
		<LI>Most mathematical operations are useful or &quot;beautiful&quot; relationships specifically intended to support
		understanding in either direction, as opposed to relationships which might be particularly difficult to reverse
		or infer. So when using the traditional operations for cryptography, we must first defeat the very properties which
		made these operations so valuable in their normal use.
		<LI>Mathematics has evolved to produce, describe and expose <I>structure</I>, as in useful or &quot;beautiful&quot;
		large-scale relationships and groupings. But, in a sense, relationships and groupings are the exact opposite of
		the fine-grained completely <A HREF="Glossary.htm#Random">random</A> mappings that cryptography would like to see. Such mappings
		are awkward to express mathematically, and contain little of the structure which mathematics is intended to describe.
		<LI>There may be an ingrained tendency in math practitioners, based on long practice, to <I>construct</I> math-like
		relationships, and such relationships are not desirable in this application. So when using math to construct cryptography,
		we may first have to defeat our own training and tendencies to group, understand and simplify.
	</OL>
	<P>On the other hand, mathematics is <I>irreplaceable</I> in providing the tools to pick out and describe <I>structure</I>
	in apparently strong cipher designs. Mathematics can identify specific strength problems, and evaluate potential
	fixes. But there appears to be no real hope of evaluating strength with respect to <I>every possible</I> attack,
	even using mathematics.</P>
	<P>Although mathematical cryptography has held out the promise of providing <I>provable</I> <A HREF="Glossary.htm#Security">security</A>,
	in over 50 years of work, <B>no</B> practical cipher has been generally accepted as having <I>proven</I> <A HREF="Glossary.htm#Strength">strength</A>.
	See, for example: <A HREF="Glossary.htm#OneTimePad">one time pad</A>. <A NAME="MB"></A></P>
	<P>
	<DT><B>MB</B></DT>
	<DD>Megabyte. 2<SUP>20</SUP> or 1,048,576 <A HREF="Glossary.htm#Byte">bytes</A>. <A NAME="Mb"></A>
	<P>
	<DT><B>Mb</B></DT>
	<DD>Megabit. 2<SUP>20</SUP> or 1,048,576 <A HREF="Glossary.htm#Bit">bits</A>. <A NAME="MaximalLength"></A>
	<P>
	<DT><B>Maximal Length</B></DT>
	<DD>A <A HREF="Glossary.htm#LinearFeedbackShiftRegister">linear feedback shift register</A> (LFSR) sequence of 2<SUP>n</SUP>-1
	steps (assuming a bit-wide <A HREF="Glossary.htm#ShiftRegister">shift register</A> of <I>n</I> bits. This means that every
	<A HREF="Glossary.htm#Binary">binary</A> value the register can hold, except zero, will occur on some step, and then not occur
	again until all other values have been produced. A maximal-length LFSR can be considered a binary counter in which
	the count values have been <A HREF="Glossary.htm#Shuffle">shuffled</A> or <A HREF="Glossary.htm#Encipher">enciphered</A>. And while the
	sequence from a normal binary counter is perfectly <A HREF="Glossary.htm#Balance">balanced</A>, the sequence from a maximal-length
	LFSR is <I>almost</I> perfectly balanced. Also see <A HREF="Glossary.htm#MSequence">M-sequence</A>. <A NAME="Mechanism"></A>
	<P>
	<DT><B>Mechanism</B></DT>
	<DD>The logical concept of a machine, which may be realized either as a physical machine, or as a sequence of logical
	commands executed by a physical machine.
	<P>A mechanism can be seen as a process or an implementation for performing that process (such as <A HREF="Glossary.htm#Electronic">electronic</A>
	<A HREF="Glossary.htm#Hardware">hardware</A>, <A HREF="Glossary.htm#Computer">computer</A> <A HREF="Glossary.htm#Software">software</A>, hybrids, or
	the like). <A NAME="MechanisticCryptography"></A></P>
	<P>
	<DT><B>Mechanistic Cryptography</B></DT>
	<DD><A HREF="Glossary.htm#Cryptography">Cryptography</A> based on <A HREF="Glossary.htm#Mechanism">mechanisms</A>, or machines. As opposed
	to <A HREF="Glossary.htm#MathematicalCryptography">mathematical cryptography</A>.
	<P>Although perhaps looked down upon by those of the mathematical cryptography persuasion, mechanistic cryptography
	certainly does use mathematics to design and predict performance. But rather than being restricted to arithmetic
	operations, mechanistic cryptography tends to use a wide variety of mechanically-simple <A HREF="Glossary.htm#Component">components</A>
	which may not have concise mathematical descriptions. Rather than simply implementing a <A HREF="Glossary.htm#System">system</A>
	of math expressions, complexity is constructed from the various efficient components available to digital computation.
	<A NAME="MersennePrime"></A></P>
	<P>
	<DT><B>Mersenne Prime</B></DT>
	<DD>A <A HREF="Glossary.htm#Prime">prime</A> p for which <NOBR>2<SUP>p</SUP> - 1</NOBR> is also prime. For example, 5 is a
	Mersenne prime because <NOBR>2<SUP>5</SUP> - 1 = 31,</NOBR> and 31 is prime. For <A HREF="Glossary.htm#Mod2Polynomial">mod
	2 polynomials</A> of Mersenne prime degree, <I>every</I> <A HREF="Glossary.htm#Irreducible">irreducible</A> is also <A HREF="Glossary.htm#Primitive">primitive</A>.
	<PRE>Mersenne Primes:
    2         107          9689         216091
    3         127          9941         756839
    5         521         11213         859433
    7         607         19937        1257787
   13        1279         21701        1398269
   17        2203         23209
   19        2281         44497
   31        3217         86243
   61        4253        110503
   89        4423        132049
</PRE>
	<A NAME="MessageDigest"></A>
	<P>
	<DT><B>Message Digest</B></DT>
	<DD>A small value which represents an entire message for purposes of authentication; a <A HREF="Glossary.htm#Hash">hash</A>.
	<A NAME="MessageKey"></A>
	<P>
	<DT><B>Message Key</B></DT>
	<DD>A <A HREF="Glossary.htm#Key">key</A> transported with the message and used for deciphering the message. (The idea of a
	&quot;<A HREF="Glossary.htm#SessionKey">session key</A>&quot; is very similar, but lasts across multiple messages.)
	<P>Normally, the message key is a large <A HREF="Glossary.htm#Random">random</A> value which becomes the key for ciphering
	the data in a single message. Normally, the message key itself is enciphered under the User Key or other key for
	that link. The receiving end first deciphers the message key, then uses that value as the key for deciphering the
	message data. Alternately, the random value itself may be sent unenciphered, but is then enciphered or hashed (under
	a keyed cryptographic hash) to produce a value used as the data ciphering key.</P>
	<P>The message key assures that the actual data is ciphered under a key which is an arbitrary selection from a
	huge number of possible keys; it therefore prevents weakness due to user key selection. A message key is used exactly
	once, no matter how many times the same message is enciphered, so at most, a successful attack on a message key
	exposes just one message. The internal construction of a random message key cannot be controlled by a user, and
	thus prevents all <A HREF="Glossary.htm#Attack">attacks</A> based on repeated ciphering under a single key. To the extent that
	the message key value really is random and is never exposed on either end, the message key is much more easily
	protected than ordinary text (see <A HREF="Glossary.htm#IdealSecrecy">ideal secrecy</A>). In a sense, a message key is the
	higher-level concept of an <A HREF="Glossary.htm#IV">IV</A>, which is necessarily distinct for each particular design. <A NAME="MITM"></A></P>
	<P>
	<DT><B>MITM</B></DT>
	<DD><A HREF="Glossary.htm#ManInTheMiddleAttack">Man In The Middle</A>. <A NAME="Mixing"></A>
	<P>
	<DT><B>Mixing</B></DT>
	<DD>The act of transforming multiple input values into one or more output values, such that changing any input
	value will change the output value. There is no implication that the result must be <A HREF="Glossary.htm#Balance">balanced</A>,
	but effective mixing may need to be, in some sense, <A HREF="Glossary.htm#Complete">complete</A>. Also see <A HREF="Glossary.htm#MixingCipher">Mixing
	Cipher</A>, <A HREF="Glossary.htm#Combiner">combiner</A>, <A HREF="Glossary.htm#LatinSquareCombiner">Latin square combiner</A>, and <A
	HREF="Glossary.htm#BalancedBlockMixing">Balanced Block Mixing</A>. <A NAME="MixingCipher"></A>
	<P>
	<DT><B>Mixing Cipher</B></DT>
	<DD>A <A HREF="Glossary.htm#BlockCipher">block cipher</A> based on <A HREF="Glossary.htm#BalancedBlockMixing">Balanced Block Mixing</A>
	of small elements in <A HREF="Glossary.htm#FFT">FFT</A>-like or <A HREF="Glossary.htm#FWT">FWT</A>-like <A HREF="Glossary.htm#Mixing">mixing</A> patterns.
	<P>Below, we have a toy 32-bit-block Mixing Cipher. <A HREF="Glossary.htm#Plaintext">Plaintext</A> at the top is transformed
	into <A HREF="Glossary.htm#Ciphertext">ciphertext</A> at the bottom. Each &quot;S&quot; is an 8-bit <A HREF="Glossary.htm#SubstitutionTable">substitution
	table</A>, and each table (and now each mixing operation also) is individually <A HREF="Glossary.htm#Key">keyed</A>.</P>
	<P>Horizontal lines connect elements which are to be mixed together: Each *---* represents a single <A HREF="Glossary.htm#BalancedBlockMixing">Balanced
	Block Mixing</A> or BBM. Each BBM takes two elements, mixes them, and returns two mixed values. The mixed results
	then replace the original values in the selected positions just like the &quot;butterfly&quot; operations used
	in some <A HREF="Glossary.htm#FFT">FFT</A>'s.</P>
	<PRE>   A 32-Bit Mixing Cipher

    |   |   |   |    &lt;- Input Block (Plaintext)
    S   S   S   S    &lt;- <A HREF="Glossary.htm#Fencing">Fencing</A>
    |   |   |   |
    *---*   *---*    &lt;- 2 BBM Mixings
    |   |   |   |
    *-------*   |    &lt;- 1 BBM Mixing
    |   *-------*    &lt;- 1 BBM Mixing
    |   |   |   |
    S   S   S   S    &lt;- Fencing
    |   |   |   |
    *-------*   |
    |   *-------*
    |   |   |   |
    *---*   *---*
    |   |   |   |
    S   S   S   S    &lt;- Fencing
    |   |   |   |    &lt;- Output Block (Ciphertext)
</PRE>
	<P>By mixing each element with another, and then each pair with another pair and so on, every element is eventually
	mixed with every other element. Each BBM mixing is <A HREF="Glossary.htm#Dyadic">dyadic</A>, so each &quot;sub-level&quot;
	is a mixing of twice as many elements as the sublevel before it. A block of <I>n</I> elements is thus fully mixed
	in <NOBR>log<SUB>2</SUB> <I>n</I></NOBR> sublevels, and each result element is equally influenced equally by each
	and every input element.</P>
	<P>The pattern of these mixings is exactly like some implementations of the FFT, and thus the term &quot;FFT-style.&quot;
	Also see the articles in the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/CRYPHTML.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/CRYPHTML.HTM#MixTech'" tppabs="http://www.io.com/~ritter/CRYPHTML.HTM#MixTech">Mixing Ciphers</A> section
	on the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers By Ritter</A> pages. <A NAME="Mod2"></A></P>
	<P>
	<DT><B>Mod 2</B></DT>
	<DD>The <A HREF="Glossary.htm#Field">field</A> formed from the set of integers {0,1} with operations + and * producing the
	remainder after dividing by <A HREF="Glossary.htm#Congruence">modulus</A> 2. Thus:
	<PRE>     0 + 0 = 0
     0 + 1 = 1
     1 + 0 = 1
     1 + 1 = 0

     1 + 1 + 1 = 1

     0 * 0 = 0
     0 * 1 = 0
     1 * 0 = 0
     1 * 1 = 1
</PRE>
	Subtraction mod 2 is the same as addition mod 2. The operations + and * can also be considered the <A HREF="Glossary.htm#LogicFunction">logic
	functions</A> <A HREF="Glossary.htm#XOR">XOR</A> and <A HREF="Glossary.htm#AND">AND</A> respectively. <A NAME="Mod2Polynomial"></A>
	<P>
	<DT><B>Mod 2 Polynomial</B></DT>
	<DD>A <A HREF="Glossary.htm#Polynomial">polynomial</A> in which the coefficients are taken <A HREF="Glossary.htm#Mod2">mod 2</A>. The four
	arithmetic operations addition, subtraction, multiplication and division are supported. As usual, mod 2 subtraction
	is the same as mod 2 addition. Each column of coefficients is added separately, without &quot;carrys&quot; to an
	adjacent column:
	<PRE>Addition and Subtraction:

       1 0 1 1
     + 0 1 0 1
     + 1 1 0 0
      ---------
       0 0 1 0


Multiplication:

          1 0 1 1
        * 1 1 0 0
        ----------
                0
              0
      1 0 1 1
    1 0 1 1
   ---------------
    1 1 1 0 1 0 0
</PRE>
	Polynomial multiplication is <I>not</I> the same as repeated polynomial addition. But there is a fast approach
	to squaring mod 2 polynomials:
	<PRE>               a  b  c  d
               a  b  c  d
              ------------
              ad bd cd dd
           ac bc cc dc
        ab bb cb db
     aa ba ca da
    ----------------------
      a  0  b  0  c  0  d
</PRE>
	To square a mod 2 polynomial, all we have to do is &quot;insert&quot; a zero between every column. Note that aa
	= a for a = 0 or a = 1, and ab = ba, so either 0 + 0 = 0 or 1 + 1 = 0.
	<PRE>Division:
                    1 0 1 1
            ----------------
    1 1 0 0 ) 1 1 1 0 1 0 0
              1 1 0 0
             ---------
                  1 0 1 0
                  1 1 0 0
                 ---------
                    1 1 0 0
                    1 1 0 0
                   ---------
                          0
</PRE>
	<P>The decision about whether the divisor &quot;goes into&quot; the dividend is based exclusively on the most-significant
	(leftmost) digit. This makes polynomial division far easier than integer division.</P>
	<P>Mod 2 polynomials behave much like <A HREF="Glossary.htm#Integer">integers</A> in that one polynomial may or may not divide
	another without remainder. This means that we can expect to find analogies to integer &quot;<A HREF="Glossary.htm#Prime">primes</A>,&quot;
	which we call <A HREF="Glossary.htm#Irreducible"><I>irreducible</I></A> polynomials.</P>
	<P>Mod 2 polynomials do not constitute a <A HREF="Glossary.htm#Field">field</A>; clearly, the size of a multiplication is unbounded.
	However, a <A HREF="Glossary.htm#FiniteField">finite field</A> of polynomials can be created by choosing an irreducible modulus
	polynomial, thus producing a Galois field <A HREF="Glossary.htm#GF2n">GF 2<SUP>n</SUP></A>. <A NAME="Mode"></A></P>
	<P>
	<DT><B>Mode</B></DT>
	<DD>One possibility is: <A HREF="Glossary.htm#BlockCipher">block cipher</A> <A HREF="Glossary.htm#OperatingMode">operating mode</A>. <A
	NAME="Modulo"></A>
	<P>
	<DT><B>Modulo</B></DT>
	<DD>Casually, the remainder after an integer division by a modulus; see <A HREF="Glossary.htm#Congruence">congruence</A>. When
	the modulus is <A HREF="Glossary.htm#Prime">prime</A>, this may generate a useful <A HREF="Glossary.htm#Field">field</A>. <A NAME="Monadic"></A>
	<P>
	<DT><B>Monadic</B></DT>
	<DD>Relating to <I>monad</I>, which is Greek for single or one. In particular, a function with a single input or
	argument, also called <A HREF="Glossary.htm#Unary">unary</A>. Also see: <A HREF="Glossary.htm#Dyadic">dyadic</A>. <A NAME="MonoalphabeticSubstitution"></A>
	<P>
	<DT><B>Monoalphabetic Substitution</B></DT>
	<DD>Substitution using a single <A HREF="Glossary.htm#Alphabet">alphabet</A>. Also called <A HREF="Glossary.htm#SimpleSubstitution">simple
	substitution</A>. As opposed to <A HREF="Glossary.htm#PolyalphabeticSubstitution">Polyalphabetic Substitution</A>. <A NAME="Monographic"></A>
	<P>
	<DT><B>Monographic</B></DT>
	<DD>Greek for &quot;single letter.&quot; A <A HREF="Glossary.htm#Cipher">cipher</A> which translates one <A HREF="Glossary.htm#Plaintext">plaintext</A>
	symbol at a time into <A HREF="Glossary.htm#Ciphertext">ciphertext</A>. As opposed to <A HREF="Glossary.htm#Polygraphic">polygraphic</A>;
	also see <A HREF="Glossary.htm#Homophonic">homophonic</A> and <A HREF="Glossary.htm#Polyphonic">polyphonic</A>. <A NAME="MultipleEncryption"></A>
	<P>
	<DT><B>Multiple Encryption</B></DT>
	<DD><A HREF="Glossary.htm#Encipher">Enciphering</A> or <A HREF="Glossary.htm#Encryption">encrypting</A> a message more than once. This
	usually has the <A HREF="Glossary.htm#Strength">strength</A> advantage of producing a very random-like <A HREF="Glossary.htm#Ciphertext">ciphertext</A>
	from the first pass, which is of course the &quot;<A HREF="Glossary.htm#Plaintext">plaintext</A>&quot; for the next pass.
	<P>Multiple encryption using different <A HREF="Glossary.htm#Key">keys</A> can be a way to increase strength. And multiple
	encryption using different <A HREF="Glossary.htm#Cipher">ciphers</A> can reduce the probability of using a single cipher which
	has been <A HREF="Glossary.htm#Break">broken</A> in secret. In both cases, the cost is additional ciphering operations.</P>
	<P>Unfortunately, multiple encryption using just <I>two</I> (2) ciphers may not be much advantage: If we assume
	The Opponents know which ciphers are used, they can manipulate <I>both</I> the plaintext <I>and</I> the ciphertext
	to search for a match (a &quot;meet-in-the-middle&quot; <A HREF="Glossary.htm#Attack">attack</A> strategy). One way to avoid
	this is to use <I>three</I> (3) cipherings, as in Triple DES.</P>
	<P>Multiple encryption also can be <I>dangerous</I>, if a single cipher is used with the same key each time. Some
	ciphers are <A HREF="Glossary.htm#Involution">involutions</A> which both encipher and decipher with the same process; these
	ciphers will <B>de</B>cipher a message if it is <B>en</B>ciphered a second time under the same key. This is typical
	of classic additive synchronous stream ciphers, as it avoids the need to have separate encipher and decipher operations.
	But it also can occur with block ciphers operated in stream-cipher-like modes such as <A HREF="Glossary.htm#OFB">OFB</A>, for
	exactly the same reason. <A NAME="Nomenclator"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Nomenclator</B>
	<DD>Originally, a list of transformations from <I>names</I> to symbols or numbers for diplomatic communications.
	Later, typically a list of transformations from names, <A HREF="Glossary.htm#Polygraphic">polygraphic</A> syllables, and <A
	HREF="Glossary.htm#Monographic">monographic</A> letters, to numbers. Usually the monographic transformations had multiple or
	<A HREF="Glossary.htm#Homophonic">homophonic</A> alternatives for frequently-used letters. Generally smaller than a <A HREF="Glossary.htm#Codebook">codebook</A>,
	due to the use of the syllables instead of a comprehensive list of phrases. A sort of early manual <A HREF="Glossary.htm#Cipher">cipher</A>
	with some characteristics of a <A HREF="Glossary.htm#Code">code</A>, that operated like a <A HREF="Glossary.htm#Codebook">codebook</A>.
	<A NAME="Nominal"></A>
	<P>
	<DT><B>Nominal</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, measurements which are in categories or &quot;bins.&quot; Also see:
	<A HREF="Glossary.htm#Ordinal">ordinal</A>, and <A HREF="Glossary.htm#Interval">interval</A>. <A NAME="Nonlinearity"></A>
	<P>
	<DT><B>Nonlinearity</B></DT>
	<DD>The extent to which a function is not <A HREF="Glossary.htm#Linear">linear</A>. See <A HREF="Glossary.htm#BooleanFunctionNonlinearity">Boolean
	function nonlinearity</A>. <A NAME="NOT"></A>
	<P>
	<DT><B>NOT</B></DT>
	<DD>A Boolean <A HREF="Glossary.htm#LogicFunction">logic function</A> which is the &quot;complement&quot; or the <A HREF="Glossary.htm#Mod2">mod
	2</A> addition of 1. <A NAME="NullHypothesis"></A>
	<P>
	<DT><B>Null Hypothesis</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the particular statement or hypothesis <I>H</I><SUB>0</SUB> which
	is accepted unless a <A HREF="Glossary.htm#Statistic">statistic</A> testing that hypothesis produces evidence to the contrary.
	Normally, the null hypothesis is accepted when the associated statistical test indicates &quot;nothing unusual
	found.&quot;
	<P>The logically contrary <A HREF="Glossary.htm#AlternativeHypothesis">alternative hypothesis</A> <I>H</I><SUB>1</SUB> is sometimes
	formulated with the specific <I>hope</I> that something unusual <I>will</I> be found, but this can be very tricky
	to get right. Many statistical tests (such as <A HREF="Glossary.htm#GoodnessOfFit">goodness-of-fit</A> tests) can only indicate
	whether something matches what we expect, or does not. But any number of things can cause a mismatch, including
	a fundamentally flawed experiment. A simple mismatch does not normally imply the presence of a particular quality.</P>
	<P>Even in the best possible situation, <A HREF="Glossary.htm#Random">random</A> <A HREF="Glossary.htm#Sample">sampling</A> will produce
	a range or <A HREF="Glossary.htm#Distribution">distribution</A> of test statistic values. Often, even the worst possible statistic
	value can be produced by an unlucky sampling of the best possible data. It is thus important to know what distribution
	to expect because of the sampling alone, so if we find a <I>different</I> distribution, that will be evidence supporting
	the alternative hypothesis <I>H</I><SUB>1</SUB>.</P>
	<P>If we collect enough statistic values, we should see them occur in the ideal distribution for that particular
	statistic. So if we call the upper 5 percent of the distribution &quot;failure&quot; (this is the <A HREF="Glossary.htm#Significance">significance</A>
	level) we not only <I>expect</I> but in fact <I>require</I> such &quot;failure&quot; to occur about 1 time in 20.
	If it does not, we will in fact have detected something unusual, something which might even indicate problems in
	the experimental design.</P>
	<P>If we have only a small number of samples, and do not run repeated trials, a relatively few chance events can
	produce an improbable statistic value, which might cause us to reject a valid null hypothesis, and so commit a
	<A HREF="Glossary.htm#TypeIError">type I error</A>.</P>
	<P>On the other hand, if there <I>is</I> a systematic deviation in the underlying distribution, only a very specific
	type of random sampling could mask that problem. With few samples and trials, though, the chance random masking
	of a systematic problem is still <I>possible,</I> and could lead to a <A HREF="Glossary.htm#TypeIIError">type II error</A>.
	<A NAME="ObjectCode"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Object Code</B>
	<DD>Typically, <A HREF="Glossary.htm#MachineLanguage">machine language</A> instructions represented in a form which can be
	&quot;linked&quot; with other routines. Also see <A HREF="Glossary.htm#SourceCode">source code</A>. <A NAME="Objective"></A>
	<P>
	<DT><B>Objective</B></DT>
	<DD>In the study of <A HREF="Glossary.htm#Logic">logic</A>, reality observed without interpretation. As opposed to <A HREF="Glossary.htm#Subjective">subjective</A>
	or interpreted reality. Alternately, a goal. <A NAME="Octal"></A>
	<P>
	<DT><B>Octal</B></DT>
	<DD>Base 8: The numerical representation in which each digit has an <A HREF="Glossary.htm#Alphabet">alphabet</A> of eight symbols,
	generally 0 through 7.
	<P>Somewhat easier to learn than <A HREF="Glossary.htm#Hexadecimal">hexadecimal</A>, since no new numeric symbols are needed,
	but octal can only represent three <A HREF="Glossary.htm#Bit">bits</A> at a time. This generally means that the leading digit
	will not take all values, and that means that the representation of the top part of two concatenated values will
	differ from its representation alone, which can be confusing. Also see: <A HREF="Glossary.htm#Binary">binary</A> and <A HREF="Glossary.htm#Decimal">decimal</A>.
	<A NAME="Octave"></A></P>
	<P>
	<DT><B>Octave</B></DT>
	<DD>A <A HREF="Glossary.htm#Frequency">frequency</A> ratio of 2:1. From an 8-step musical scale. <A NAME="OFB"></A>
	<P>
	<DT><B>OFB</B></DT>
	<DD>OFB or Output FeedBack is an <A HREF="Glossary.htm#OperatingMode">operating mode</A> for a <A HREF="Glossary.htm#BlockCipher">block
	cipher</A>.
	<P>OFB is closely related to <A HREF="Glossary.htm#CFB">CFB</A>, and is intended to provide some of the characteristics of
	a <A HREF="Glossary.htm#StreamCipher">stream cipher</A> from a block cipher. OFB is a way of using a block cipher to form a
	<A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>. The resulting <A HREF="Glossary.htm#PseudoRandom">pseudorandom</A>
	<A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> can be <A HREF="Glossary.htm#Combiner">combined</A> with data as in the
	usual stream cipher.</P>
	<P>OFB assumes a <A HREF="Glossary.htm#ShiftRegister">shift register</A> of the block cipher block size. An <A HREF="Glossary.htm#IV">IV</A>
	or initial value first fills the register, and then is ciphered. Part of the result, often just a single <A HREF="Glossary.htm#Byte">byte</A>,
	is used to cipher data, and <I>also</I> is shifted into the register. The resulting new register value is ciphered,
	producing another confusion value for use in stream ciphering.</P>
	<P>One disadvantage of this, of course, is the need for a full block-wide ciphering operation, typically for each
	data byte ciphered. The advantage is the ability to cipher individual characters, instead of requiring accumulation
	into a block before processing. <A NAME="OneTimePad"></A></P>
	<P>
	<DT><B>One Time Pad</B></DT>
	<DD>The term &quot;one time pad&quot; (OTP) is rather casually used for two fundamentally different types of <A
	HREF="Glossary.htm#Cipher">cipher</A>:
	<P>
	<OL>
		<LI><B>The Theoretical One Time Pad:</B> a theoretical <A HREF="Glossary.htm#Random">random</A> source produces values which
		are <A HREF="Glossary.htm#Combiner">combined</A> with data to produce <A HREF="Glossary.htm#Ciphertext">ciphertext</A>. In a theoretical
		discussion of this concept, we can simply <B>assume</B> <I>perfect</I> randomness in the source, and this <B>assumption</B>
		supports a mathematical proof that the cipher is unbreakable. But the theoretical result applies to reality <B>only
		if we can prove the assumption is valid</B> in reality. Unfortunately, we cannot do this, because <I>provably</I>
		perfect randomness apparently cannot be attained in practice. So the theoretical OTP does not really exist, except
		as a goal.
		<P>
		<LI><B>The Realized One Time Pad:</B> a <A HREF="Glossary.htm#ReallyRandom">really random</A> source produces values which
		are combined with data to produce ciphertext. But because we can neither <I>assume</I> nor <I>prove</I> perfect,
		theoretical-class randomness in any real generator, this cipher does not have the mathematical proof of the theoretical
		system. Thus, a realized one time pad is <B>NOT <I>proven</I></B> unbreakable, although it may in fact <I>be</I>
		unbreakable in practice. In this sense, it is much like other realized ciphers.
	</OL>
	<P>A realized one time pad (OTP) is essentially a <A HREF="Glossary.htm#StreamCipher">stream cipher</A> with a <A HREF="Glossary.htm#ReallyRandom">really
	random</A> <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> used exactly once. The confusion sequence is the
	<A HREF="Glossary.htm#Key">key</A>, and it is as long as the data. Since this amount of keying material can be awkward to transfer
	and keep, we often see &quot;pseudo&quot; one-time pad designs which attempt to correct this deficiency. Normally,
	the point is to achieve the theoretical advantages of a one-time pad without the costs; the problem with this is
	that the one-time pad theory of strength no longer applies. These variations are best seen as classic stream cipher
	designs.</P>
	<P>In a realized one time pad, the confusion sequence must be <I>unpredictable</I> (not generated from a small
	key value) and must be transported to the far end and held at both locations in absolute secrecy like any other
	secret key. But where a normal secret key might range perhaps from 16 bytes to 160 bytes, there must be as much
	OTP sequence as there will be data (which might well be megabytes). And a normal secret key could itself be sent
	under a key (as in a <A HREF="Glossary.htm#MessageKey">message key</A> or under a <A HREF="Glossary.htm#PublicKeyCipher">public key</A>).
	But an OTP sequence <I>cannot</I> be sent under a key, since this would make the OTP as weak as the key, in which
	case we might as well use a normal cipher. All this implies very significant inconveniences, costs, and risks,
	well beyond what one would at first expect, so even the realized one time pad is generally considered <B>impractical</B>,
	except in very special situations.</P>
	<P>In a realized one time pad, the confusion sequence itself must be <A HREF="Glossary.htm#Random">random</A> for, if not,
	it will be somewhat predictable. And, although we have a great many <A HREF="Glossary.htm#Statistics">statistical</A> randomness
	tests, there is no test which can <I>certify</I> a sequence as either random or unpredictable. This means that
	a sequence which we assume to be random may <B>not</B> be the unpredictable sequence we need, and we can never
	know for sure. (This might be considered an argument for using a <A HREF="Glossary.htm#Combiner">combiner</A> with strength,
	such as a <A HREF="Glossary.htm#LatinSquareCombiner">Latin square</A> or <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic Substitution</A>.)
	In practice, the much touted &quot;mathematically proven unbreakability&quot; of the one time pad depends upon
	an assumption of randomness and unpredictability which we can neither test nor prove.</P>
	<P>The one time pad sometimes seems to have yet another level of strength above the usual stream cipher, the ever-increasing
	amount of &quot;unpredictability&quot; or <A HREF="Glossary.htm#Entropy">entropy</A> in the <A HREF="Glossary.htm#ConfusionSequence">confusion
	sequence</A>, leading to an indefinite <A HREF="Glossary.htm#UnicityDistance">unicity distance</A>. In contrast, the typical
	<A HREF="Glossary.htm#StreamCipher">stream cipher</A> will produce a long sequence from a relatively small amount of initial
	<A HREF="Glossary.htm#State">state</A>, and it can be argued that the entropy of an <A HREF="Glossary.htm#RNG">RNG</A> is just the number
	of bits in its initial state. In theory, this might mean that the initial state or <A HREF="Glossary.htm#Key">key</A> used
	in the stream cipher could be identified after somewhat more than that same amount of data had been enciphered.
	But it is also perfectly possible for an unsuspected problem to occur in a really-random generator, and then the
	more sequence generated, the more apparent and useful that problem might be to an <A HREF="Glossary.htm#Opponent">Opponent</A>.</P>
	<P>Nor does even a theoretical one time pad imply unconditional security: Consider <I>A</I> sending the same message
	to <I>B</I> and <I>C,</I> using, of course, two <I>different</I> pads. Now, suppose the Opponents can acquire plaintext
	from <I>B</I> and intercept the ciphertext to <I>C</I>. If the system is using the usual <A HREF="Glossary.htm#AdditiveCombiner">additive
	combiner</A>, the Opponents can <I>reconstruct the pad</I> between <I>A</I> and <I>C</I>. Now they can send <I>C</I>
	any message they want, and encipher it under the correct pad. And <I>C</I> will never question such a message,
	since <I>everyone knows</I> that a one time pad provides &quot;absolute&quot; security as long as the pad is kept
	secure. Note that both <I>A</I> and <I>C</I> have done this, and they are the only ones who had that pad.</P>
	<P>Various companies offer one time pad programs, and sometimes also the keying or &quot;pad&quot; material. <A
	NAME="OneToOne"></A></P>
	<P>
	<DT><B>One-To-One</B></DT>
	<DD><A HREF="Glossary.htm#Injective">Injective</A>. A <A HREF="Glossary.htm#Mapping">mapping</A> f: <I>X -&gt; Y</I> where no two values
	<I>x</I> in <I>X</I> produce the same result <I>f(x)</I> in <I>Y.</I> A one-to-one mapping is invertible for those
	values of <I>X</I> which produce unique results <I>f(x)</I>, but there may not be a full inverse mapping g: <I>Y
	-&gt; X</I>. <A NAME="OneWayDiffusion"></A>
	<P>
	<DT><B>One Way Diffusion</B></DT>
	<DD>In the context of a <A HREF="Glossary.htm#BlockCipher">block cipher</A>, a one way <A HREF="Glossary.htm#Diffusion">diffusion</A> <A
	HREF="Glossary.htm#Layer">layer</A> will carry any changes in the data <A HREF="Glossary.htm#Block">block</A> in a direction from one side
	of the block to the other, but not in the opposite direction. This is the usual situation for fast, effective diffusion
	layer realizations. <A NAME="Onto"></A>
	<P>
	<DT><B>Onto</B></DT>
	<DD><A HREF="Glossary.htm#Surjective">Surjective</A>. A <A HREF="Glossary.htm#Mapping">mapping</A> f: <I>X -&gt; Y</I> where <I>f(x)</I>
	covers all elements in <I>Y.</I> Not necessarily invertible, since multiple elements <I>x</I> in <I>X</I> could
	produce the same <I>f(x)</I> in <I>Y.</I>
	<PRE>   +----------+          +----------+
   |          |   ONTO   |          |
   |    X     |          | Y = f(X) |
   |          |    f     |          |
   |          |   ---&gt;   |          |
   +----------+          +----------+
</PRE>
	<A NAME="Opcode"></A>
	<P>
	<DT><B>Opcode</B></DT>
	<DD>Operation <A HREF="Glossary.htm#Code">code</A>: a value which selects one operation from among a set of possible operations.
	This is an encoding of functions as values. These values may be interpreted by a <A HREF="Glossary.htm#Computer">computer</A>
	to perform the selected operations in their given sequence and produce a desired result. Also see: <A HREF="Glossary.htm#Software">software</A>
	and <A HREF="Glossary.htm#Hardware">hardware</A>. <A NAME="OperatingMode"></A>
	<P>
	<DT><B>Operating Mode</B></DT>
	<DD>With respect to <A HREF="Glossary.htm#BlockCipher">block ciphers</A>, a way to handle messages which are larger than the
	defined <A HREF="Glossary.htm#Block">block</A> size. Usually this means one of the four block cipher &quot;applications&quot;
	defined for use with <A HREF="Glossary.htm#DES">DES</A>:
	<UL>
		<LI><A HREF="Glossary.htm#ECB">ECB</A> or Electronic CodeBook;
		<LI><A HREF="Glossary.htm#CBC">CBC</A> or Cipher Block Chaining;
		<LI><A HREF="Glossary.htm#CFB">CFB</A> or Ciphertext FeedBack; and
		<LI><A HREF="Glossary.htm#OFB">OFB</A> or Output FeedBack.
	</UL>
	<P>It can be argued that block cipher operating modes are <A HREF="Glossary.htm#StreamCipher">stream &quot;meta-ciphers&quot;</A>
	in which the streamed transformation is of full block cipher width, instead of the usual stream cipher <A HREF="Glossary.htm#Bit">bit</A>-
	or <A HREF="Glossary.htm#Byte">byte</A>-width transformations. <A NAME="Opponent"></A></P>
	<P>
	<DT><B>Opponent</B></DT>
	<DD>A term used by some <A HREF="Glossary.htm#Cryptographer">cryptographers</A> to refer to the opposing <A HREF="Glossary.htm#Cryptanalyst">cryptanalyst</A>
	or opposing team. Sometimes used in preference to &quot;the enemy.&quot; <A NAME="OR"></A>
	<P>
	<DT><B>OR</B></DT>
	<DD>A Boolean <A HREF="Glossary.htm#LogicFunction">logic function</A> which is also nonlinear under <A HREF="Glossary.htm#Mod2">mod 2</A>
	addition. <A NAME="Order"></A>
	<P>
	<DT><B>Order</B></DT>
	<DD>In mathematics, typically the number of elements in a structure, or the number of steps required to traverse
	a cyclic structure. <A NAME="Ordinal"></A>
	<P>
	<DT><B>Ordinal</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, measurements which are ordered from smallest to largest. Also see:
	<A HREF="Glossary.htm#Nominal">nominal</A>, and <A HREF="Glossary.htm#Interval">interval</A>. <A NAME="Orthogonal"></A>
	<P>
	<DT><B>Orthogonal</B></DT>
	<DD>At right angles; on an independent dimension. Two structures which each express an independent dimension. <A
	NAME="OrthogonalLatinSquares"></A>
	<P>
	<DT><B>Orthogonal Latin Squares</B></DT>
	<DD>Two <A HREF="Glossary.htm#LatinSquare">Latin squares</A> of order <I>n,</I> which, when superimposed, form each of the
	<I>n</I><SUP>2</SUP> possible ordered pairs of <I>n</I> symbols exactly once. At most, <I>n</I>-1 Latin squares
	may be mutually orthogonal.
	<PRE>   3 1 2 0   0 3 2 1       30  13  22  01
   0 2 1 3   2 1 0 3   =   02  21  10  33
   1 3 0 2   1 2 3 0       11  32  03  20
   2 0 3 1   3 0 1 2       23  00  31  12
</PRE>
	<P>Also see <A HREF="Glossary.htm#BalancedBlockMixing">Balanced Block Mixing</A>. <A NAME="OTP"></A></P>
	<P>
	<DT><B>OTP</B></DT>
	<DD><A HREF="Glossary.htm#OneTimePad">One Time Pad</A>. <A NAME="OverallDiffusion"></A>
	<P>
	<DT><B>Overall Diffusion</B></DT>
	<DD>That property of an ideal <A HREF="Glossary.htm#BlockCipher">block cipher</A> in which a change of even a single message
	or <A HREF="Glossary.htm#Plaintext">plaintext</A> <A HREF="Glossary.htm#Bit">bit</A> will change every <A HREF="Glossary.htm#Ciphertext">ciphertext</A>
	bit with probability 0.5. In practice, a good block cipher will approach this ideal. This means that about half
	of the output bits should change for any possible change to the input block.
	<P>Overall diffusion means that the ciphertext will appear to change at <A HREF="Glossary.htm#Random">random</A> even between
	related message blocks, thus hiding message relationships which might be used to <A HREF="Glossary.htm#Attack">attack</A> the
	cipher.</P>
	<P>Overall diffusion can be measured statistically in a realized cipher and used to differentiate between better
	and worse designs. Overall diffusion does not, by itself, define a good cipher, but it is <I>required</I> in a
	good block cipher.</P>
	<P>Also see <A HREF="Glossary.htm#Diffusion">diffusion</A>, <A HREF="Glossary.htm#Avalanche">avalanche</A>, <A HREF="Glossary.htm#StrictAvalancheCriterion">strict
	avalanche criterion</A> and <A HREF="Glossary.htm#Complete">complete</A>. <A NAME="Padding"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Padding</B>
	<DD>In classical <A HREF="Glossary.htm#Cryptography">cryptography</A>, <A HREF="Glossary.htm#Random">random</A> data added to the start
	and end of messages so as to conceal the length of the message, and the position where coding actually starts.
	<P>In more conventional computing, some additional data needed to fill-out a fixed-size data structure. This meaning
	also exists in cryptography, where the last <A HREF="Glossary.htm#Block">block</A> of a fixed-size <A HREF="Glossary.htm#BlockCipher">block
	cipher</A> often must be padded to fill the block. <A NAME="Password"></A></P>
	<P>
	<DT><B>Password</B></DT>
	<DD>A <A HREF="Glossary.htm#Key">key</A>, in the form of a word. Also &quot;pass phrase,&quot; for multiple-word keys. See:
	<A HREF="Glossary.htm#UserAuthentication">user authentication</A>. <A NAME="Patent"></A>
	<P>
	<DT><B>Patent</B></DT>
	<DD>The legal right, formally granted by a government, to exclude others from making, selling or using the particular
	invention described in the patent deed. (The term &quot;selling&quot; is generally understood to cover free distribution.)
	Note that a patent is <I>not</I> the right to make the invention, if it is covered by <I>other</I> unexpired patents.
	A patent constitutes the open <I>publication</I> of an invention, in return for a limited-term monopoly on its
	use. A patent is said to protect the <I>application</I> of an idea (as opposed to the idea itself), and is distinct
	from copyright, which protects the <I>expression</I> of an idea.
	<P>The concept behind patenting is to establish intellectual property in a way somewhat related to a mining claim
	or real estate. An inventor of a machine or process can file a <I>claim</I> on the innovation, provided that it
	is not previously published, and that someone else does not already have such a claim. Actual patents normally
	do not claim an overall machine, but just the newly-innovative part, and wherever that part is used, it must be
	licensed from the inventor. It is common for an inventor to refine earlier work patented by someone else, but if
	the earlier patent has not expired, the resulting patent often cannot be practiced without a license from the earlier
	patent holder.</P>
	<P>Someone who comes up with a patentable invention and wishes to give up <I>their</I> rights can simply publish
	a full description of the invention. Simple publication should prevent an application from anyone who has not already
	established legal proof that they previously came up with the same invention. In the U.S., publication also apparently
	sets a 1-year clock running for an application to be filed by anyone who <I>does</I> have such proof. But coming
	up with an invention does not take away <I>someone else's</I> rights if they came up with the same thing first,
	they may have a year to file, and their case might take several years to prosecute and issue.</P>
	<P>In the U.S., a patent is a non-renewable grant, previously lasting 17 years from issue date, now lasting 20
	years from application date. Both an application fee and an issue fee are required, as are periodic &quot;maintenance&quot;
	fees throughout the life of the patent. There are four main requirements:
	<OL>
		<P>
		<LI><B>Statutory Class</B> (35 USC 101): The invention must be either:
		<UL>
			<LI>a process,
			<LI>a machine,
			<LI>a manufacture,
			<LI>a composition of materials, or
			<LI>a new use for one of the above.
		</UL>
		<P>
		<LI><B>Utility</B> (35 USC 101): The invention must be of some use.
		<P>
		<LI><B>Novelty</B> (35 USC 102): The invention must have some aspect which is different from all previous inventions
		and public knowledge.
		<P>A U.S. patent is <B>not</B> available if -- <B>before the <I>invention</I> date</B> -- the invention was:
		<UL>
			<LI>Publicly known or used the United States of America, or
			<LI>Described in a printed publication (e.g., available at a public library) anywhere
		</UL>
		(35 USC 102(a)).
		<P>A U.S. patent is <B>not</B> available if -- <B>more than a year before the <I>application</I> date</B> -- the
		invention was:
		<UL>
			<LI>In public use or on sale in the United States of America, or
			<LI>Described in a printed publication (e.g., available at a public library) anywhere
		</UL>
		(35 USC 102(b)).
		<P>
		<LI><B>Unobviousness</B> (35 USC 103): The invention must have <B>not</B> been obvious <I>to someone of ordinary
		skill</I> in the field of the invention <I>at the time of the invention.</I> Unobviousness has various general
		arguments, such as:
		<UL>
			<LI>Unexpected Results,
			<LI>Unappreciated Advantage.
			<LI>Solution of Long-Felt and Unsolved Need, and
			<LI>Contrarian Invention (contrary to teachings of the prior art),
		</UL>
		among many others.
	</OL>
	<P>When the same invention is claimed by different inventors, deciding who has &quot;priority&quot; to be awarded
	the patent can require <I>legally provable</I> dates for both &quot;conception&quot; and &quot;reduction to practice&quot;:
	<UL>
		<LI><I>Conception</I> can be proven by disclosure to others, preferably in documents which can be signed and dated
		as having been read and understood. The readers can then testify as to exactly what was known and when it was known.
		<LI><I>Reduction to Practice</I> may be the patent application itself, or requires others either to watch the invention
		operate or to make it operate on behalf of the inventor. These events also should be carefully recorded in written
		documents with signatures and dates.
	</UL>
	&quot;In determining priority of invention, there shall be considered not only the respective dates of conception
	and reduction to practice of the invention, but also the reasonable diligence of one who was first to conceive
	and last to reduce to practice . . .&quot; (35 USC 102(g)).
	<P>Also see: <A HREF="Glossary.htm#PriorArt">prior art</A> and our <A HREF="javascript:if(confirm('http://christalmirror.ifrance.com/assembly/dossier10/fichiers/PATS/PATPOLI.HTM  \n\nThis file was not retrieved by Teleport Pro, because the server reports that this file cannot be found.  \n\nDo you want to open it from the server?'))window.location='http://christalmirror.ifrance.com/assembly/dossier10/fichiers/PATS/PATPOLI.HTM#ClaimsTutorial'" tppabs="http://christalmirror.ifrance.com/assembly/dossier10/fichiers/PATS/PATPOLI.HTM#ClaimsTutorial">claims tutorial</A>.</P>
	<P>In practice, a patent is rarely the intrusive prohibitive right that it may at first appear to be, because patents
	are really about <I>money</I> and <I>respect.</I> Ideally, a patent rewards the inventor for doing research and
	development, and then disclosing an invention to the public; it is also a legal recognition of a contribution to
	society. If someone infringes a patent in a way which affects sales, or which implies that the inventor cannot
	do anything about it, the patent holder can be expected to show some interest. But when little or no money is involved,
	a patent can be <A HREF="Glossary.htm#PatentInfringement">infringed</A> repeatedly with little or no response, and typically
	this will have no effect on future legal action.</P>
	<P>This simple introduction cannot begin to describe the complexity involved in filing and prosecuting a patent
	application. Your author does <I>not</I> recommend going it alone, unless one is willing to put far more time into
	learning about it and doing it than one could possibly imagine. <A NAME="PatentInfringement"></A></P>
	<P>
	<DT><B>Patent Infringement</B></DT>
	<DD>Patent infringement occurs when someone makes, sells, or uses a <A HREF="Glossary.htm#Patent">patented</A> invention without
	license from the patent holder.
	<P>Normally the offender will be contacted, and there may be a settlement and proper licensing, or the offender
	may be able to design around the patent, or offender may simply stop infringing. Should none of these things occur,
	the appropriate eventual response is a patent infringement lawsuit in federal court. <A NAME="PerfectSecrecy"></A></P>
	<P>
	<DT><B>Perfect Secrecy</B></DT>
	<DD>The unbreakable <A HREF="Glossary.htm#Strength">strength</A> delivered by a <A HREF="Glossary.htm#Cipher">cipher</A> in which all possible
	<A HREF="Glossary.htm#Ciphertext">ciphertexts</A> may be <A HREF="Glossary.htm#Key">key</A>-selected with equal probability given any possible
	<A HREF="Glossary.htm#Plaintext">plaintext</A>. This means that no ciphertext can imply any particular plaintext any more than
	any other. This sort of cipher needs as much keying information as there is message information to be protected.
	A cipher with perfect secrecy has at least as many keys as messages, and may be seen as a (huge) <A HREF="Glossary.htm#LatinSquare">Latin
	square</A>.
	<P>There are some examples:
	<UL>
		<LI>(Theoretically) the <A HREF="Glossary.htm#OneTimePad">one-time pad</A> with a perfectly <A HREF="Glossary.htm#Random">random</A> pad
		generator.
		<LI>The <A HREF="Glossary.htm#DynamicTransposition">Dynamic Transposition</A> cipher approaches perfect secrecy in that every
		ciphertext is a bit-permuted balanced block. Thus, every possible plaintext block is just a particular permutation
		of any ciphertext block. Since the permutation is created by a <A HREF="Glossary.htm#Key">keyed</A> <A HREF="Glossary.htm#RNG">RNG</A>,
		we expect any particular permutation to &quot;never&quot; re-occur, and be easily protected from <A HREF="Glossary.htm#DefinedPlaintextAttack">defined
		plaintext attack</A> with the usual <A HREF="Glossary.htm#MessageKey">message key</A>. We also expect that the RNG itself will
		be protected by the vast number of different sequences which could produce the exact same bit-pattern for any ciphertext
		result.
	</UL>
	<P>Also see: <A HREF="Glossary.htm#IdealSecrecy">ideal secrecy</A>. From Claude Shannon. <A NAME="Permutation"></A></P>
	<P>
	<DT><B>Permutation</B></DT>
	<DD>The mathematical term for a particular arrangement of symbols, objects, or other elements. With <I>n</I> symbols,
	there are
	<PRE>   P(n) = n*(n-1)*(n-2)*...*2*1 = n!
</PRE>
	or <I>n</I>- <A HREF="Glossary.htm#Factorial">factorial</A> possible permutations. The number of permutations of <I>n</I> things
	taken <I>k</I> at a time is:
	<PRE>   P(n,k) = n! / (n-k)!
</PRE>
	<P>See the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM#Permutations'" tppabs="http://www.io.com/~ritter/JAVASCRP/PERMCOMB.HTM#Permutations">permutations</A> section of the
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages. Also see
	<A HREF="Glossary.htm#Combination">combination</A> and <A HREF="Glossary.htm#SymmetricGroup">symmetric group</A>.</P>
	<P>A <A HREF="Glossary.htm#BlockCipher">block cipher</A> can be seen as a transformation between <A HREF="Glossary.htm#Plaintext">plaintext</A>
	<A HREF="Glossary.htm#Block">block</A> values and <A HREF="Glossary.htm#Ciphertext">ciphertext</A> block values, and is thus an emulated
	<A HREF="Glossary.htm#SimpleSubstitution">simple substitution</A> on huge block-wide values. Both plaintext and ciphertext
	have the same set of possible block values, and when the ciphertext values have the same ordering as the plaintext,
	ciphering is obviously ineffective. So <I>effective</I> ciphering depends upon <I>re-arranging</I> the ciphertext
	values from the plaintext ordering, which is a <I>permutation</I> of the plaintext values. A block cipher is <A
	HREF="Glossary.htm#Key">keyed</A> by constructing a <I>particular</I> permutation of ciphertext values.</P>
	<P>Within an explicit <A HREF="Glossary.htm#SubstitutionTable">table</A>, an arbitrary permutation (one of the set of all possible
	permutations) can be produced by <A HREF="Glossary.htm#Shuffle">shuffling</A> the elements under the control of a <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A>. If, as usual, the random number generator has been initialized from a <A HREF="Glossary.htm#Key">key</A>,
	a particular permutation can be produced for each particular key; thus, each key selects a particular permutation.</P>
	<P>Also, the second part of <A HREF="Glossary.htm#SubstitutionPermutation">substitution-permutation</A> <A HREF="Glossary.htm#BlockCipher">block
	ciphers</A>: First, <A HREF="Glossary.htm#SimpleSubstitution">substitution</A> operations <A HREF="Glossary.htm#Diffusion">diffuse</A>
	information across the width of each substitutions. Next, &quot;permutation&quot; operations act to re-arrange
	the bits of the substituted result (more clearly described as a set of <A HREF="Glossary.htm#Transposition">transpositions</A>);
	this ends a single round. In subsequent rounds, further substitutions and transpositions occur until the block
	is thoroughly mixed and <A HREF="Glossary.htm#OverallDiffusion">overall diffusion</A> hopefully achieved. <A NAME="PGP"></A></P>
	<P>
	<DT><B>PGP</B></DT>
	<DD>A popular <A HREF="Glossary.htm#PublicKeyCipher">public key cipher</A> system using both <A HREF="Glossary.htm#RSA">RSA</A> and <A
	HREF="Glossary.htm#IDEA">IDEA</A> ciphers. RSA is used to tranfer a random key; IDEA is used to actually protect the message.
	<P>One problem with PGP is a relatively unworkable facility for <A HREF="Glossary.htm#Authentication">authenticating</A> public
	keys. While the users can compare a cryptographic hash of a key, this requires communication through a different
	channel, which is more than most users are willing to do. The result is a system which generally supports <A HREF="Glossary.htm#ManInTheMiddleAttack">man-in-the-middle
	attacks</A>, and these do <B>not</B> require &quot;breaking&quot; either of the ciphers. <A NAME="PhysicallyRandom"></A></P>
	<P>
	<DT><B>Physically Random</B></DT>
	<DD>A random value or sequence derived from a physical source, typically thermal-electrical noise. Also called
	<A HREF="Glossary.htm#ReallyRandom">really random</A> and <A HREF="Glossary.htm#TrulyRandom">truly random</A>. <A NAME="PinkNoise"></A>
	<P>
	<DT><B>Pink Noise</B></DT>
	<DD>A <A HREF="Glossary.htm#Random">random</A>-like signal in which the magnitude of the spectrum at each <A HREF="Glossary.htm#Frequency">frequency</A>
	is proportional to the inverse of the frequency, or 1/f. At twice the frequency, we have half the energy, which
	is -3 <A HREF="Glossary.htm#dB">dB</A>. This is a frequency-response slope of -3 dB / octave, or -10 dB / decade. As opposed
	to <A HREF="Glossary.htm#WhiteNoise">white noise</A>, which has the same energy at all frequencies, pink noise has more low-frequency
	or &quot;red&quot; components, and so is called &quot;pink.&quot;
	<P>A common frequency response has half the output <A HREF="Glossary.htm#Voltage">voltage</A> at twice the frequency. But this
	is actually one-quarter the power and so is a -6 dB / octave drop. For pink noise, the desired voltage drop per
	octave is 0.707. <A NAME="Plaintext"></A></P>
	<P>
	<DT><B>Plaintext</B></DT>
	<DD>Plaintext is the original, readable message. It is convenient to think of plaintext as being actual language
	characters, but may be any other symbols or values (such as arbitrary <A HREF="Glossary.htm#Computer">computer</A> data) which
	need to be protected. <A NAME="PoissonDistribution"></A>
	<P>
	<DT><B>Poisson Distribution</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a simplified form of the <A HREF="Glossary.htm#BinomialDistribution">binomial
	distribution</A>, justified when we have:
	<P>
	<OL>
		<LI>a large number of trials <I>n,</I>
		<LI>a small probability of success <I>p,</I> and
		<LI>an expectation <I>np</I> much smaller than SQRT(<I>n</I>).
	</OL>
	<P>The probability of finding exactly <I>k</I> successes when we have expectation <I>u</I> is:</P>
	<PRE>             k  -u
   P(k,u) = u  e    /  k!
</PRE>
	where <I>e</I> is the base of natural logarithms:
	<PRE>   e = 2.71828...
</PRE>
	and <I>u</I> is:
	<PRE>   u = n p
</PRE>
	again for <I>n</I> independent trials, when each trial has success probability <I>p.</I> In the Poisson distribution,
	<I>u</I> is also both the mean and the variance
	<P>The ideal <A HREF="Glossary.htm#Distribution">distribution</A> is produced by evaluating the probability function for all
	possible <I>k,</I> from 0 to <I>n.</I></P>
	<P>If we have an experiment which we think <I>should</I> produce a Poisson distribution, and then repeatedly and
	systematically find very improbable test values, we may choose to reject the <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>
	that the experimental distribution is in fact Poisson.</P>
	<P>Also see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#Poisson'" tppabs="http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#Poisson">Poisson</A> section of the <A
	HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages. <A NAME="PolyalphabeticCombiner"></A></P>
	<P>
	<DT><B>Polyalphabetic Combiner</B></DT>
	<DD>A <A HREF="Glossary.htm#Combiner">combining</A> <A HREF="Glossary.htm#Mechanism">mechanism</A> in which one input selects a substitution
	alphabet (or table), and another input selects a value from within the selected alphabet, said value becoming the
	combining result. Also called a <A HREF="Glossary.htm#TableSelectionCombiner">Table Selection Combiner</A>. <A NAME="PolyalphabeticSubstitution"></A>
	<P>
	<DT><B>Polyalphabetic Substitution</B></DT>
	<DD>A type of <A HREF="Glossary.htm#Substitution">substitution</A> in which multiple distinct <A HREF="Glossary.htm#SimpleSubstitution">simple
	substitution</A> alphabets are used. <A NAME="PolygramSubstitution"></A>
	<P>
	<DT><B>Polygram Substitution</B></DT>
	<DD>A type of <A HREF="Glossary.htm#Substitution">substitution</A> in which one or more symbols are substituted for one or
	more symbols. The most general possible substitution. <A NAME="Polygraphic"></A>
	<P>
	<DT><B>Polygraphic</B></DT>
	<DD>Greek for &quot;multiple letters.&quot; A <A HREF="Glossary.htm#Cipher">cipher</A> which translates multiple <A HREF="Glossary.htm#Plaintext">plaintext</A>
	symbols at a time into <A HREF="Glossary.htm#Ciphertext">ciphertext</A>. As opposed to <A HREF="Glossary.htm#Monographic">monographic</A>;
	also see <A HREF="Glossary.htm#Homophonic">homophonic</A> and <A HREF="Glossary.htm#Polyphonic">polyphonic</A>. <A NAME="Polynomial"></A>
	<P>
	<DT><B>Polynomial</B></DT>
	<DD>Mathematically, an expression in the standard form of: <BIG>
	<PRE>     c<SUB>n</SUB>x<SUP>n</SUP> + . . . + c<SUB>1</SUB>x + c<SUB>0</SUB>
</PRE>
</BIG>
	The c's or <I>coefficients</I> are elements of some <A HREF="Glossary.htm#Field">field</A> F. The <I>degree</I> <I>n</I> is
	the value of the exponent of the highest power term. A <A HREF="Glossary.htm#Mod2Polynomial">mod 2 polynomial</A> of degree
	<I>n</I> has <I>n</I>+1 bits representing the coefficients for each power: <I>n</I>, <I>n</I>-1, ..., 1, 0.
	<P>Perhaps the most insightful part of this is that the addition of coefficients for a particular power does not
	&quot;carry&quot; into other coefficients or columns. <A NAME="Polyphonic"></A></P>
	<P>
	<DT><B>Polyphonic</B></DT>
	<DD>Greek for &quot;multiple sounds.&quot; The concept of having a letter sequence which is pronounced in distinctly
	different ways, depending on context. In <A HREF="Glossary.htm#Cryptography">cryptography</A>, a <A HREF="Glossary.htm#Cipher">cipher</A>
	which uses a single <A HREF="Glossary.htm#Ciphertext">ciphertext</A> symbol to represent multiple different <A HREF="Glossary.htm#Plaintext">plaintext</A>
	symbols. Also see <A HREF="Glossary.htm#Homophonic">homophonic</A>, <A HREF="Glossary.htm#Polygraphic">polygraphic</A> and <A HREF="Glossary.htm#Monographic">monographic</A>.
	<A NAME="Population"></A>
	<P>
	<DT><B>Population</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the size, or the number of distinct elements in the possibly hidden
	universe of elements which we can only know by <A HREF="Glossary.htm#Sample">sampling</A>. <A NAME="PopulationEstimation"></A>
	<P>
	<DT><B>Population Estimation</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, techniques used to predict the <A HREF="Glossary.htm#Population">population</A>
	based only on information from random <A HREF="Glossary.htm#Sample">samples</A> on that population. See <A HREF="Glossary.htm#AugmentedRepetitions">augmented
	repetitions</A>. <A NAME="Power"></A>
	<P>
	<DT><B>Power</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the probability of rejecting a false <A HREF="Glossary.htm#NullHypothesis">null
	hypothesis</A>, and thus accepting a true <A HREF="Glossary.htm#AlternativeHypothesis">alternative hypothesis</A>.
	<P>In <A HREF="Glossary.htm#DC">DC</A> <A HREF="Glossary.htm#Electronic">electronics</A>, simply <A HREF="Glossary.htm#Voltage">voltage</A> times <A
	HREF="Glossary.htm#Current">current</A>. In <A HREF="Glossary.htm#AC">AC</A> electronics, the instantaneous product of voltage times current,
	integrated over a repetitive cycle. In either case the result is in watts, denoted W. <A NAME="Primitive"></A></P>
	<P>
	<DT><B>Primitive</B></DT>
	<DD>A value within a <A HREF="Glossary.htm#FiniteField">finite field</A> which, when taken to increasing powers, produces all
	field values except zero. A primitive binary <A HREF="Glossary.htm#Polynomial">polynomial</A> will be <A HREF="Glossary.htm#Irreducible">irreducible</A>,
	but not all irreducibles are necessarily primitive. <A NAME="PrimitivePolynomial"></A>
	<P>
	<DT><B>Primitive Polynomial</B></DT>
	<DD>An <A HREF="Glossary.htm#Irreducible">irreducible</A> <A HREF="Glossary.htm#Polynomial">polynomial</A>, <A HREF="Glossary.htm#Primitive">primitive</A>
	within a given <A HREF="Glossary.htm#Field">field</A>, which generates a <A HREF="Glossary.htm#MaximalLength">maximal length</A> sequence
	in <A HREF="Glossary.htm#LinearFeedbackShiftRegister">linear feedback shift register</A> (LFSR) applications.
	<P>All primitive polynomials are <A HREF="Glossary.htm#Irreducible">irreducible</A>, but irreducibles are not necessarily primitive,
	unless the degree of the polynomial is a <A HREF="Glossary.htm#MersennePrime">Mersenne prime</A>. One way to find a primitive
	polynomial is to select an appropriate Mersenne prime degree and find an irreducible using Algorithm A of Ben Or:</P>
	<PRE>     1.  Generate a monic random polynomial gx of degree n over GF(q);
     2.  ux := x;
     3.  for k := 1 to (n DIV 2) do
     4.     ux := ux^q mod gx;
     5.     if GCD(gx, ux-x)  1 then go to 1 fi;
     6.     od
</PRE>
	<BLOCKQUOTE>
		<P>Ben-Or, M. 1981. Probabilistic algorithms in finite fields. <I>Proceedings of the 22nd IEEE Foundations of Computer
		Science Symposium.</I> 394-398.
	</BLOCKQUOTE>
	<P>The result is a certified irreducible. <A HREF="Glossary.htm#GF2n">GF(q)</A> represents the Galois Field to the prime base
	<I>q</I>; for <A HREF="Glossary.htm#Mod2">mod 2</A> polynomials, <I>q</I> is 2. These computations require <A HREF="Glossary.htm#Mod2Polynomial">mod
	2 polynomial</A> arithmetic operations for polynomials of large degree; &quot;<I>ux<SUP>q</SUP></I>&quot; is a
	polynomial squared, and &quot;mod <I>gx</I>&quot; is a polynomial division. A &quot;monic&quot; polynomial has
	a leading coefficient of 1; this is a natural consequence of mod 2 polynomials of any degree. The first step assigns
	the polynomial &quot;x&quot; to the variable <I>ux</I>; the polynomial &quot;x&quot; is x<SUP>1</SUP>, otherwise
	known as &quot;10&quot;.</P>
	<P>To get primitives of non-Mersenne prime degree n, we certify irreducibles P of degree n. To do this, we must
	factor the value <NOBR>2<SUP>n</SUP> - 1</NOBR> (which can be a difficult problem, in general). Then, for each
	factor d of <NOBR>2<SUP>n</SUP> - 1</NOBR> we create the polynomial T(d) which is <NOBR>x<SUP>d</SUP> + 1</NOBR>;
	this is a polynomial with just two bits set: bit d and bit 0. If P evenly divides T(d) for some divisor d, P cannot
	be primitive. So if P does not divide any T(d) for all distinct divisors d of <NOBR>2<SUP>n</SUP> - 1,</NOBR> P
	is primitive. <A NAME="Prime"></A></P>
	<P>
	<DT><B>Prime</B></DT>
	<DD>In general, a positive <A HREF="Glossary.htm#Integer">integer</A> which is evenly divisible only by itself and 1.
	<P>Small primes can be found though the ever-popular <A HREF="Glossary.htm#SieveOfEratosthenes">Sieve of Eratosthenes</A>,
	which can also be used to develop a list of small primes used for testing individual values. A potential prime
	need only be divided by each prime equal to or less than the square-root of the value of interest; if any remainder
	is zero, the number is not prime.</P>
	<P>Large primes can be found by probabilistic tests. <A NAME="PriorArt"></A></P>
	<P>
	<DT><B>Prior Art</B></DT>
	<DD>In <A HREF="Glossary.htm#Patent">patents</A>, the knowledge published or otherwise available to the public as of some date.
	Traditionally, this &quot;knowledge&quot; is in ink-on-paper articles or patents, both of which have provable release
	dates. Private &quot;in house&quot; journals available only within a company generally would not be prior art,
	nor would information which has been kept secret. Normally, we expect prior art information to be available in
	a public library.
	<P>In a U.S. application for patent, we are interested in the state of the open or public art as it existed as
	of the invention date, and also one year prior to the filing date. It is that art -- and not something hidden or
	something later -- against which the new application must be judged. Many things which seem &quot;obvious&quot;
	in retrospect were really quite innovative at the time they were done. <A NAME="PRNG"></A></P>
	<P>
	<DT><B>PRNG</B></DT>
	<DD><A HREF="Glossary.htm#PseudoRandom">Pseudo Random</A> Number Generator. In general, <I>pseudo</I>randomness is the norm.
	Any <A HREF="Glossary.htm#Computer">computer</A> <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A> which is not
	explicitly labeled as <A HREF="Glossary.htm#PhysicallyRandom">physically random</A>, <A HREF="Glossary.htm#ReallyRandom">really random</A>,
	or other such description, is almost certainly <I>pseudo</I>random. <A NAME="Process"></A>
	<P>
	<DT><B>Process</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a sequence of values; a source or generator of such a sequence; a
	function. <A NAME="PseudoRandom"></A>
	<P>
	<DT><B>Pseudorandom</B></DT>
	<DD>A value or sequence of values typically produced by a <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>,
	a <A HREF="Glossary.htm#Deterministic">deterministic</A> computational mechanism. As opposed to <A HREF="Glossary.htm#ReallyRandom">really
	random</A>. Also see <A HREF="Glossary.htm#Random">random</A>.
	<P>The usual random number generator is actually <B><I>pseudo</I>random</B>. Given the initial <A HREF="Glossary.htm#State">state</A>,
	the entire subsequent sequence is completely pre-determined, but nevertheless exhibits many of the expected characteristics
	of a random sequence. Pseudorandomness supports generating the exact same cryptographic sequence repeatedly at
	different times or locations. Pseudorandomness is generally produced by a mathematical process, which may provide
	good assurances as to the resulting <A HREF="Glossary.htm#Statistics">statistics</A>, assurances which a really random generator
	generally cannot provide. <A NAME="PublicKeyCipher"></A></P>
	<P>
	<DT><B>Public Key Cipher</B></DT>
	<DD>Also called an <A HREF="Glossary.htm#AsymmetricCipher">asymmetric cipher</A> or a <I>two-key</I> cpher. A <A HREF="Glossary.htm#Cipher">cipher</A>
	which uses one <A HREF="Glossary.htm#Key">key</A> to <A HREF="Glossary.htm#Encipher">encipher</A> a message, and a <I>different</I> key
	to <A HREF="Glossary.htm#Decipher">decipher</A> the resulting <A HREF="Glossary.htm#Ciphertext">ciphertext</A>. This allows the enciphering
	key to be exposed, without exposing the message. As opposed to a <A HREF="Glossary.htm#SecretKeyCipher">secret key cipher</A>.
	<P>Either key can be used for enciphering or deciphering. Usually the exposed key is called the &quot;public&quot;
	key, and the retained hidden key is called the &quot;private&quot; key. The public key is distributed widely, so
	anyone can use it to encipher a message which presumably can only be deciphered by the hidden private key on the
	other end. Note that the enciphering end normally does not possess a key which will decipher a message which was
	just enciphered.</P>
	<P>The whole scheme of course depends upon the idea that the private key cannot be developed from knowledge of
	the public key. The cipher also must resist both <A HREF="Glossary.htm#KnownPlaintextAttack">known-plaintext</A> <I>and</I>
	<A HREF="Glossary.htm#DefinedPlaintextAttack">defined-plaintext</A> attack (since anyone can generate any amount of plaintext
	and encipher it). A public key cipher is vastly slower than a secret key cipher, and so is normally used simply
	to deliver the <A HREF="Glossary.htm#MessageKey">message key</A> or session key for a conventional or secret key cipher.</P>
	<P>Although at first proclaimed as a solution to the <A HREF="Glossary.htm#KeyDistributionProblem">key distribution problem</A>,
	it soon became apparent that someone could <I>pretend</I> to be someone else, and send out a &quot;spoofed&quot;
	public key. When people use that key, the spoofer could receive the message, decipher and read it, then re-encipher
	the message under the correct key and send it to the correct destination. This is known as a <A HREF="Glossary.htm#ManInTheMiddleAttack">man-in-the-middle</A>
	(MITM) attack.</P>
	<P>A MITM attack is unusual in that it can penetrate cipher security <I>without</I> &quot;<A HREF="Glossary.htm#Break">breaking</A>&quot;
	<I>either</I> the public key cipher <I>or</I> the internal secret key cipher, and takes almost no computational
	effort. This is <I>extremely serious</I> because it means that the use of even &quot;unbreakable&quot; ciphers
	is <B>not</B> sufficient to guarantee privacy. All the effort spent on proving the strength of either cipher is
	simply wasted when a MITM attack is possible, and MITM attacks are only possible with public key ciphers.</P>
	<P>To prevent spoofing, public keys must be <A HREF="Glossary.htm#Authentication">authenticated</A> (or <I>validated</I> or
	<I>certified</I>) as representing who they claim to represent. This can be almost as difficult as the conventional
	key distribution problem and generally requires complex protocols. And a failure in a key certification protocol
	can expose a system which uses &quot;unbreakable&quot; ciphers. In contrast, the simple use of an &quot;unbreakable&quot;
	secret key cipher (with hand-delivered keys) <B>is</B> sufficient to guarantee security. This is a real, vital
	difference between ciphering models. <A NAME="Random"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Random</B>
	<DD>A process which selects unpredictably, each time independent of all previous times, from among multiple possible
	results; or a result from such a process. Ideally, an arbitrary <A HREF="Glossary.htm#State">stateless</A> selection from among
	equiprobable outcomes, thus producing a <A HREF="Glossary.htm#UniformDistribution">uniform distribution</A> of values. The
	absence of pattern. Also see <A HREF="Glossary.htm#PseudoRandom">pseudorandom</A>.
	<P>Randomness is an attribute of the <I>process</I> which generates or selects &quot;random&quot; numbers rather
	than the numbers themselves. But the numbers do carry the ghost of their creation: If values really are randomly
	generated with the same probability, we expect to find <I>almost</I> the same number of occurrences of each value
	or each sequence of the same length. Over many values and many sequences we expect to see results form in <A HREF="Glossary.htm#Distribution">distributions</A>
	which accord with our understanding of random processes. So if we do not find these expectations in the resulting
	numbers, we may have reason to suspect that the generating process is not random. Unfortunately, any such suspicion
	is necessarily <A HREF="Glossary.htm#Statistic">statistical</A> in nature, and cannot produce absolute proof in either direction:
	Randomness can produce <I>any</I> relationship between values, including apparent <A HREF="Glossary.htm#Correlation">correlations</A>
	(or their lack) which do not in fact represent the systematic production of the generator. (Also see the discussions
	of randomness testing in <A HREF="Glossary.htm#Statistics">Statistics</A> and <A HREF="Glossary.htm#NullHypothesis">Null Hypothesis</A>,
	the article <A HREF="javascript:if(confirm('http://www.io.com/~ritter/ARTS/RUNSUP.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/ARTS/RUNSUP.HTM'" tppabs="http://www.io.com/~ritter/ARTS/RUNSUP.HTM">Chi-Square Bias in Runs-Up/Down RNG Tests</A>,
	also <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/RANDTEST.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/RANDTEST.HTM'" tppabs="http://www.io.com/~ritter/RES/RANDTEST.HTM">Randomness Tests: A Literature Survey</A>, in the <A
	HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page, and <A HREF="javascript:if(confirm('http://www.io.com/~ritter/NETLINKS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/NETLINKS.HTM#RandomnessLinks'" tppabs="http://www.io.com/~ritter/NETLINKS.HTM#RandomnessLinks">Randomness Links</A>,
	in <A HREF="javascript:if(confirm('http://www.io.com/~ritter/NETLINKS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/NETLINKS.HTM'" tppabs="http://www.io.com/~ritter/NETLINKS.HTM">Ritter's Net Links</A> page.)</P>
	<P>From one point of view, there are no &quot;less random&quot; or &quot;more random&quot; sequences, since any
	sequence can be produced by a random process. And any sequence (at least any <I>particular</I> sequence) <I>also</I>
	can be produced by a <A HREF="Glossary.htm#Deterministic">deterministic</A> computational <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A>. (We note that such generators are specifically designed to and do pass statistical randomness
	tests.) So the difference is not in the sequences, <I>per se,</I> but instead in the generators: For one thing,
	an RNG sequence is deterministic and therefore may somehow be predicted. But, in practice, extensive analysis could
	show deviations from randomness in <I>either</I> the deterministic RNG designs <I>or</I> the nondeterministic <A
	HREF="Glossary.htm#ReallyRandom">really random</A> generation equipment, and this could make even a nondeterministic generator
	somewhat predictable.</P>
	<P>There are &quot;more complex&quot; and &quot;less complex&quot; sequences according to various measures. For
	example:
	<UL>
		<LI><A HREF="Glossary.htm#LinearComplexity">Linear complexity</A> grades sequences on the size of the minimum shift-register
		<A HREF="Glossary.htm#State">state</A> needed to produce the sequence.
		<LI>Kolmogorov-Chaitin complexity grades sequences on the size of the description of the algorithm needed to produce
		the sequence.
	</UL>
	These measures produce values related to the amount of pattern in a sequence, or the extent to which a sequence
	can be predicted by some algorithmic model. Such values describe the uncertainty of a sequence, and are in this
	way related to <A HREF="Glossary.htm#Entropy">entropy</A>.
	<P>We should note that the subset of sequences which have a high linear complexity leaves a substantial subset
	which does not. So if we avoid sequences with low linear complexity, any sequence we do accept must be <I>more</I>
	probable than it would be in the unfiltered set of all possible sequences. In this case, the expected higher uncertainty
	of the sequence itself is at least partly offset by the certainty that such a sequence will be used. Similar logic
	applies to <A HREF="Glossary.htm#S-Box">S-box</A> measurement and selection.</P>
	<P>Oddly -- and much like <A HREF="Glossary.htm#Strength">strength</A> in <A HREF="Glossary.htm#Cipher">ciphers</A> -- the &quot;unpredictable&quot;
	part of randomness is <A HREF="Glossary.htm#Contextual">contextual</A> and <A HREF="Glossary.htm#Subjective">subjective</A>, rather than
	the <A HREF="Glossary.htm#Absolute">absolute</A> and <A HREF="Glossary.htm#Objective">objective</A> qualities we like in Science. While
	the sequence from a complex <A HREF="Glossary.htm#RNG">RNG</A> can <I>appear</I> random, if we know the secret of the generator
	construction, and its <A HREF="Glossary.htm#State">state</A>, we can predict the sequence exactly. But often we are in the
	position of seeing the sequence alone, <I>without</I> knowing the source, the construction, or the internal state.
	So while <I>we</I> might see a sequence as &quot;random,&quot; that same sequence might be absolutely predictable
	(and thus <I>not</I> random) to someone who knows &quot;the secret.&quot; <A NAME="RandomNumberGenerator"></A></P>
	<P>
	<DT><B>Random Number Generator</B></DT>
	<DD>A <A HREF="Glossary.htm#Random">random</A> number generator is a standard computational tool which creates a sequence of
	apparently unrelated numbers which are often used in statistics and other computations.
	<P>In practice, most random number generators are <A HREF="Glossary.htm#Deterministic">deterministic</A> computational mechanisms,
	and each number is directly determined from the previous <A HREF="Glossary.htm#State">state</A> of the mechanism. Such a sequence
	is often called <A HREF="Glossary.htm#PseudoRandom">pseudo-random</A>, to distinguish it from a <A HREF="Glossary.htm#ReallyRandom">really
	random</A>, sequence somehow composed of actually unrelated values.</P>
	<P>A computational random number generator will always generate the same sequence if it is started in the same
	state. So if we initialize the state from a <A HREF="Glossary.htm#Key">key</A>, we can use the random number generator to <A
	HREF="Glossary.htm#Shuffle">shuffle</A> a table into a particular order which we can reconstruct any time we have the same
	key. (See, for example: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/KEYSHUF.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/KEYSHUF.HTM'" tppabs="http://www.io.com/~ritter/KEYSHUF.HTM">A Keyed Shuffling System for Block Cipher
	Cryptography</A>.)</P>
	<P>Note that random number generators are <I>designed</I> to pass the many <A HREF="Glossary.htm#Statistic">statistical</A>
	tests of randomness; clearly, such tests do not indicate a <A HREF="Glossary.htm#ReallyRandom">really random</A> sequence.
	Moreover, if we define &quot;random&quot; as &quot;the absence of any pattern,&quot; the only way we could validate
	such a sequence is by checking for every possible pattern. But there are too many patterns, so &quot;real&quot;
	randomness would seem to be impossible to check experimentally. (Also see the discussions of randomness testing
	in <A HREF="Glossary.htm#Statistics">Statistics</A> and <A HREF="Glossary.htm#NullHypothesis">Null Hypothesis</A>.)</P>
	<P>Also see the article: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/ARTS/CRNG2ART.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/ARTS/CRNG2ART.HTM'" tppabs="http://www.io.com/~ritter/ARTS/CRNG2ART.HTM">The Efficient Generation of Cryptographic
	Confusion Sequences</A>, plus <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/RNGENS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/RNGENS.HTM'" tppabs="http://www.io.com/~ritter/RES/RNGENS.HTM">RNG Implementations: A Literature
	Survey</A>, <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/RNGSURVE.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/RNGSURVE.HTM'" tppabs="http://www.io.com/~ritter/RES/RNGSURVE.HTM">RNG Surveys: A Literature Survey</A>, in the <A
	HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page, and <A HREF="javascript:if(confirm('http://www.io.com/~ritter/NETLINKS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/NETLINKS.HTM#RandomnessLinks'" tppabs="http://www.io.com/~ritter/NETLINKS.HTM#RandomnessLinks">Randomness Links</A>,
	in <A HREF="javascript:if(confirm('http://www.io.com/~ritter/NETLINKS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/NETLINKS.HTM'" tppabs="http://www.io.com/~ritter/NETLINKS.HTM">Ritter's Net Links</A> page. <A NAME="RandomVariable"></A></P>
	<P>
	<DT><B>Random Variable</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a term or label for an unknown value. Also used when each of the possible
	values have some known probability.
	<P>A <I>discrete</I> random variable takes on a finite set of values. The probability of each value is the <I>frequency
	function</I> or <I>probability density function</I>, and the graph of the frequency function is the frequency <A
	HREF="Glossary.htm#Distribution">distribution</A>. <A NAME="Range"></A></P>
	<P>
	<DT><B>Range</B></DT>
	<DD>The set of the results from a <A HREF="Glossary.htm#Mapping">mapping</A> for all possible arguments. Also see: <A HREF="Glossary.htm#Domain">domain</A>.
	<A NAME="ReallyRandom"></A>
	<P>
	<DT><B>Really Random</B></DT>
	<DD>A <A HREF="Glossary.htm#Random">random</A> value or sequence derived from a source which is expected to produce no predictable
	or repeatable relationship between values.
	<P>Examples of a really random source might include radioactive decay, Johnson or thermal noise, shot noise from
	a Zener diode or reverse-biased junction in breakdown, etc. Clearly, some sort of circuitry will be required to
	detect these generally low-level events, and the quality of the result is often directly related to the design
	of the <A HREF="Glossary.htm#Electronic">electronic</A> processing. Other sources of randomness might be precise keystroke
	timing, and the accumulated hash of text of substantial size. Also called <A HREF="Glossary.htm#PhysicallyRandom">physically
	random</A> and <A HREF="Glossary.htm#TrulyRandom">truly random</A>. As opposed to <A HREF="Glossary.htm#PseudoRandom">pseudorandom</A>
	(see <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>).</P>
	<P>Really random values are particularly important as <A HREF="Glossary.htm#MessageKey">message key</A> objects, or as a sequence
	for use in a realized <A HREF="Glossary.htm#OneTimePad">one-time pad</A>.</P>
	<P>Also see: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/RNGMACH.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/RNGMACH.HTM'" tppabs="http://www.io.com/~ritter/RES/RNGMACH.HTM">Random Number Machines: A Literature Survey</A>
	and <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/NOISE.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/NOISE.HTM'" tppabs="http://www.io.com/~ritter/RES/NOISE.HTM">Random Electrical Noise: A Literature Survey</A>, in the
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page, and <A HREF="javascript:if(confirm('http://www.io.com/~ritter/NETLINKS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/NETLINKS.HTM#RandomnessLinks'" tppabs="http://www.io.com/~ritter/NETLINKS.HTM#RandomnessLinks">Randomness Links</A>,
	in <A HREF="javascript:if(confirm('http://www.io.com/~ritter/NETLINKS.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/NETLINKS.HTM'" tppabs="http://www.io.com/~ritter/NETLINKS.HTM">Ritter's Net Links</A> page. <A NAME="Relay"></A></P>
	<P>
	<DT><B>Relay</B></DT>
	<DD>Classically, an electro-mechanical <A HREF="Glossary.htm#Component">component</A> consisting of a mechanical <A HREF="Glossary.htm#Switch">switch</A>
	operated by the magnetic force produced by an electromagnet, a conductor wound around an iron dowel or core. A
	relay is at least potentially a sort of mechanical (slow) and <A HREF="Glossary.htm#Linear">nonlinear</A> <A HREF="Glossary.htm#Amplifier">amplifier</A>
	which is well-suited to power control. <A NAME="ResearchHypothesis"></A>
	<P>
	<DT><B>Research Hypothesis</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the statement formulated so that the logically contrary statement,
	the <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A> <I>H</I><SUB>0</SUB> has a test <A HREF="Glossary.htm#Statistic">statistic</A>
	with a known <A HREF="Glossary.htm#Distribution">distribution</A> for the case when there is nothing unusual to detect. Also
	called the <A HREF="Glossary.htm#AlternativeHypothesis">alternative hypothesis</A> <I>H</I><SUB>1</SUB>, and logically identical
	to &quot;NOT-<I>H</I><SUB>0</SUB>&quot; or &quot;<I>H</I><SUB>0</SUB> is not true.&quot; <A NAME="Resistor"></A>
	<P>
	<DT><B>Resistor</B></DT>
	<DD>A basic electronic <A HREF="Glossary.htm#Component">component</A> in which <A HREF="Glossary.htm#Voltage">voltage</A> and <A HREF="Glossary.htm#Current">current</A>
	are <A HREF="Glossary.htm#Linear">linearly</A> related by Ohm's Law: <NOBR><B>E = IR</B></NOBR>. Resistors can thus be used
	to limit current I given voltage E: <NOBR>(I = E/R),</NOBR> or to produce voltage E from current I: <NOBR>(E =
	IR).</NOBR> Two resistors in series can divide voltage Ein to produce the output voltage Eo: <NOBR>( Eo = Ein(R1/(R1+R2))
	).</NOBR>
	<P>Also see <A HREF="Glossary.htm#Capacitor">capacitor</A> and <A HREF="Glossary.htm#Inductor">inductor</A>. <A NAME="Ring"></A></P>
	<P>
	<DT><B>Ring</B></DT>
	<DD>In abstract algebra, a nonempty set R with two dyadic (two-input, one-output) operations which we choose to
	call &quot;addition&quot; and &quot;multiplication&quot; and denote + and * as usual. If elements (not necessarily
	numbers) a, b are in R, then a+b is in R, and ab (or a*b) are also in R. The following properties hold:
	<OL>
		<LI><B>Addition is commutative:</B> a + b = b + a
		<LI><B>Addition is associative:</B> (a + b) + c = a + (b + c)
		<LI><B>There is a &quot;zero&quot; or additive identity:</B> a + 0 = a
		<LI><B>There is an additive inverse:</B> for any a there is an x in R such that a + x = 0
		<LI><B>Multiplication is associative:</B> (ab)c = a(bc)
		<LI><B>Multiplication is distributive:</B> a(b + c) = ab + ac and (b + c)a = ba + ca
		<LI><B>In a commutative ring, multiplication is commutative:</B> ab = ba
		<LI><B>In a ring with unity, there is a multiplicative identity:</B> for e in R, ea = ae = a
	</OL>
	<A NAME="Root"></A>
	<P>
	<DT><B>Root</B></DT>
	<DD>A solution: A value which, when substituted for a variable in a mathematical equation, makes the statement
	true. <A NAME="RMS"></A>
	<P>
	<DT><B>RMS</B></DT>
	<DD><A HREF="Glossary.htm#RootMeanSquare">root mean square</A>. <A NAME="RootMeanSquare"></A>
	<P>
	<DT><B>Root Mean Square</B></DT>
	<DD>The square root of the integral of instantaneous values squared. Thus, when measuring <A HREF="Glossary.htm#Voltage">voltage</A>
	or <A HREF="Glossary.htm#Current">current</A>, a value proportional to the average <A HREF="Glossary.htm#Power">power</A> in watts, even
	in a complex waveform. <A NAME="RNG"></A>
	<P>
	<DT><B>RNG</B></DT>
	<DD><A HREF="Glossary.htm#RandomNumberGenerator">Random Number Generator</A>. <A NAME="Round"></A>
	<P>
	<DT><B>Round</B></DT>
	<DD>In the context of <A HREF="Glossary.htm#BlockCipher">block cipher</A> design, a term often associated with a <A HREF="Glossary.htm#FeistelConstruction">Feistel</A>
	block cipher such as <A HREF="Glossary.htm#DES">DES</A>. A round is the set of operations which are repeated multiple times
	to produce the final data. For example, DES uses 16 generally identical rounds, each of which performs a number
	of operations. As opposed to a <A HREF="Glossary.htm#Layer">layer</A>, which is not applied repeatedly. <A NAME="RSA"></A>
	<P>
	<DT><B>RSA</B></DT>
	<DD>The name of an algorithm published by Ron Rivest, Adi Shamir, and Len Adleman (thus, R.S.A.). The first major
	<A HREF="Glossary.htm#PublicKeyCipher">public key</A> system.
	<P>Based on number-theoretic concepts and using huge numerical values, a RSA key must be perhaps ten times or more
	as long as a secret key for similar security. <A NAME="RunningKey"></A></P>
	<P>
	<DT><B>Running Key</B></DT>
	<DD>The <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> in a <A HREF="Glossary.htm#StreamCipher">stream cipher</A>. <A
	NAME="Salt"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Salt</B>
	<DD>An unnecessarily cute and sadly non-descriptive name for an arbitrary value, unique to a particular computer
	or installation, prepended to a password before <A HREF="Glossary.htm#Hash">hash</A> authentication. The &quot;salt&quot; acts
	to complicate attacks on the password user-identification process by giving the same password different hash results
	on different systems. Ideally, this would be a sort of <A HREF="Glossary.htm#Key">keying</A> for a secure hash. <A NAME="Sample"></A>
	<P>
	<DT><B>Sample</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, one or more elements, typically drawn at <A HREF="Glossary.htm#Random">random</A>
	from some <A HREF="Glossary.htm#Population">population</A>.
	<P>Normally, we cannot hope to examine the full population, and so must instead investigate <I>samples</I> of the
	population, with the hope that they represent the larger whole. Often, random sampling occurs &quot;without replacement&quot;;
	effectively, each individual sample is returned to the population before the next sample is drawn. <A NAME="S-Box"></A></P>
	<P>
	<DT><B>S-Box</B></DT>
	<DD><A HREF="Glossary.htm#Substitution">Substitution</A> box or <A HREF="Glossary.htm#SubstitutionTable">table</A>; typically a <A HREF="Glossary.htm#Component">component</A>
	of a cryptographic <A HREF="Glossary.htm#System">system</A>. &quot;S-box&quot; is a rather non-specific term, however, since
	S-boxes can have more inputs than outputs, or more outputs than inputs, each of which makes a single invertible
	table impossible. The S-boxes used in <A HREF="Glossary.htm#DES">DES</A> contain multiple invertible substitution tables, with
	the particular table used at any time being data-selected.
	<P>One possible S-box is the identity transformation (0-&gt;0, 1-&gt;1, 2-&gt;2, ...) which clearly has no effect
	at all, while every other transformation has at least some effect. So different S-boxes obviously <I>can</I> contain
	different amounts of some qualities. Qualities often mentioned include <A HREF="Glossary.htm#Avalanche">avalanche</A> and <A
	HREF="Glossary.htm#BooleanFunctionNonlinearity">Boolean function nonlinearity</A>. However, one might expect that different
	ciphering structures will need <I>different</I> table characteristics to a greater or less degree. So the discussion
	of S-box <A HREF="Glossary.htm#Strength">strength</A> always occurs within the context of a particular <A HREF="Glossary.htm#Cipher">cipher</A>
	construction.
	<H4>S-Box Avalanche</H4>
	<P>With respect to avalanche, any input change -- even one bit -- will select a different table entry. Over all
	possible input values and changes, the number of output bits changed will have a <A HREF="Glossary.htm#BinomialDistribution">binomial
	distribution</A>. (See the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#BitChanges'" tppabs="http://www.io.com/~ritter/JAVASCRP/BINOMPOI.HTM#BitChanges">bit changes</A>
	section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#JavaScript'" tppabs="http://www.io.com/~ritter/#JavaScript">Ciphers By Ritter / JavaScript</A> computation pages.)
	So, in this respect, all tables are equal.</P>
	<P>On the other hand, it is possible to arrange tables so that single-bit input changes are guaranteed to produce
	at least two-bit output changes, and this would seem to improve avalanche. But we note that this is <I>probable</I>
	even with a randomly-constructed table, so we have to ask just how much this guarantee has improved things. In
	a Feistel cipher, it seems like this <I>might</I> reduce the number of needed <A HREF="Glossary.htm#Round">rounds</A> by one.
	But in actual operation, the plaintext block is generally <I>randomized,</I> as in <A HREF="Glossary.htm#CBC">CBC-mode</A>.
	This means that the probability of getting a single-bit change in operation is very low anyway.</P>
	<P>It is true that cipher avalanche is tested using single-bit input changes, and that is the way avalanche is
	defined. The point of this is to assure that every output bit is &quot;affected&quot; by every input bit. But I
	see this as more of an experimental requirement than an operational issue that need be optimized.
	<H4>S-Box Nonlinearity</H4>
	<P>With respect to <A HREF="Glossary.htm#BooleanFunctionNonlinearity">Boolean function nonlinearity</A>, as tables get larger
	it becomes very difficult -- and essentially impossible -- to find tables with ideal nonlinearity values. This
	means that we are always accepting a compromise value, and this is especially the case if the table must also have
	high values of other S-box qualities.</P>
	<P>Even randomly-constructed tables tend to have reasonable nonlinearity values. We might expect an 8-bit table
	to have a nonlinearity of about 100 (that is, 100 bits must change in one of the eight 256-bit output functions
	to reach the closest affine Boolean function). Experimental measurement of the nonlinearity of 1,000,000 random
	8-bit tables shows exactly one table with a nonlinearity as low as 78, and the computed probability of an actually
	<I>linear</I> table (nonlinearity zero) is something like 10<SUP>-72</SUP> or 2<SUP>-242</SUP>.</P>
	<P>The NSA-designed 8-bit table in Skipjack cipher has a computed nonlinearity of 104. While not quite the highest
	value we could find, it <I>is</I> in the top 2.5 percent of the distribution, and it seems improbable that this
	occurred by accident. We might assume that this table is representative of the modern understanding of the needs
	of a Feistel design with a fixed table. If so, we might conclude that good nonlinearity (or something very much
	like it) is a necessary, if not quite sufficient, part of the design.
	<H4>Keyed S-Boxes</H4>
	<P>It is &quot;easy&quot; to construct <A HREF="Glossary.htm#Key">keyed</A> S-boxes, by <A HREF="Glossary.htm#Shuffle">shuffling</A> under
	the control of a keyed cryptographic <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>. (See, for example:
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/KEYSHUF.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/KEYSHUF.HTM'" tppabs="http://www.io.com/~ritter/KEYSHUF.HTM">A Keyed Shuffling System for Block Cipher Cryptography</A>.) This
	has the significant advantage of providing no fixed tables for The Opponent to understand and attack.</P>
	<P>One question is whether one should attempt to measure and discard tables with poorer qualities than others.
	My personal feeling is that the ciphering structure should be strong enough to handle the expected random table
	distribution without added measurement and selection.</P>
	<P>Also see: <A HREF="javascript:if(confirm('http://www.io.com/~ritter/RES/SBOXDESN.HTM  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/RES/SBOXDESN.HTM'" tppabs="http://www.io.com/~ritter/RES/SBOXDESN.HTM">S-Box Design: A Literature Survey</A>, in the
	<A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#LiteratureSurveys'" tppabs="http://www.io.com/~ritter/#LiteratureSurveys">Literature Surveys and Reviews</A> section of the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers
	By Ritter</A> page. <A NAME="Scalable"></A></P>
	<P>
	<DT><B>Scalable</B></DT>
	<DD>A <A HREF="Glossary.htm#Cipher">cipher</A> design which can produce both large real ciphers and tiny experimental versions
	from the exact same construction rules. Scalability is about more than just variable size: Scalability is about
	establishing a uniform structural identity which is size-independent, so that we achieve a strong cipher near the
	top, and a tiny but accurate model that we can investigate near the bottom.
	<P>While full-size ciphers can never be exhaustively tested, tiny cipher models <I>can</I> be approached experimentally,
	and any flaws in them probably will be present in the full-scale versions we propose to use. Just as mathematics
	works the same for numbers large or small, a <A HREF="Glossary.htm#BackDoor">backdoor</A> cipher built from fixed construction
	rules must have the same sort of backdoor, whether built large or small.</P>
	<P>For <A HREF="Glossary.htm#BlockCipher">block ciphers</A>, the real block size must be at least 128 bits, and the experimental
	block size probably should be between 8 and 16 bits. Such tiny ciphers can be directly compared to keyed <A HREF="Glossary.htm#SubstitutionTable">substitution
	tables</A> of the same size, which are the ideal theoretical model of a block cipher.</P>
	<P>Potentially, scalability does far more than just <I>simplify</I> testing: Scalability is an enabling technology
	that supports experimental analysis which is otherwise <I>impossible.</I> <A NAME="Secrecy"></A></P>
	<P>
	<DT><B>Secrecy</B></DT>
	<DD>One of the objectives of <A HREF="Glossary.htm#Cryptography">cryptography</A>: Keeping private information private. Also
	see: <A HREF="Glossary.htm#Trust">trust</A>.
	<P>In a <A HREF="Glossary.htm#SecretKeyCipher">secret key cipher</A>, secrecy implies the use of a <A HREF="Glossary.htm#Strength">strong</A>
	<A HREF="Glossary.htm#Cipher">cipher</A>. Secrecy in communication requires the <A HREF="Glossary.htm#Security">secure</A> distribution
	of secret <A HREF="Glossary.htm#Key">keys</A> to both ends (this is the <A HREF="Glossary.htm#KeyDistributionProblem">key distribution
	problem</A>).</P>
	<P>In a <A HREF="Glossary.htm#PublicKeyCipher">public key cipher</A>, the ability to expose <A HREF="Glossary.htm#Key">keys</A> apparently
	solves the <A HREF="Glossary.htm#KeyDistributionProblem">key distribution problem</A>. But communications secrecy requires
	that public keys be <A HREF="Glossary.htm#Authentication">authenticated</A> (<I>certified</I>) as belonging to their supposed
	owner. This must occur to cryptographic levels of assurance, because failure leads to immediate vulnerability under
	a <A HREF="Glossary.htm#ManInTheMiddleAttack">man-in-the-middle attack</A>. The possibility of this sort of <A HREF="Glossary.htm#Attack">attack</A>
	is very disturbing, because it needs little computation, and does not involve <A HREF="Glossary.htm#Break">breaking</A> any
	cipher, which makes all discussion of <A HREF="Glossary.htm#Cipher">cipher</A> <A HREF="Glossary.htm#Strength">strength</A> simply irrelevant.
	<A NAME="SecretCode"></A></P>
	<P>
	<DT><B>Secret Code</B></DT>
	<DD>A <A HREF="Glossary.htm#Code">coding</A> in which the correspondence between symbol and code value is kept secret. <A NAME="SecretKeyCipher"></A>
	<P>
	<DT><B>Secret Key Cipher</B></DT>
	<DD>Also called a <A HREF="Glossary.htm#SymmetricCipher">symmetric cipher</A> or <A HREF="Glossary.htm#ConventionalCipher">conventional
	cipher</A>. A <A HREF="Glossary.htm#Cipher">cipher</A> in which the exact same <A HREF="Glossary.htm#Key">key</A> is used to encipher a
	message, and then decipher the resulting <A HREF="Glossary.htm#Ciphertext">ciphertext</A>. As opposed to a <A HREF="Glossary.htm#PublicKeyCipher">public
	key cipher</A>. <A NAME="Security"></A>
	<P>
	<DT><B>Security</B></DT>
	<DD>Protection of a vital quality (such as secrecy, or safety, or even wealth) from infringement, and the resulting
	relief from fear and anxiety. The ability to engage and defeat attempts to damage, weaken, or destroy a vital quality.
	Security, in the form of assuring the secrecy of information while in storage or transit, is the fundamental role
	of <A HREF="Glossary.htm#Cryptography">cryptography</A>.
	<P>A secure cryptosystem physically or logically <I>prevents</I> unauthorized disclosure of its protected data.
	This is <I>independent</I> of whether the attacker is a government agent, a criminal, a private detective, some
	corporate security person, or a friend of an ex-lover. Real security does not care <I>who</I> the attacker is,
	or <I>what</I> their motive may be, but instead protects against the threat itself. Limited security, on the other
	hand, often seeks to guess the identity, capabilities and motives of the attacker, and concentrates resources at
	those points.</P>
	<P>There is, of course, no <I>absolute</I> security. But we can have real security against particular, defined
	threats. Also see: <A HREF="Glossary.htm#Strength">strength</A>. <A NAME="SecurityThroughObscurity"></A></P>
	<P>
	<DT><B>Security Through Obscurity</B></DT>
	<DD>A phrase which normally refers to inventing a new <A HREF="Glossary.htm#Cipher">cipher</A> which is supposedly <A HREF="Glossary.htm#Strength">strong</A>,
	then keeping the cipher secret so it &quot;cannot be attacked.&quot; One problem with this strategy is that it
	prevents public review of the cipher design, which means that the cipher may have serious weaknesses. And it may
	be much easier for The <A HREF="Glossary.htm#Opponent">Opponent</A> to obtain the supposedly secret ciphering program than
	it would be to break a serious cipher (see <A HREF="Glossary.htm#Kerckhoff2">Kerckhoff's second requirement</A>).
	<P>On the other hand, it can be a mistake to use even a public and well-reviewed cipher, if the cipher protects
	enough valuable information to support a substantial investment in analysis and equipment to break the cipher.
	A reasonable alternative is to select from among a wide variety of conceptually different ciphers, each of which
	thus carries far less information of far less value and so may not warrant a substantial attack investment. <A
	NAME="Semiconductor"></A></P>
	<P>
	<DT><B>Semiconductor</B></DT>
	<DD>A material which is between <A HREF="Glossary.htm#Conductor">conductor</A> and <A HREF="Glossary.htm#Insulator">insulator</A> with
	respect to ease of electron flow. The obvious examples are silicon and germanium. <A NAME="Semigroup"></A>
	<P>
	<DT><B>Semigroup</B></DT>
	<DD>A <A HREF="Glossary.htm#Set">set</A> with an <A HREF="Glossary.htm#Associative">associative</A> <A HREF="Glossary.htm#Dyadic">dyadic</A> operation
	which happens to be <A HREF="Glossary.htm#Closed">closed</A>. <A NAME="SessionKey"></A>
	<P>
	<DT><B>Session Key</B></DT>
	<DD>A <A HREF="Glossary.htm#Key">key</A> which lasts for the period of a work &quot;session.&quot; A <A HREF="Glossary.htm#MessageKey">message
	key</A> used for multiple messages. <A NAME="Set"></A>
	<P>
	<DT><B>Set</B></DT>
	<DD>A collection of distinguishable elements, usually, but not necessarily, numbers. <A NAME="ShiftRegister"></A>
	<P>
	<DT><B>Shift Register</B></DT>
	<DD>An array of storage elements in which the values in each element may be &quot;shifted&quot; into an adjacent
	element. (A new value is shifted into the &quot;first&quot; element, and the value in the &quot;last&quot; element
	is normally lost, or perhaps captured off-chip.) (See <A HREF="Glossary.htm#LFSR">LFSR</A>.)
	<PRE>   Right-Shifting Shift Register (SR)

               +----+  +----+         +----+
   Carry In --&gt;| A0 |-&gt;| A1 |-&gt; ... -&gt;| An |--&gt; Carry Out
               +----+  +----+         +----+
</PRE>
	<P>In <A HREF="Glossary.htm#Digital">digital</A> <A HREF="Glossary.htm#Hardware">hardware</A> versions, elements are generally <A HREF="Glossary.htm#Bit">bits</A>,
	and the stored values actually move from element to element in response to a <A HREF="Glossary.htm#Clock">clock</A>. <A HREF="Glossary.htm#Analog">Analog</A>
	hardware versions include the charge-coupled devices (CCD's) used in cameras, where the analog values from lines
	of sensors are sampled in parallel, then serialized and stepped off the chip to be digitized and processed.</P>
	<P>In <A HREF="Glossary.htm#Software">software</A> versions, elements are often <A HREF="Glossary.htm#Byte">bytes</A> or larger values,
	and the values may not actually move during stepping. Instead, the values may reside in a circular array, and one
	or more offsets into that array may step. In this way, even huge amounts of <A HREF="Glossary.htm#State">state</A> can be &quot;shifted&quot;
	by changing a single index or pointer. <A NAME="Shuffle"></A></P>
	<P>
	<DT><B>Shuffle</B></DT>
	<DD>Generally, the concept of &quot;mixing up&quot; a set of objects, symbols or elements, as in shuffling cards.
	Mathematically, each possible arrangement of elements is a particular <A HREF="Glossary.htm#Permutation">permutation</A>.
	<P>Within a <A HREF="Glossary.htm#Computer">computer</A> environment, it is easy to shuffle an arbitrary number of symbols
	using a <A HREF="Glossary.htm#RandomNumberGenerator">random number generator</A>, and the algorithm of Durstenfeld, which is
	described in Knuth II:
	<BLOCKQUOTE>
		<P>Durstenfeld, R. 1964. Algorithm 235, Random Permutation, Procedure SHUFFLE. <I>Communications of the ACM.</I>
		7: 420.</P>
		<P>Knuth, D. 1981. <I>The Art of Computer Programming,</I> Vol. 2, Seminumerical Algorithms. 2nd ed. 139. Reading,
		Mass: Addison-Wesley.
	</BLOCKQUOTE>
	<A NAME="SieveOfEratosthenes"></A>
	<P>
	<DT><B>Sieve of Eratosthenes</B></DT>
	<DD>A way to find relatively small <A HREF="Glossary.htm#Prime">primes</A>. Although small primes are less commonly useful
	in <A HREF="Glossary.htm#Cryptography">cryptography</A> than large (say, 100+ digit) primes, they <I>can</I> at least help
	to validate implementations of the procedures used to find large primes.
	<P>Basically, the &quot;Sieve of Eratosthenes&quot; starts out with a table of numbers from 1 to some limit, all
	of which are potential primes, and the knowledge that 2 is a prime. Since 2 is a prime, no other prime can have
	2 as a factor, so we run though the table discarding all multiples of 2. The next remaining number above 2 is 3,
	which we accept as a prime, and then run through the table crossing off all multiples of 3. The next remaining
	is 5, so we cross off all multiples of 5, and so on. After we cross-off each prime up to the square-root of the
	highest value in the table, the table will contain only primes.</P>
	<P>A similar process works with small <A HREF="Glossary.htm#Polynomial">polynomials</A>, and small polynomial <A HREF="Glossary.htm#Field">fields</A>,
	to find <A HREF="Glossary.htm#Irreducible">irreducible</A> polynomials. <A NAME="Significance"></A></P>
	<P>
	<DT><B>Significance</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the probability of committing a <A HREF="Glossary.htm#TypeIError">type I error</A>,
	the rejection of a true <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>. Given the probability distribution of the
	test <A HREF="Glossary.htm#Statistic">statistic</A> for the case &quot;nothing unusual found,&quot; that area which is sufficiently
	unlikely that values in this <I>critical region</I> would lead to rejecting the null hypothesis, and thus accepting
	the <A HREF="Glossary.htm#AlternativeHypothesis">alternative hypothesis</A>. <A NAME="SimpleSubstitution"></A>
	<P>
	<DT><B>Simple Substitution</B></DT>
	<DD>A type of <A HREF="Glossary.htm#Substitution">substitution</A> in which each possible symbol is given a unique replacement
	symbol.
	<P>Perhaps the original classical form of <A HREF="Glossary.htm#Cipher">cipher</A>, in which each <A HREF="Glossary.htm#Plaintext">plaintext</A>
	character is <A HREF="Glossary.htm#Encipher">enciphered</A> as some different character. In essence, the order of the alphabet
	is scrambled or <A HREF="Glossary.htm#Permutation">permuted</A>, and the particular scrambled order (or the scrambling process
	which creates that particular order) is the cipher <A HREF="Glossary.htm#Key">key</A>. Normally we think of scrambling alphabetic
	letters, but any <A HREF="Glossary.htm#Computer">computer</A> <A HREF="Glossary.htm#Code">coding</A> can be scrambled similarly.</P>
	<P>Small, practical examples of simple substitution are easily realized in <A HREF="Glossary.htm#Hardware">hardware</A> or
	<A HREF="Glossary.htm#Software">software</A>. In software, we can have a table of values each of which can be indexed or selected
	by element number. In hardware, we can simply have addressable memory. Given an index value, we can select the
	element at the index location, and read or change the value of the selected element.</P>
	<P>A <A HREF="Glossary.htm#SubstitutionTable">substitution table</A> will be initialized to contain exactly one occurrence
	of each possible symbol or character. This allows enciphering to be reversed and the <A HREF="Glossary.htm#Ciphertext">ciphertext</A>
	<A HREF="Glossary.htm#Decipher">deciphered</A>. For example, suppose we substitute a two-bit quantity, thus a value 0..3, in
	a particular table as follows:</P>
	<PRE>   2  3  1  0.
</PRE>
	<P>The above substitution table takes an input value to an output value by selecting a particular element. For
	example, an input of 0 selects 2 for output, and an input of 2 selects 1. If this is our enciphering, we can decipher
	with an inverse table. Since 0 is enciphered as 2, 2 must be deciphered as 0, and since 2 is enciphered as 1, 1
	must be deciphered as 2, with the whole table as follows:</P>
	<PRE>   3  2  0  1.
</PRE>
	<P>Mathematically, a simple substitution is a <A HREF="Glossary.htm#Mapping">mapping</A> (from input to output) which is <A
	HREF="Glossary.htm#OneToOne">one-to-one</A> and <A HREF="Glossary.htm#Onto">onto</A>, and is therefore <A HREF="Glossary.htm#Invertible">invertible</A>.
	<A NAME="Software"></A></P>
	<P>
	<DT><B>Software</B></DT>
	<DD>The description of a logic machine. The original textual composition is called <A HREF="Glossary.htm#SourceCode">source
	code</A>, the file of compiled <A HREF="Glossary.htm#Opcode">opcode</A> values is called <A HREF="Glossary.htm#ObjectCode">object code</A>,
	and the final linked result is pure &quot;machine code&quot; or <A HREF="Glossary.htm#MachineLanguage">machine language</A>
	Note that, by itself, software does not and can not function; but instead relies upon <A HREF="Glossary.htm#Hardware">hardware</A>
	for all functionality. When &quot;software&quot; is running, there is no software there: there is only hardware
	memory, with hardware <A HREF="Glossary.htm#Bit">bits</A> which can be sensed and stored, hardware counters and registers,
	and hardware <A HREF="Glossary.htm#Digital">digital</A> <A HREF="Glossary.htm#Logic">logic</A> to make decisions. See: <A HREF="Glossary.htm#Computer">computer</A>,
	<A HREF="Glossary.htm#System">system</A>, <A HREF="Glossary.htm#SystemDesign">system design</A>, and <A HREF="Glossary.htm#Debug">debug</A>. <A NAME="SourceCode"></A>
	<P>
	<DT><B>Source Code</B></DT>
	<DD>The textual representation of a <A HREF="Glossary.htm#Computer">computer</A> program as it is written by a programmer.
	Nowadays, source is typically in a high-level language like C, C++ or Pascal, but inevitably some programmers must
	work &quot;close to the machine&quot; in assembly language. The &quot;<A HREF="Glossary.htm#Code">code</A>&quot; part of this
	is presumably an extension of the idea that, ultimately, all computer programs are executed as &quot;machine code&quot;
	or <A HREF="Glossary.htm#MachineLanguage">machine language</A>. This consists of numeric values or &quot;operation codes&quot;
	(&quot;<A HREF="Glossary.htm#Opcode">opcodes</A>&quot;) which select the instruction to be executed, and so represent a very
	public <I>code</I> for those instructions. Also see <A HREF="Glossary.htm#ObjectCode">object code</A>. <A NAME="State"></A>
	<P>
	<DT><B>State</B></DT>
	<DD>Information storage, or &quot;memory.&quot; In abstract machine theory, retained information, generally used
	to influence future events.
	<P>In <A HREF="Glossary.htm#Statistics">statistics</A>, the current symbol from a sequence, or a value which selects or conditions
	possible outcomes (see: <A HREF="Glossary.htm#MarkovProcess">Markov process</A>).</P>
	<P>We normally measure &quot;state&quot; in units of information or <A HREF="Glossary.htm#Bit">bits</A>, and 8 bits of &quot;state&quot;
	can support 2<SUP>8</SUP> or 256 different state-value combinations or <I>states</I>.</P>
	<P>Also see: <A HREF="Glossary.htm#Deterministic">deterministic</A> and <A HREF="Glossary.htm#Keyspace">keyspace</A>. <A NAME="StationaryProcess"></A></P>
	<P>
	<DT><B>Stationary Process</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, a <A HREF="Glossary.htm#Stochastic">stochastic</A> (random) <A HREF="Glossary.htm#Process">process</A>
	(function) whose general <A HREF="Glossary.htm#Statistic">statistics</A> do not change over time; in which every sub-sequence
	is representative of the whole; a homogenous process. This may not be true of a <A HREF="Glossary.htm#MarkovProcess">Markov
	process</A>. Also see: <A HREF="Glossary.htm#Ergodic">ergodic</A>. <A NAME="Statistic"></A>
	<P>
	<DT><B>Statistic</B></DT>
	<DD>A computation or process intended to reduce diverse results into a one-dimensional ordering of values for better
	understanding and comparison. Also the value result of such a computation. See <A HREF="Glossary.htm#Statistics">statistics</A>.
	<P>A useful statistic will have some known (or at least explorable) probability <A HREF="Glossary.htm#Distribution">distribution</A>
	for the case &quot;nothing unusual found.&quot; This allows the statistic value to be interpreted as the probability
	of finding that value or less, for the case &quot;nothing unusual found.&quot; Then, if improbable statistic values
	occur repeatedly and systematically, we can infer that something unusual <I>is</I> being found, leading to the
	rejection of the <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>.</P>
	<P>It is also possible to explore different distributions for the same statistic under different conditions. This
	can provide a way to guess which condition was in force when the data were obtained. <A NAME="Statistics"></A></P>
	<P>
	<DT><B>Statistics</B></DT>
	<DD>The mathematical science of interpreting probability to extract meaning from diverse results. Also the analysis
	of a large <A HREF="Glossary.htm#Population">population</A> based on a limited number of <A HREF="Glossary.htm#Random">random</A> <A HREF="Glossary.htm#Sample">samples</A>
	from that population; this is also the ability to state probability bounds for the correctness of certain types
	of <A HREF="Glossary.htm#InductiveReasoning">inductive reasoning</A>. See <A HREF="Glossary.htm#Statistic">statistic</A> and <A HREF="Glossary.htm#RandomVariable">random
	variable</A>.
	<P>The usual role of statistics is to identify particular systematic events in the context of expected random variations
	that may conceal such events. This often occurs in a context of difficult and costly experimentation, and there
	is a premium on results which are so good that they stand above the noise; it may be that not much is lost if a
	weak positive is ignored.</P>
	<P>In contrast, cryptography and randomness generally support vast amounts of testing at low cost, and we seek
	weak indications. In this context, we may find it more useful to conduct many tests and collect many statistic
	values, then visually and mathematically compare the experimental distribution to the ideal for that statistic.</P>
	<P>A statistical <A HREF="Glossary.htm#Distribution">distribution</A> usually represents what we should expect from random
	data or random sampling. If we have random data, statistic values exceeding 95% of the distribution (often called
	<I>failure</I>) <I>should</I> occur about 1 time in 20. And since that one time may happen on the very first test,
	it is only prudent to conduct many tests and accumulate results which are more likely to represent reality than
	any one result from a single test.</P>
	<P>In statistical randomness testing, &quot;failure&quot; should and <I>must</I> occur with the appropriate frequency.
	Thus, the failure to fail is itself a failure! This means that the very concept of statistical &quot;failure&quot;
	often may be inappropriate for cryptographic use. Grading a result as &quot;pass&quot; or &quot;fail&quot; discards
	all but one <A HREF="Glossary.htm#Bit">bit</A> of information. Further, a pass / fail result is a <A HREF="Glossary.htm#BernoulliTrials">Bernoulli
	trial</A>, which would take many, many similar tests to properly characterize. So it may be more appropriate to
	collect 20 or more statistic probability values, and then compare the accumulation to the expected distribution
	for that statistic. This will provide a substantial basis for asserting that the sampled process either did or
	did not produce the same <A HREF="Glossary.htm#Statistic">statistic</A> <A HREF="Glossary.htm#Distribution">distribution</A> as a random
	process.</P>
	<P>Due to random sampling, any statistical result is necessarily a <I>probability,</I> rather than certainty. An
	&quot;unlucky&quot; sampling can produce statistical results which imply the opposite of reality. In general, statistics
	simply <B>cannot</B> provide the 100 percent certainty which is traditionally expected of mathematical &quot;proof.&quot;
	<A NAME="Steganography"></A></P>
	<P>
	<DT><B>Steganography</B></DT>
	<DD>Greek for &quot;sheltered writing.&quot; Methods of <A HREF="Glossary.htm#Cryptology">cryptology</A> which seek to conceal
	the <I>existence</I> of a message. As opposed to <A HREF="Glossary.htm#Cryptography">cryptography</A> which seeks to hide the
	<I>information</I> in the message, even if the message itself is completely exposed. <A NAME="Stochastic"></A>
	<P>
	<DT><B>Stochastic</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, <A HREF="Glossary.htm#Random">random</A>; involving a <A HREF="Glossary.htm#RandomVariable">random
	variable</A>. <A NAME="StreamCipher"></A>
	<P>
	<DT><B>Stream Cipher</B></DT>
	<DD>A <A HREF="Glossary.htm#Cipher">cipher</A> which directly handles messages of arbitrary size, by ciphering individual elements,
	such as <A HREF="Glossary.htm#Bit">bits</A> or <A HREF="Glossary.htm#Byte">bytes</A>. This avoids the need to accumulate data into a <A
	HREF="Glossary.htm#Block">block</A> before ciphering, as is necessary in a conventional <A HREF="Glossary.htm#BlockCipher">block cipher</A>.
	But note that a stream cipher can be seen as an <A HREF="Glossary.htm#OperatingMode">operating mode</A>, a &quot;streaming&quot;
	of a tiny block transformation. Stream ciphers can be called &quot;<A HREF="Glossary.htm#Combiner">combiner</A>-style&quot;
	ciphers.
	<H4>Stream Cipher Diffusion</H4>
	<P>In a conventional stream cipher, each element (for example, each byte) of the message is ciphered independently,
	and does not affect any other element.</P>
	<P>In a few stream cipher designs, the value of one message byte may change the enciphering of <I>subsequent</I>
	message bytes; this is forward data <A HREF="Glossary.htm#Diffusion">diffusion</A>. But a stream cipher <B>cannot</B> change
	the enciphering of <I>previous</I> message bytes. In contrast, changing even the last bit in a block cipher block
	will generally change about half of the earlier bits within that same block. Changing a bit in one block may even
	affect later blocks if we have some sort of stream meta-cipher composed of block cipher transformations, like <A
	HREF="Glossary.htm#CBC">CBC</A>.</P>
	<P>Note that a stream cipher generally does not need data diffusion for strength, as does a block cipher. In a
	block cipher, it may be possible to separate individual components of the cipher if their separate effects are
	not hidden by diffusion. But a stream cipher generally re-uses the same transformation, and has no multiple data
	components to hide.
	<H4>Stream Cipher Construction</H4>
	<P>The classic stream cipher is very simple, consisting of a <A HREF="Glossary.htm#Key">keyed</A> <A HREF="Glossary.htm#RandomNumberGenerator">random
	number generator</A> which produces a random-like <A HREF="Glossary.htm#ConfusionSequence">confusion sequence</A> or <A HREF="Glossary.htm#RunningKey">running
	key</A>. That sequence is then combined with <A HREF="Glossary.htm#Plaintext">plaintext</A> data in a simple additive <A HREF="Glossary.htm#Combiner">combiner</A>
	to produce <A HREF="Glossary.htm#Ciphertext">ciphertext</A>.</P>
	<P>When an exclusive-OR combiner is used, exactly the same construction will also decipher the ciphertext. But
	if The Opponents have some <A HREF="Glossary.htm#KnownPlaintextAttack">known-plaintext</A> and associated ciphertext, they
	can easily produce the original confusion sequence. This, along with their expected knowledge of the cipher design,
	may allow them to attack and expose the confusion generator. If this is successful, it will, of course, break the
	system until the RNG is re-keyed.</P>
	<P>The ultimate stream cipher is the <A HREF="Glossary.htm#OneTimePad">one-time pad</A>, in which a <A HREF="Glossary.htm#ReallyRandom">really
	random</A> sequence is never re-used. But if a sequence <I>is</I> re-used, The Opponent can generally combine the
	two ciphertexts, eliminating the confusion sequence, and producing the combined result of two plaintexts. Such
	a combination is normally easy to attack and penetrate.</P>
	<P>The re-use of confusion sequence is extremely dangerous in a stream cipher design. In general, all stream cipher
	designs <I>must</I> use a <A HREF="Glossary.htm#MessageKey">message key</A> to assure that the cipher is keyed with a random
	value for every new ciphering. This does, of course, expand the ciphertext by the size of the message key.</P>
	<P>Another alternative in stream cipher design is to use a stronger combiner, such as <A HREF="Glossary.htm#LatinSquareCombiner">Latin
	square</A> or <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic Substitution</A> combining. This can drastically reduce
	the complexity required in the confusion generator, which normally provides all stream cipher strength. Each of
	these stronger combiners is nonlinear, with substantial internal <A HREF="Glossary.htm#State">state</A>, and the designer may
	elect to use multiple combinings in sequence, or a selection among different combiners. Neither of these approaches
	make much sense with an <A HREF="Glossary.htm#AdditiveCombiner">additive combiner</A>. <A NAME="Strength"></A></P>
	<P>
	<DT><B>Strength</B></DT>
	<DD>The ability of a <A HREF="Glossary.htm#Cipher">cipher</A> to resist <A HREF="Glossary.htm#Attack">attack</A> and maintain <A HREF="Glossary.htm#Secrecy">secrecy</A>.
	The overall &quot;strength&quot; of a cipher is the minimum effort required to <A HREF="Glossary.htm#Break">break</A> the cipher,
	by any possible attack. But our <I>knowledge</I> of cipher &quot;strength&quot; is necessarily <A HREF="Glossary.htm#Contextual">contextual</A>
	and <A HREF="Glossary.htm#Subjective">subjective</A>, much like <I>unpredictability</I> in <A HREF="Glossary.htm#Random">random</A> sequences.
	Although &quot;strength&quot; would seem to be the entire point of using a cipher, <A HREF="Glossary.htm#Cryptography">cryptography</A>
	has no way to measure strength.
	<P>Cipher &quot;strength&quot; is often taken as an absolute universal <I>negative,</I> the simple <I>non-existence</I>
	of any attack which could succeed, assuming some level of attack resources. But this means that overall &quot;strength&quot;
	may be forever impossible to measure, because there is no hope of enumerating and evaluating <I>every possible</I>
	attack.
	<H4>Strength and Cryptanalysis</H4>
	<P>Because we have no tools for the discussion of strength under all possible <A HREF="Glossary.htm#Attack">attacks</A>, cipher
	&quot;strength&quot; is normally discussed in the context of particular attacks. Each known attack approach can
	be elaborated for a particular cipher, and a value calculated for the effort required to break the cipher in that
	way; this may set an &quot;upper bound&quot; on the unknown strength of the cipher (although some &quot;elaborations&quot;
	are clearly better than others). And while this is certainly better than not knowing the strength with respect
	to known attacks, such attacks may not represent the actual threat to the cipher in the field. (A cipher may even
	be said to have <I>different</I> &quot;contextual strengths,&quot; depending on the knowledge available to different
	<A HREF="Glossary.htm#Opponent">Opponents</A>.) In general, we never know the &quot;lower bound&quot; or &quot;true&quot; strength
	of a cipher. So, unless a cipher is shown to be weaker than we can accept, <A HREF="Glossary.htm#Cryptanalysis">cryptanalysis</A>
	provides no useful information about cipher strength.</P>
	<P>It is sometimes argued that &quot;our guys&quot; are just as good as the Opponents, who thus could not break
	a cipher with less effort than we know. Or it is said that if a better break were known, that secret necessarily
	would get out. When viewed in isolation such statements are clearly false reasoning, yet these are the sort of
	assumptions that are often implicitly used to assert strength after <A HREF="Glossary.htm#Cryptanalysis">cryptanalysis</A>.</P>
	<P>Since we cannot know the true situation, for a proper <A HREF="Glossary.htm#Security">security</A> analysis we must instead
	assume that our Opponents have more time, are better trained, are better equipped, and may even be <I>smarter</I>
	than our guys. Further, the Opponents are quite likely to function as a well-motivated group with a common goal
	and which can keep secrets; clearly, this is a far different situation than the usual academic cryptanalysis. So,
	again, cryptanalysis by &quot;our guys&quot; provides <B>no</B> information about the strength of the cipher as
	seen by our Opponents.
	<H4>Increasing Probable Strength and Reducing Possible Loss</H4>
	<P>Technical strength is just one of the many possibilities for weakness in a <A HREF="Glossary.htm#Cipher">cipher</A> system,
	and perhaps even the least likely. It is surprisingly difficult to construct a cipher system without &quot;holes,&quot;
	despite using good ciphers, and The Opponents get to exploit any overlooked problems. Users must be educated in
	security, and must actively keep secrets or there will be nothing to protect. In contrast, <A HREF="Glossary.htm#Cryptanalysis">cryptanalysis</A>
	is very expensive, success is never assured, and even many of the known <A HREF="Glossary.htm#Attack">attacks</A> are essentially
	impossible in practice.</P>
	<P>Nevertheless, it is a disturbing fact that we do not know and cannot guarantee a &quot;true&quot; strength for
	any cipher. But there <I>are</I> approaches which may reduce the probability of technical weakness and the extent
	of any loss:
	<OL>
		<LI>We can <I>extrapolate</I> various attacks beyond weakness levels actually shown, and thus possibly avoid some
		weak ciphers.
		<LI>We can use systems that change ciphers periodically. This will reduce the amount of information under any one
		cipher, and so limit the damage if that cipher is weak.
		<LI>We can use <A HREF="Glossary.htm#MultipleEncryption">multiple encryption</A> with different keys and different ciphers
		as our standard mode. In this way, not just one but multiple ciphers must each be penetrated simultaneously to
		expose the protected data.
		<LI>We can use systems that allow us to stop using ciphers when they are shown weak, and switch to others.
	</OL>
	<H4>Kinds of Cipher Strength</H4>
	<P>In general, we can consider a <A HREF="Glossary.htm#Cipher">cipher</A> to be a large <A HREF="Glossary.htm#Key">key</A>-selected transformation
	between <A HREF="Glossary.htm#Plaintext">plaintext</A> and <A HREF="Glossary.htm#Ciphertext">ciphertext</A>, with two main types of strength:
	<UL>
		<LI>One type of &quot;strength&quot; is an inability to extrapolate from known parts of the transformation (e.g.,
		<A HREF="Glossary.htm#KnownPlaintextAttack">known plaintext</A>) to model -- or even approximate -- the transformation at new
		points of interest (message ciphertexts).
		<LI>Another type of &quot;strength&quot; is an inability to develop a particular key, given the known cipher and
		a large number of known transformation points.
	</UL>
	<H4>Views of Strength</H4>
	<P>Strength is the effectiveness of fixed defense in the <A HREF="Glossary.htm#CryptographyWar">cryptography war</A>. In real
	war, a strong defense might be a fortification at the top of a mountain which could only be approached on a single
	long and narrow path. Unfortunately, in real military action, time after time, making assumptions about what the
	opponent &quot;could not&quot; do turned out to be deadly mistakes. In cryptography we can at least imagine that
	someday we might <I>prove</I> that all approaches but one are actually <I>impossible,</I> and then guard that last
	approach; see <A HREF="Glossary.htm#MathematicalCryptography">mathematical cryptography</A>.
	<H4>The Future of Strength</H4>
	<P>It is sometimes convenient to see security as a fence around a restricted compound: We can beef up the front
	gate, and in some way measure that increase in &quot;strength.&quot; But none of that matters if someone cuts through
	elsewhere, or tunnels under, or jumps over. Until we can produce a cipher design which reduces all the possible
	avenues of attack to exactly one, it will be very difficult to measure &quot;strength.&quot;</P>
	<P>One possibility might be to construct ciphers in <A HREF="Glossary.htm#Layer">layers</A> of different puzzles: Now, the
	obvious point of having multiple puzzles is to require multiple solutions before the cipher is broken. But a perhaps
	less obvious point is to set up the design so that the solution to one puzzle requires The Opponent to <I>commit</I>
	(in an information sense) in a way that <I>prevents</I> the solution to the next puzzle.</P>
	<P>Also see <A HREF="Glossary.htm#DesignStrength">design strength</A>, <A HREF="Glossary.htm#PerfectSecrecy">perfect secrecy</A>, <A HREF="Glossary.htm#IdealSecrecy">ideal
	secrecy</A>, and <A HREF="Glossary.htm#Security">security</A>. <A NAME="StrictAvalancheCriterion"></A></P>
	<P>
	<DT><B>Strict Avalanche Criterion (SAC)</B></DT>
	<DD>A term used in <A HREF="Glossary.htm#S-Box">S-box</A> analysis to describe the contents of an invertible <A HREF="Glossary.htm#Substitution">substitution</A>
	or, equivalently, a <A HREF="Glossary.htm#BlockCipher">block cipher</A>. If we have some input value, and then change one bit
	in that value, we expect about half the output bits to change; this is the <A HREF="Glossary.htm#AvalancheEffect">avalanche
	effect</A>, and is caused by an <A HREF="Glossary.htm#Avalanche">avalanche</A> process. The <I>Strict Avalanche Criterion</I>
	requires that each output bit change with probability one-half (over all possible input starting values). This
	is stricter than avalanche, since if a <I>particular</I> half of the output bits changed <I>all</I> the time, a
	strict interpretationist might call <I>that</I> &quot;avalanche.&quot; Also see <A HREF="Glossary.htm#Complete">complete</A>.
	<P>As introduced in Webster and Tavares:
	<BLOCKQUOTE>
		<P>&quot;If a cryptographic function is to satisfy the strict avalanche criterion, then each output bit should
		change with a probability of one half whenever a single input bit is complemented.&quot; [p.524]
	</BLOCKQUOTE>
	<P>Webster, A. and S. Tavares. 1985. On the Design of S-Boxes. <I>Advances in Cryptology -- CRYPTO '85.</I> 523-534.</P>
	<P>Although the SAC has tightened the understanding of &quot;avalanche,&quot; even SAC can be taken too literally.
	Consider the <A HREF="Glossary.htm#Scalable">scaled-down</A> block cipher model of a small invertible <A HREF="Glossary.htm#Key">keyed</A>
	<A HREF="Glossary.htm#SubstitutionTable">substitution table</A>: Any input bit-change thus selects a different table element,
	and so produces a random new value (over all possible keys). But when we compare the new value with the old, we
	find that typically half the bits change, and sometimes <I>all</I> the bits change, but <I>never</I> is there no
	change at all. This is a tiny bias toward change.</P>
	<P>If we have a 2-bit (4-element) table, there are 4 values, but after we take one as the original, there are only
	3 <I>changed</I> values, not 4. We will see changes of 1 bit, 1 bit, and 2 bits. But this is a change expectation
	of 2/3 for each output bit, instead of exactly 1/2 as one might interpret from SAC. Although this bias is clearly
	size-related, its source is <I>invertibility</I> and the definition of <I>change.</I> Thus, even a large block
	cipher <I>must</I> have <I>some</I> bias, though it is unlikely that we could measure enough cases to see it. The
	point is that one can extend some of these definitions well beyond their intended role. <A NAME="Subjective"></A></P>
	<P>
	<DT><B>Subjective</B></DT>
	<DD>In the study of <A HREF="Glossary.htm#Logic">logic</A>, a particular <I>interpretation</I> of reality, rather than <A HREF="Glossary.htm#Objective">objective</A>
	reality itself. <A NAME="Substitution"></A>
	<P>
	<DT><B>Substitution</B></DT>
	<DD>The concept of replacing one symbol with another symbol. This might be as simple as a grade-school lined sheet
	with the alphabet down the left side, and a substitute listed for each letter. In <A HREF="Glossary.htm#Computer">computer</A>
	science this might be a simple array of values, any one of which can be selected by indexing from the start of
	the array. See <A HREF="Glossary.htm#SubstitutionTable">substitution table</A>.
	<P>Cryptography recognizes four types of substitution:
	<UL>
		<LI><A HREF="Glossary.htm#SimpleSubstitution">Simple Substitution</A> or <A HREF="Glossary.htm#MonoalphabeticSubstitution">Monoalphabetic
		Substitution</A>,
		<LI><A HREF="Glossary.htm#HomophonicSubstitution">Homophonic Substitution</A>,
		<LI><A HREF="Glossary.htm#PolyalphabeticSubstitution">Polyalphabetic Substitution</A>, and
		<LI><A HREF="Glossary.htm#PolygramSubstitution">Polygram Substitution</A>.
	</UL>
	<A NAME="SubstitutionPermutation"></A>
	<P>
	<DT><B>Substitution-Permutation</B></DT>
	<DD>A method of constructing <A HREF="Glossary.htm#BlockCipher">block ciphers</A> in which block elements are <A HREF="Glossary.htm#Substitution">substituted</A>,
	and the resulting bits typically <A HREF="Glossary.htm#Transposition">transposed</A> or scrambled into a new arrangement. This
	would be one round of many.
	<P>One of the advantages of S-P construction is that the &quot;permutation&quot; stage can be simply a re-arrangement
	of wires, taking almost no time. Such a stage is more clearly described as a limited set of &quot;transpositions,&quot;
	rather than the more general &quot;permutation&quot; term. Since substitutions are <I>also</I> permutations (albeit
	with completely different costs and effects), one might fairly describe such a cipher as a &quot;permutation-permutation
	cipher,&quot; which is not particularly helpful.</P>
	<P>A disadvantage of the S-P construction is the need for special substitution patterns which support <A HREF="Glossary.htm#Diffusion">diffusion</A>.
	S-P ciphers diffuse bit-changes across the block round-by-round; if one of the substitution table output bits does
	not change, then no change can be conducted to one of the tables in the next round, which has the effect of reducing
	the complexity of the cipher. Consequently, special tables are required in S-P designs, but even special tables
	can only reduce and not eliminate the effect. See <A HREF="Glossary.htm#Complete">Complete</A>. <A NAME="SubstitutionTable"></A></P>
	<P>
	<DT><B>Substitution Table</B></DT>
	<DD>(Also <A HREF="Glossary.htm#S-Box">S-box</A>.) A linear array of values, indexed by position, which includes any value
	at most once. In cryptographic service, we normally use binary-power invertible tables with the same input and
	output range. For example, a <A HREF="Glossary.htm#Byte">byte</A>-substitution table will have 256 elements, and will contain
	each of the values 0..255 exactly once. Any value 0..255 into that table will select some element for output which
	will also be in the range 0..255.
	<P>For the same range of input and output values, two invertible substitution tables differ only in the order or
	<A HREF="Glossary.htm#Permutation">permutation</A> of the values in the table. There are 256 <A HREF="Glossary.htm#Factorial">factorial</A>
	different byte-substitution tables, which is a <A HREF="Glossary.htm#Keyspace">keyspace</A> of 1648 bits.</P>
	<P>A <A HREF="Glossary.htm#Key">keyed</A> <A HREF="Glossary.htm#SimpleSubstitution">simple substitution</A> table of sufficient size is
	the ideal <A HREF="Glossary.htm#BlockCipher">block cipher</A>. Unfortunately, with 128-bit blocks being the modern minimum
	for strength, there would be 2<SUP>128</SUP> entries in that table, which is completely out of the question.</P>
	<P>A keyed substitution table of <I>practical</I> size can only be thought of as a weak block cipher by itself,
	but it can be part of a combination of <A HREF="Glossary.htm#Component">components</A> which produce a stronger cipher. And
	since an invertible substitution table is the ideal tiny block cipher, it can be used for direct experimental comparison
	to a <A HREF="Glossary.htm#Scalable">scalable</A> block cipher of that same tiny size. <A NAME="Superencryption"></A></P>
	<P>
	<DT><B>Superencryption</B></DT>
	<DD>Usually the outer-level <A HREF="Glossary.htm#Encryption">encryption</A> of a <A HREF="Glossary.htm#MultipleEncryption">multiple encryption</A>.
	Often relatively weak, relying upon the text randomization effect of the lower-level encryption. <A NAME="Surjective"></A>
	<P>
	<DT><B>Surjective</B></DT>
	<DD><A HREF="Glossary.htm#Onto">Onto</A>. A <A HREF="Glossary.htm#Mapping">mapping</A> f: <I>X -&gt; Y</I> where <I>f(x)</I> covers all
	elements in <I>Y.</I> Not necessarily invertible, since multiple elements <I>x</I> in <I>X</I> could produce the
	same <I>f(x)</I> in <I>Y.</I> <A NAME="Switch"></A>
	<P>
	<DT><B>Switch</B></DT>
	<DD>Classically, an electro-mechanical device which physically presses two <A HREF="Glossary.htm#Conductor">conductors</A>
	together at a contact point, thus &quot;making&quot; a <A HREF="Glossary.htm#Circuit">circuit</A>, and also pulls the conductors
	apart, thus allowing air to <A HREF="Glossary.htm#Insulator">insulate</A> them and thus &quot;breaking&quot; the circuit. More
	generally, something which exhibits a significant change in some parameter between &quot;ON&quot; and &quot;OFF.&quot;
	<A NAME="SwitchingFunction"></A>
	<P>
	<DT><B>Switching Function</B></DT>
	<DD>A <A HREF="Glossary.htm#LogicFunction">logic function</A>. <A NAME="SymmetricCipher"></A>
	<P>
	<DT><B>Symmetric Cipher</B></DT>
	<DD>A <A HREF="Glossary.htm#SecretKeyCipher">secret key cipher</A>. <A NAME="SymmetricGroup"></A>
	<P>
	<DT><B>Symmetric Group</B></DT>
	<DD>The symmetric <A HREF="Glossary.htm#Group">group</A> is the set of all <A HREF="Glossary.htm#OneToOne">one-to-one</A> <A HREF="Glossary.htm#Mapping">mappings</A>
	from a set into itself. The collection of all <A HREF="Glossary.htm#Permutation">permutations</A> of some set.
	<P>Suppose we consider a <A HREF="Glossary.htm#BlockCipher">block cipher</A> to be a key-selected permutation of the <A HREF="Glossary.htm#Block">block</A>
	values: One question of interest is whether our cipher construction could, if necessary, reach every possible permutation,
	the symmetric group. <A NAME="System"></A></P>
	<P>
	<DT><B>System</B></DT>
	<DD>An interconnecting network of <A HREF="Glossary.htm#Component">components</A> which coordinate to perform a larger function.
	Also a system of ideas. See <A HREF="Glossary.htm#SystemDesign">system design</A>. <A NAME="SystemDesign"></A>
	<P>
	<DT><B>System Design</B></DT>
	<DD>The design of potentially complex <A HREF="Glossary.htm#System">systems</A>.
	<P>It is now easy to construct large <A HREF="Glossary.htm#Hardware">hardware</A> or <A HREF="Glossary.htm#Software">software</A> systems
	which are almost unmanageably complex and never error-free. But a good design and development approach can produce
	systems with far fewer problems. One such approach is:</P>
	<P>
	<OL>
		<LI>Decompose the system into small, <I>testable</I> components.
		<LI>Construct and then <I>actually test</I> each of the components individually.
	</OL>
	<P>This is both easier and harder than it looks: there are <I>many</I> ways to decompose a large system, and finding
	an effective and efficient decomposition can take both experience and trial-and-error. But many of the possible
	decompositions define components which are less testable or even <I>un</I>testable, so the testability criterion
	greatly reduces the search.</P>
	<P>Testing is no panacea: we cannot hope to find all possible bugs this way. But in practice we <I>can</I> hope
	to find 90 percent or more of the bugs simply by <I>actually testing</I> each component. (Component testing means
	that we are forced to <I>think</I> about what each component does, and about its requirements and limits. Then
	we have to make the realized component <I>conform</I> to those tests, which were based on our theoretical concepts.
	This will often expose problems, whether in the implementation, the tests, or the concepts.) By testing all components,
	when we put the system together, we can hope to avoid having to <A HREF="Glossary.htm#Debug">debug</A> multiple independent
	problems simultaneously.</P>
	<P>Other important system design concepts include:
	<UL>
		<LI>Build in test points and switches to facilitate run-time inspection, control, and analysis.
		<LI>Use repeatable comprehensive tests at all levels, and when a component is &quot;fixed,&quot; run those tests
		again.
		<LI>Start with the most basic system and fewest components, make that &quot;work&quot; (pass appropriate system
		tests), then &quot;add features&quot; one-by-one. Try not to get too far before making the expanded system work
		again.
	</UL>
	<A NAME="TableSelectionCombiner"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Table Selection Combiner</B>
	<DD>A <A HREF="Glossary.htm#Combiner">combining</A> <A HREF="Glossary.htm#Mechanism">mechanism</A> in which one input selects a table or
	substitution alphabet, and another input selects a value from within the selected table, said value becoming the
	combined result. Also called a <A HREF="Glossary.htm#PolyalphabeticCombiner">Polyalphabetic Combiner</A>. <A NAME="TEMPEST"></A>
	<P>
	<DT><B>TEMPEST</B></DT>
	<DD>Supposedly the acronym for &quot;Transient Electromagnetic Pulse Emanation Surveillance Technology.&quot; Originally,
	the potential insecurity due to the <A HREF="Glossary.htm#ElectromagneticField">electromagnetic</A> radiation which inherently
	occurs when a <A HREF="Glossary.htm#Current">current</A> flow changes in a <A HREF="Glossary.htm#Conductor">conductor</A>. Thus, pulses
	from <A HREF="Glossary.htm#Digital">digital</A> <A HREF="Glossary.htm#Circuit">circuitry</A> might be picked up by a receiver, and the
	<A HREF="Glossary.htm#Plaintext">plaintext</A> data reconstructed. The general concept can be extended to the idea that plaintext
	data pulses may escape on power lines, or as a faint background signal to encrypted data, or in any other unexpected
	<A HREF="Glossary.htm#Electronic">electronic</A> way.
	<P>Some amount of current change seems inevitable when switching occurs, and modern digital computation is based
	on such switching. But the amount of electromagnetic radiation emitted depends upon the amount of current switched,
	the length of the conductor, and the speed of the switching (that is, dI/dt, or the rate-of-change in current).
	In normal processing the amount of radiated energy is very small, but the value can be much larger when fast power
	drivers are used to send signals across cables of some length. This typically results in broadband noise which
	can be sensed with a shortwave receiver, a television, or an AM portable radio. Such receivers can be used to monitor
	attempts at improving the shielding.</P>
	<P>Ideally, equipment would be fully enclosed in an electrically unbroken conducting surface. In practice, the
	conductive enclosure may be sheet metal or screening, with holes for shielded cables. Shielding occurs not primarily
	from metal <I>per se,</I> but instead from the flow of electrical current in that metal. When an electromagnetic
	wave passes through a conductive surface, it induces a current, and that current change creates a similar but <I>opposing</I>
	electromagnetic wave which nearly <I>cancels</I> the original. The metallic surface must conduct in all directions
	to properly neutralize waves at every location and from every direction.</P>
	<P>Stock <A HREF="Glossary.htm#Computer">computer</A> enclosures often have huge unshielded openings which are hidden by a
	plastic cover. These should be covered with metal plates or screening, making sure that good electrical contact
	occurs at all places around the edges. Note that assuring good electrical connections can be difficult with aluminum,
	which naturally forms a thin but hard and non-conductive surface oxide. It is important to actually monitor emission
	levels with receivers both before and after any change, and extreme success can be very difficult. We can at least
	make sure that the shielding is tight (that it electrically conducts to all the surrounding metal), that it is
	as complete as possible, and that external cables are effectively shielded.</P>
	<P>Cable shielding extends the conductive envelope around signal wires and into the envelope surrounding the equipment
	the wire goes to. Any electromagnetic radiation from within a shield will tend to produce an opposing current in
	the shield conductor which will &quot;cancel&quot; the original radiation. But if a cable shield is <I>not</I>
	connected at <I>both</I> ends, no opposing current can flow, and no electromagnetic shielding will occur, despite
	having a metallic &quot;shield&quot; around the cable. It is thus necessary to assure that each external cable
	<I>has</I> a shield, and that the shield is <I>connected</I> to a conductive enclosure at <I>both</I> ends. (Note
	that some equipment may have an isolating capacitor between the shield and chassis ground to minimize &quot;ground
	loop&quot; effects when the equipment at each end of the cable connects to different <A HREF="Glossary.htm#AC">AC</A> sockets.)
	When shielding is impossible, it can be useful to place ferrite beads or rings around cables to promote a balanced
	and therefore essentially non-radiating signal flow.</P>
	<P>Perhaps the most worrisome emitter on a personal computer is the display cathode ray tube (CRT). Here we have
	a bundle of three electron beams, serially modulated, with reasonable current, switching quickly, and repeatedly
	tracing the exact same picture typically 60 times a second. This produces a recognizable substantial signal, and
	the repetition allows each display point to be compared across many different receptions, thus removing noise and
	increasing the effective range of the unintended communication. All things being equal, a liquid-crystal display
	should radiate a far smaller and also more-complex signal than a desktop CRT. <A NAME="Transformer"></A></P>
	<P>
	<DT><B>Transformer</B></DT>
	<DD>A passive electrical <A HREF="Glossary.htm#Component">component</A> composed of magnetically-coupled coils of wire. When
	AC flows through one coil or &quot;primary,&quot; it creates a changing <A HREF="Glossary.htm#MagneticField">magnetic field</A>
	which induces power in another coil. A transformer thus <I>isolates</I> power or signal, and also can change the
	<A HREF="Glossary.htm#Voltage">voltage</A>-to-<A HREF="Glossary.htm#Current">current</A> ratio, for example to &quot;step down&quot; line
	voltage for low-voltage use, or to &quot;step up&quot; low voltages for high-voltage devices (such as tubes or
	plasma devices). <A NAME="Transistor"></A>
	<P>
	<DT><B>Transistor</B></DT>
	<DD>An active <A HREF="Glossary.htm#Semiconductor">semiconductor</A> <A HREF="Glossary.htm#Component">component</A> which performs <A HREF="Glossary.htm#Analog">analog</A>
	<A HREF="Glossary.htm#Amplifier">amplification</A>.
	<P>Originally, a bipolar version with three terminals: Emitter (e), Collector (c), and Base (b). <A HREF="Glossary.htm#Current">Current</A>
	flow through the base-emitter junction (I<SUB>be</SUB>) is amplified by the current <A HREF="Glossary.htm#Gain">gain</A> or
	beta (B) of the device in allowing current to flow through the collector-base junction and on through the emitter
	(I<SUB>ce</SUB>).</P>
	<P>In a sense, a bipolar transistor consists of two back-to-back <A HREF="Glossary.htm#Diode">diodes</A>: the base-collector
	junction (operated in reverse bias) and the base-emitter junction (operated in forward bias) which influence each
	other. Current through the base-emitter junction releases either electrons or &quot;holes&quot; which are then
	drawn to the collector junction by the higher potential there, thus increasing collector current. The current ratio
	between the base input and the collector output is amplification.</P>
	<P>Field-Effect Transistors (FET's, as in MOSFET, etc.) have an extremely high input impedence, taking essentially
	no input current, and may be more easily fabricated in integrated circuits than bipolars. In an FET, Drain (d)
	and Source (s) contacts connect to a &quot;doped&quot; semiconductor channel. Extremely close to that channel,
	but still insulated from it, is a conductive area connected to a Gate (g) contact. Voltage on the gate creates
	an electrostatic field which interacts with current flowing in the drain-source channel, and can act to turn that
	current ON or OFF, depending on channel material (P or N), doping (enhancement or depletion), and gate polarity.
	Sometimes the drain and source terminals are interchangeable, and sometimes the source is connected to the substrate.
	Instead of an insulated gate, we can also have a reverse-biased diode junction, as in a JFET.</P>
	<P>N-channel FET's generally work better than p-channel devices. JFET's can only have &quot;depletion mode,&quot;
	which means that, with the gate grounded to the source, they are ON. N-channel JFET devices go OFF with a negative
	voltage on the gate. Normally, MOSFET devices are &quot;enhancement mode&quot; and are OFF with their gate grounded.
	N-channel MOSFET devices go ON with a positive voltage (0.5 to 5v) on the gate. Depletion mode n-channel MOSFET
	devices are possible, but not common. <A NAME="Transposition"></A></P>
	<P>
	<DT><B>Transposition</B></DT>
	<DD>The exchange in position of two elements. The most primitive possible <A HREF="Glossary.htm#Permutation">permutation</A>
	or re-ordering of elements. Any possible permutation can be constructed from a sequence of transpositions. <A NAME="TrapDoor"></A>
	<P>
	<DT><B>Trap Door</B></DT>
	<DD>A <A HREF="Glossary.htm#Cipher">cipher</A> design feature, presumably planned, which allows the apparent strength of the
	design to be easily avoided by those who know the trick. Similar to <A HREF="Glossary.htm#BackDoor">back door</A>. <A NAME="TripleDES"></A>
	<P>
	<DT><B>Triple DES</B></DT>
	<DD>The particular <A HREF="Glossary.htm#BlockCipher">block cipher</A> which is the U.S. Data Encryption Standard or <A HREF="Glossary.htm#DES">DES</A>,
	performed three times, with two or three different keys. <A NAME="TrulyRandom"></A>
	<P>
	<DT><B>Truly Random</B></DT>
	<DD>A random value or sequence derived from a physical source. Also called <A HREF="Glossary.htm#ReallyRandom">really random</A>
	and <A HREF="Glossary.htm#PhysicallyRandom">physically random</A>. <A NAME="Trust"></A>
	<P>
	<DT><B>Trust</B></DT>
	<DD>The assumption of a particular outcome in a dependence upon someone else. Trust is the basis for communications
	secrecy: While <A HREF="Glossary.htm#Secrecy">secrecy</A> can involve keeping one's own secrets, <I>communications secrecy</I>
	almost inevitably involves at least a second party. We thus necessarily &quot;trust&quot; that party with the secret
	itself, to say nothing of <A HREF="Glossary.htm#Cryptography">cryptographic</A> <A HREF="Glossary.htm#Key">keys</A>. It makes little sense
	to talk about secrecy in the absence of trust.
	<P>In a true <A HREF="Glossary.htm#Security">security</A> sense, it is impossible to fully trust <I>anyone:</I> Everyone has
	their weaknesses, their oversights, their own agendas. But normally &quot;trust&quot; involves some form of <I>commitment</I>
	by the other party to keep any secrets that occur. Normally the other party is constrained in some way, either
	by their own self-interest, or by contractual, legal, or other consequences of the failure of trust. The idea that
	there can be any realistic trust between two people who have never met, are not related, have no close friends
	in common, are not in the same employ, and are not contractually bound, can be a very dangerous delusion. It is
	important to recognize that no trust is without limit, and those limits are precisely the commitment of the other
	party, bolstered by the consequences of betrayal. Trust without consequences is necessarily a very weak trust.
	<A NAME="TruthTable"></A></P>
	<P>
	<DT><B>Truth Table</B></DT>
	<DD>Typically, a <A HREF="Glossary.htm#BooleanFunction">Boolean function</A> expressed as the table of the value it will produce
	for each possible combination of input values. <A NAME="TypeIError"></A>
	<P>
	<DT><B>Type I Error</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the rejection of a true <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>.
	<A NAME="TypeIIError"></A>
	<P>
	<DT><B>Type II Error</B></DT>
	<DD>In <A HREF="Glossary.htm#Statistics">statistics</A>, the acceptance of a false <A HREF="Glossary.htm#NullHypothesis">null hypothesis</A>.
	<A NAME="Unary"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Unary</B>
	<DD>From the Latin for &quot;one kind.&quot; Sometimes used to describe functions with a single argument, such
	as &quot;the unary -&quot; (the minus-sign), as opposed to subtraction, which presumably would be &quot;binary,&quot;
	and <I>that</I> could get very confusing very fast. Thus, <A HREF="Glossary.htm#Monadic">monadic</A> may be a better choice.
	Also see: <A HREF="Glossary.htm#Binary">binary</A> and <A HREF="Glossary.htm#Dyadic">dyadic</A>. <A NAME="UnexpectedDistance"></A>
	<P>
	<DT><B>Unexpected Distance</B></DT>
	<DD>The values computed by a <A HREF="Glossary.htm#FastWalshTransform">fast Walsh transform</A> when calculating <A HREF="Glossary.htm#BooleanFunctionNonlinearity">Boolean
	function nonlinearity</A> as often used in <A HREF="Glossary.htm#S-Box">S-box</A> analysis.
	<P>Given any two <A HREF="Glossary.htm#Random">random</A> <A HREF="Glossary.htm#Boolean">Boolean</A> sequences of the same length, we &quot;expect&quot;
	to find about half of the bits the same, and about half different. This means that the <I>expected</I> <A HREF="Glossary.htm#HammingDistance">Hamming
	distance</A> between two sequences is half their length.</P>
	<P>With respect to Boolean function nonlinearity, the expected distance is not only what we <I>expect,</I> it is
	also <I>the best we can possibly do,</I> because each <A HREF="Glossary.htm#AffineBooleanFunction">affine Boolean function</A>
	comes in both complemented and uncomplemented versions. So if <I>more</I> than half the bits differ between a random
	function and one version, then <I>less</I> than half must differ to the other version. This makes the expected
	distance the ideal reference point for nonlinearity.</P>
	<P>Since the FWT automatically produces the difference between the expected distance and the distance to each possible
	affine Boolean function (of the given length), I call this the <I>un</I>expected distance. Each term is positive
	or negative, depending on which version is more correlated to the given sequence, and the absolute value of this
	is a measure of <A HREF="Glossary.htm#Linear">linearity</A>. But since we generally want <I>non</I>linearity, we typically
	subtract the unexpected value from half the length of the sequence. <A NAME="UnicityDistance"></A></P>
	<P>
	<DT><B>Unicity Distance</B></DT>
	<DD>The amount of <A HREF="Glossary.htm#Ciphertext">ciphertext</A> needed to uniquely identify the correct <A HREF="Glossary.htm#Key">key</A>
	and its associated <A HREF="Glossary.htm#Plaintext">plaintext</A> (assuming a ciphertext-only <A HREF="Glossary.htm#Attack">attack</A>
	and natural language plaintext). With less ciphertext than the unicity distance, multiple keys may produce decipherings
	which are each plausible messages, although only one of these would be the correct solution. As we increase the
	amount of ciphertext, many formerly-plausable keys are eliminated, because the plaintext they produce becomes identifiably
	different from the structure and redundancy we expect in a natural language.
	<BLOCKQUOTE>
		<P>&quot;If a secrecy system with a finite key is used, and <I>N</I> letters of cryptogram intercepted, there will
		be, for the enemy, a certain set of messages with certain probabilities, that this cryptogram could represent.
		As <I>N</I> increases the field usually narrows down until eventually there is a unique 'solution' to the cryptogram;
		one message with probability essentially unity while all others are practically zero. A quantity <I>H(N)</I> is
		defined, called the equivocation, which measures in a statistical way how near the average cryptogram of <I>N</I>
		letters is to a unique solution; that is, how uncertain the enemy is of the original message after intercepting
		a cryptogram of <I>N</I> letters.&quot; [p.659]</P>
		<P>&quot;This gives a way of calculating approximately how much intercepted material is required to obtain a solution
		to the secrecy system. It appears <NOBR>. . .</NOBR> that with ordinary languages and the usual types of ciphers
		(not codes) this 'unicity distance' is approximately <I>H(K)/D.</I> Here <I>H(K)</I> is a number measuring the
		'size' of the key space. If all keys are <I>a priori</I> equally likely, <I>H(K)</I> is the logarithm of the number
		of possible keys. <I>D</I> is the redundancy of the <NOBR>language . . . .&quot;</NOBR> &quot;In simple substitution
		with a random key <I>H(K)</I> is <NOBR>log<SUB>10</SUB> 26!</NOBR> or about 20 and <I>D</I> (in decimal digits
		per letter) is about .7 for English. Thus unicity occurs at about 30 letters.&quot; [p.660]
	</BLOCKQUOTE>
	<P>Shannon, C. 1949. Communication Theory of Secrecy Systems. <I>Bell System Technical Journal.</I> 28: 656-715.
	<A NAME="UniformDistribution"></A></P>
	<P>
	<DT><B>Uniform Distribution</B></DT>
	<DD>A probability <A HREF="Glossary.htm#Distribution">distribution</A> in which each possible value is equally likely. Also
	a &quot;flat&quot; or &quot;even&quot; distribution.
	<P>A uniform distribution is the most important distribution in cryptography. For example, a cryptographer strives
	to make every possible <A HREF="Glossary.htm#Plaintext">plaintext</A> an equally likely interpretation of any <A HREF="Glossary.htm#Ciphertext">ciphertext</A>
	(see <A HREF="Glossary.htm#IdealSecrecy">ideal secrecy</A>). A cryptographer also strives to make every possible <A HREF="Glossary.htm#Key">key</A>
	equally likely, given any amount of <A HREF="Glossary.htm#KnownPlaintextAttack">known plaintext</A>.</P>
	<P>On the other hand, a uniform distribution with respect to one quality is not necessarily uniform with respect
	to another. For example, while keyed <A HREF="Glossary.htm#Shuffle">shuffling</A> can provably produce any possible <A HREF="Glossary.htm#Permutation">permutation</A>
	with equal probability (a uniform distribution of different <A HREF="Glossary.htm#SubstitutionTable">tables</A>), those tables
	will have a <A HREF="Glossary.htm#BooleanFunctionNonlinearity">Boolean function nonlinearity</A> distribution which is decidedly
	not uniform. And we might well expect a <I>different</I> non-uniform distribution for every different quality we
	measure. <A NAME="VariableSizeBlockCipher"></A></P>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Variable Size Block Cipher</B>
	<DD>The ciphering concept described in U.S. Patent 5,727,062 (see the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/#VSBCTech'" tppabs="http://www.io.com/~ritter/#VSBCTech">VSBC
	articles</A> on the <A HREF="javascript:if(confirm('http://www.io.com/~ritter/  \n\nThis file was not retrieved by Teleport Pro, because it is addressed on a domain or path outside the boundaries set for its Starting Address.  \n\nDo you want to open it from the server?'))window.location='http://www.io.com/~ritter/'" tppabs="http://www.io.com/~ritter/">Ciphers By Ritter</A> page).
	<P>A <A HREF="Glossary.htm#BlockCipher">block cipher</A> which supports ciphering in blocks of dynamically variable size. The
	<A HREF="Glossary.htm#Block">block</A> size may vary only in steps of some element size (for example, a <A HREF="Glossary.htm#Byte">byte</A>),
	but blocks could be arbitrarily large.</P>
	<P>Three characteristics distinguish a true variable size block cipher from designs which are merely imprecise
	about the size of block or element they support or the degree to which they support <A HREF="Glossary.htm#OverallDiffusion">overall
	diffusion</A>:
	<OL>
		<P>
		<LI>A variable size block cipher is indefinitely extensible and has no theoretical block size limitation;
		<P>
		<LI>A variable size block cipher can approach overall diffusion, such that each <A HREF="Glossary.htm#Bit">bit</A> in the output
		block is a function of every bit in the input block; and
		<P>
		<LI>A true variable size block cipher does not require additional steps (<A HREF="Glossary.htm#Round">rounds</A>) or <A HREF="Glossary.htm#Layer">layers</A>
		to approach overall diffusion as the block size is expanded.
	</OL>
	<P>Also see <A HREF="Glossary.htm#DynamicSubstitutionCombiner">Dynamic Substitution Combiner</A> and <A HREF="Glossary.htm#BalancedBlockMixing">Balanced
	Block Mixing</A>. <A NAME="Voltage"></A></P>
	<P>
	<DT><B>Voltage</B></DT>
	<DD>The measure of electron &quot;potential&quot; in volts. Voltage is analogous to water <I>pressure,</I> as opposed
	to <I>flow</I> or <A HREF="Glossary.htm#Current">current</A>. <A NAME="WalshFunctions"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>Walsh Functions</B>
	<DD>Walsh Functions are essentially the <A HREF="Glossary.htm#AffineBooleanFunction">affine Boolean functions</A>, although
	they are often represented with values {+1,-1). There are three different canonical orderings for these functions.
	The worth of these functions largely rests on their being a complete set of orthogonal functions. This allows any
	function to be represented as a correlation to each of the Walsh functions. This is a transform into an alternate
	basis which may be more useful for analysis or construction.
	<P>Also see: <A HREF="Glossary.htm#FastWalshTransform">Fast Walsh-Hadamard Transform</A>. <A NAME="Weight"></A></P>
	<P>
	<DT><B>Weight</B></DT>
	<DD>The weight of <A HREF="Glossary.htm#BooleanFunction">Boolean Function</A> <I>f</I> is the number of 1's in the <A HREF="Glossary.htm#TruthTable">truth
	table</A> of <I>f</I>. <A NAME="Whitening"></A>
	<P>
	<DT><B>Whitening</B></DT>
	<DD>An overly-cute description of making a signal or data more like <A HREF="Glossary.htm#WhiteNoise">white noise</A>, with
	an equal amount of energy in each frequency. To make data more <A HREF="Glossary.htm#Random">random</A>-like. <A NAME="WhiteNoise"></A>
	<P>
	<DT><B>White Noise</B></DT>
	<DD>A <A HREF="Glossary.htm#Random">random</A>-like signal with a flat <A HREF="Glossary.htm#Frequency">frequency</A> spectrum, in which
	each frequency has the same magnitude. As opposed to <A HREF="Glossary.htm#PinkNoise">pink noise</A>, in which the frequency
	spectrum drops off with frequency. White noise is analogous to white light, which contains every possible color.
	<P>White noise is normally described as a relative power density in <A HREF="Glossary.htm#Voltage">volts</A> squared per hertz.
	White noise power varies directly with bandwidth, so white noise would have twice as much power in the next higher
	octave as in the current one. The introduction of a white noise audio signal can destroy high-frequency loudspeakers.
	<A NAME="Wire"></A></P>
	<P>
	<DT><B>Wire</B></DT>
	<DD>A thin, long <A HREF="Glossary.htm#Conductor">conductor</A>, often considered &quot;ideally conductive&quot; compared to
	other parts of a <A HREF="Glossary.htm#Circuit">circuit</A>. <A NAME="XOR"></A>
	<P>
	<DT>
<HR ALIGN="CENTER">
</DT>
	<P><B>XOR</B>
	<DD><A HREF="Glossary.htm#ExclusiveOR">Exclusive-OR</A>. A Boolean <A HREF="Glossary.htm#LogicFunction">logic function</A> which is also
	<A HREF="Glossary.htm#Mod2">mod 2</A> addition.
</DL>

<P>
<HR ALIGN="CENTER">
<I><A HREF="javascript:if(confirm('http://christalmirror.ifrance.com/assembly/dossier10/fichiers/AUTHOR.HTM  \n\nThis file was not retrieved by Teleport Pro, because the server reports that this file cannot be found.  \n\nDo you want to open it from the server?'))window.location='http://christalmirror.ifrance.com/assembly/dossier10/fichiers/AUTHOR.HTM'" tppabs="http://christalmirror.ifrance.com/assembly/dossier10/fichiers/AUTHOR.HTM">Terry Ritter</A>, his <A HREF="javascript:if(confirm('http://christalmirror.ifrance.com/assembly/dossier10/fichiers/AUTHOR.HTM  \n\nThis file was not retrieved by Teleport Pro, because the server reports that this file cannot be found.  \n\nDo you want to open it from the server?'))window.location='http://christalmirror.ifrance.com/assembly/dossier10/fichiers/AUTHOR.HTM#Addr'" tppabs="http://christalmirror.ifrance.com/assembly/dossier10/fichiers/AUTHOR.HTM#Addr">current address</A>, and his <A HREF="javascript:if(confirm('http://christalmirror.ifrance.com/assembly/dossier10/fichiers/CRYPHTML.HTM  \n\nThis file was not retrieved by Teleport Pro, because the server reports that this file cannot be found.  \n\nDo you want to open it from the server?'))window.location='http://christalmirror.ifrance.com/assembly/dossier10/fichiers/CRYPHTML.HTM'" tppabs="http://christalmirror.ifrance.com/assembly/dossier10/fichiers/CRYPHTML.HTM">top
page</A>.</I>

</BODY>

</HTML>